{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12223406,
          "sourceType": "datasetVersion",
          "datasetId": 7701010
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Connect into my Huggingface account\n",
        "from huggingface_hub import login\n",
        "login(token=\"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\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T17:18:41.006215Z",
          "iopub.execute_input": "2025-06-21T17:18:41.006532Z",
          "iopub.status.idle": "2025-06-21T17:18:41.057716Z",
          "shell.execute_reply.started": "2025-06-21T17:18:41.006512Z",
          "shell.execute_reply": "2025-06-21T17:18:41.056889Z"
        },
        "id": "RWUDGwlASTOA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = \"/kaggle/input/non-gpt-responses/non-GPT_Responses.xlsx\"\n",
        "dataset = pd.read_excel(file_path)\n",
        "df = dataset\n",
        "print(f\"Number of rows: {len(df)}\")\n",
        "dataset.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T17:18:42.799386Z",
          "iopub.execute_input": "2025-06-21T17:18:42.799688Z",
          "iopub.status.idle": "2025-06-21T17:18:43.039111Z",
          "shell.execute_reply.started": "2025-06-21T17:18:42.799667Z",
          "shell.execute_reply": "2025-06-21T17:18:43.038339Z"
        },
        "id": "xmyyp2N3STOD",
        "outputId": "32dea82e-fbdb-41b8-cfc9-22412799a92b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of rows: 1466\n",
          "output_type": "stream"
        },
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      ID     Type                                          Responses  \\\n0  N1001  Student  Away from each other due to the fact that obje...   \n1  N1002  Student  They are negative so they will repel and they ...   \n2  N1003  Student  The cars will repel each other because there b...   \n3  N1004  Student  They will not make any force, therefore drivin...   \n4  N1005  Student  I believe that since they are the same ( they ...   \n\n   Category 1  Category 2  Category 3  Category 4  Category 5  Category 6  \\\n0           1           0           0           0           0           0   \n1           1           1           1           0           0           0   \n2           1           1           1           1           0           0   \n3           0           0           0           0           0           0   \n4           0           0           1           0           0           0   \n\n   Category 7 Category 8  Category 9  Category 10  Category 11  \n0           1          0           0            0            0  \n1           0          0           0            0            1  \n2           0          0           0            0            0  \n3           0          0           0            0            0  \n4           0          0           0            0            0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Type</th>\n      <th>Responses</th>\n      <th>Category 1</th>\n      <th>Category 2</th>\n      <th>Category 3</th>\n      <th>Category 4</th>\n      <th>Category 5</th>\n      <th>Category 6</th>\n      <th>Category 7</th>\n      <th>Category 8</th>\n      <th>Category 9</th>\n      <th>Category 10</th>\n      <th>Category 11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>N1001</td>\n      <td>Student</td>\n      <td>Away from each other due to the fact that obje...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>N1002</td>\n      <td>Student</td>\n      <td>They are negative so they will repel and they ...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>N1003</td>\n      <td>Student</td>\n      <td>The cars will repel each other because there b...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>N1004</td>\n      <td>Student</td>\n      <td>They will not make any force, therefore drivin...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>N1005</td>\n      <td>Student</td>\n      <td>I believe that since they are the same ( they ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "category_cols = [col for col in df.columns if col.startswith(\"Category\")]\n",
        "for cat in category_cols:\n",
        "    unique_labels = df[cat].dropna().unique()\n",
        "    print(f\"Category '{cat}': unique classes = {unique_labels}\")\n",
        "\n",
        "print()\n",
        "print(\"Category 8 values:\", df[\"Category 8\"].unique())\n",
        "print(\"Category 10 values:\", df[\"Category 10\"].unique())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T17:18:46.006813Z",
          "iopub.execute_input": "2025-06-21T17:18:46.007127Z",
          "iopub.status.idle": "2025-06-21T17:18:46.018121Z",
          "shell.execute_reply.started": "2025-06-21T17:18:46.007104Z",
          "shell.execute_reply": "2025-06-21T17:18:46.017346Z"
        },
        "id": "IMNPqH_9STOF",
        "outputId": "437dd260-e778-49bb-e99b-81993ed2ecee"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Category 'Category 1': unique classes = [1 0]\nCategory 'Category 2': unique classes = [0 1]\nCategory 'Category 3': unique classes = [0 1]\nCategory 'Category 4': unique classes = [0 1]\nCategory 'Category 5': unique classes = [0 1]\nCategory 'Category 6': unique classes = [0 1]\nCategory 'Category 7': unique classes = [1 0]\nCategory 'Category 8': unique classes = [0 1 '`']\nCategory 'Category 9': unique classes = [0 1]\nCategory 'Category 10': unique classes = [ 0  1 10]\nCategory 'Category 11': unique classes = [0 1]\n\nCategory 8 values: [0 1 '`']\nCategory 10 values: [ 0  1 10]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Category 8 to numeric (remove '`' or other non-numeric values)\n",
        "df[\"Category 8\"] = pd.to_numeric(df[\"Category 8\"], errors=\"coerce\")\n",
        "\n",
        "# Convert Category 10 to numeric as well\n",
        "df[\"Category 10\"] = pd.to_numeric(df[\"Category 10\"], errors=\"coerce\")\n",
        "\n",
        "# Remove the value '10'\n",
        "df.loc[df[\"Category 10\"] == 10, \"Category 10\"] = np.nan\n",
        "\n",
        "# Show cleaned unique values\n",
        "for cat in category_cols:\n",
        "    unique_labels = df[cat].dropna().unique()\n",
        "    print(f\"Category '{cat}': cleaned unique classes = {unique_labels}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T17:18:48.216747Z",
          "iopub.execute_input": "2025-06-21T17:18:48.217033Z",
          "iopub.status.idle": "2025-06-21T17:18:48.230814Z",
          "shell.execute_reply.started": "2025-06-21T17:18:48.217012Z",
          "shell.execute_reply": "2025-06-21T17:18:48.229945Z"
        },
        "id": "By172ZZ9STOG",
        "outputId": "0b69fb61-c60a-44fa-e171-5147ee7e4049"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Category 'Category 1': cleaned unique classes = [1 0]\nCategory 'Category 2': cleaned unique classes = [0 1]\nCategory 'Category 3': cleaned unique classes = [0 1]\nCategory 'Category 4': cleaned unique classes = [0 1]\nCategory 'Category 5': cleaned unique classes = [0 1]\nCategory 'Category 6': cleaned unique classes = [0 1]\nCategory 'Category 7': cleaned unique classes = [1 0]\nCategory 'Category 8': cleaned unique classes = [0. 1.]\nCategory 'Category 9': cleaned unique classes = [0 1]\nCategory 'Category 10': cleaned unique classes = [0. 1.]\nCategory 'Category 11': cleaned unique classes = [0 1]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "nan_counts = df.isna().sum()\n",
        "print(\"Number of NaN values per column:\")\n",
        "print(nan_counts)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T17:18:51.081792Z",
          "iopub.execute_input": "2025-06-21T17:18:51.082089Z",
          "iopub.status.idle": "2025-06-21T17:18:51.089228Z",
          "shell.execute_reply.started": "2025-06-21T17:18:51.082067Z",
          "shell.execute_reply": "2025-06-21T17:18:51.088009Z"
        },
        "id": "rDjAQfsZSTOI",
        "outputId": "e09543a3-4ebf-412f-8bc2-71bf51679c4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of NaN values per column:\nID             0\nType           0\nResponses      1\nCategory 1     0\nCategory 2     0\nCategory 3     0\nCategory 4     0\nCategory 5     0\nCategory 6     0\nCategory 7     0\nCategory 8     1\nCategory 9     0\nCategory 10    1\nCategory 11    0\ndtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Load data and clean df --------\n",
        "df = dataset\n",
        "df = df.dropna(subset=category_cols)\n",
        "df.isna().sum()\n",
        "print(f\"Number of rows: {len(df)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T17:18:53.573263Z",
          "iopub.execute_input": "2025-06-21T17:18:53.573543Z",
          "iopub.status.idle": "2025-06-21T17:18:53.582461Z",
          "shell.execute_reply.started": "2025-06-21T17:18:53.573524Z",
          "shell.execute_reply": "2025-06-21T17:18:53.581599Z"
        },
        "id": "VP4HiJfSSTOL",
        "outputId": "6208078a-e45b-4d08-e8cb-105691178588"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of rows: 1464\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Fixed BERT Embeddings (Without fine tuning)"
      ],
      "metadata": {
        "id": "F_zp5gIASTOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we implement code that does multi-label text classification using a pretrained BERT model without training it again. The model, called BertForSequenceClassification, comes from the Hugging Face Transformers library. It is already trained on lots of text and can turn sentences into useful numbers (embeddings). It also has a built-in classifier that gives a score for each label. Unlike methods where you train a separate classifier on top of BERT’s features(that w'll explore after), here the classifier is part of the BERT model itself. The model gives a score for each category, then uses a sigmoid function to turn these scores into probabilities. Finally, these probabilities are converted into yes/no predictions using a threshold."
      ],
      "metadata": {
        "id": "giEYU1-JSTON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Since we do not fine-tune BERT, we use it as a fixed feature extractor to get embeddings for each text. Then, we train a logistic regression classifier on these embeddings to predict the labels."
      ],
      "metadata": {
        "id": "EXo509sLSTOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "X_texts = df[\"Responses\"].fillna(\"\").astype(str).tolist()\n",
        "Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "# Load tokenizer and pretrained classification model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(category_cols))\n",
        "model.eval()\n",
        "\n",
        "# Batch prediction function with tqdm progress bar\n",
        "def predict_batch_multilabel(texts, batch_size=16, threshold=0.5):\n",
        "    all_predictions = []\n",
        "    all_probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting batches\"):\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            inputs = tokenizer(batch_texts, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            probs = torch.sigmoid(logits)\n",
        "            batch_predictions = (probs > threshold).int().cpu().numpy()\n",
        "            batch_probabilities = probs.cpu().numpy()\n",
        "\n",
        "            all_predictions.extend(batch_predictions)\n",
        "            all_probabilities.extend(batch_probabilities)\n",
        "\n",
        "    return np.array(all_predictions), np.array(all_probabilities)\n",
        "\n",
        "# Predict on the whole dataset\n",
        "Y_pred, Y_prob = predict_batch_multilabel(X_texts, batch_size=32, threshold=0.5)\n",
        "\n",
        "# Evaluate per category\n",
        "results = []\n",
        "for i, cat in enumerate(category_cols):\n",
        "    unique_classes = np.unique(Y[:, i])\n",
        "    average_type = 'binary' if (len(unique_classes) == 2 and set(unique_classes) == {0, 1}) else 'macro'\n",
        "\n",
        "    acc = accuracy_score(Y[:, i], Y_pred[:, i])\n",
        "    prec = precision_score(Y[:, i], Y_pred[:, i], zero_division=0, average=average_type)\n",
        "    rec = recall_score(Y[:, i], Y_pred[:, i], zero_division=0, average=average_type)\n",
        "    f1 = f1_score(Y[:, i], Y_pred[:, i], zero_division=0, average=average_type)\n",
        "\n",
        "    results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T08:45:59.956951Z",
          "iopub.execute_input": "2025-06-21T08:45:59.957663Z",
          "iopub.status.idle": "2025-06-21T08:48:16.501670Z",
          "shell.execute_reply.started": "2025-06-21T08:45:59.957641Z",
          "shell.execute_reply": "2025-06-21T08:48:16.500831Z"
        },
        "id": "yYG2U2J9STOS",
        "outputId": "ce976e42-1110-435c-e72d-17c3e59e9a66"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nPredicting batches: 100%|██████████| 46/46 [02:16<00:00,  2.96s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "       Category  Accuracy  Precision    Recall  F1 Score\n0    Category 1  0.772696   0.854674  0.880259  0.867278\n1    Category 2  0.623208   0.585406  0.931398  0.718941\n2    Category 3  0.456655   0.000000  0.000000  0.000000\n3    Category 4  0.639590   0.000000  0.000000  0.000000\n4    Category 5  0.108532   0.041146  0.982456  0.078984\n5    Category 6  0.987031   0.000000  0.000000  0.000000\n6    Category 7  0.219113   0.038593  0.661765  0.072934\n7    Category 8  0.076451   0.076451  1.000000  0.142042\n8    Category 9  0.040273   0.040273  1.000000  0.077428\n9   Category 10  0.173379   0.173379  1.000000  0.295521\n10  Category 11  0.427986   0.021519  0.207317  0.038991\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results show good performance for some categories but very poor or zero scores for many others, likely due to the classifier struggling with class imbalance and minority classes. So, we are going to explore different classifiers to improve these results."
      ],
      "metadata": {
        "id": "fzGzgiMnSTOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below performs multi-label classification by first extracting text embeddings using a pretrained BERT model, then training a logistic regression classifier on these embeddings for each category. After cleaning and preparing the text data and labels, loads BERT in evaluation mode (without training), and obtains fixed vector representations (embeddings) for each text using BERT’s [CLS] token output. The data is then split into training and test sets, for the purpose of evaluating the classifier’s performance on unseen data and to avoid overfitting. A multi-output logistic regression classifier is trained on the training embeddings and used to predict labels on the test set."
      ],
      "metadata": {
        "id": "5LCZ_KT8STOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -------- Extraction --------\n",
        "X_texts = df[\"Responses\"].fillna(\"\").astype(str).tolist()\n",
        "Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "# -------- Load BERT --------\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "model.eval()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# -------- Encode with BERT --------\n",
        "def get_bert_embeddings(texts, tokenizer, model, max_length=128):\n",
        "    all_embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for text in tqdm(texts, desc=\"Encoding texts with BERT\"):\n",
        "            if not isinstance(text, str):\n",
        "                text = str(text) if text is not None else \"\"\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=max_length)\n",
        "            outputs = model(**inputs)\n",
        "            cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "            all_embeddings.append(cls_embedding)\n",
        "    return np.array(all_embeddings)\n",
        "\n",
        "X_embeddings = get_bert_embeddings(X_texts, tokenizer, model)\n",
        "\n",
        "# -------- Train/Test split --------\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_embeddings, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# -------- Classification  # classifier can be changed. but us currently, you're using:\n",
        "# Pption1: With Logistic Regression\n",
        "clf = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
        "clf.fit(X_train, Y_train)\n",
        "Y_pred = clf.predict(X_test)\n",
        "\n",
        "# Option 2: Random Forest\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# clf = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "\n",
        "# Option 3: Support Vector Machine\n",
        "# from sklearn.svm import LinearSVC\n",
        "# clf = MultiOutputClassifier(LinearSVC(max_iter=1000))\n",
        "\n",
        "# -------- Evaluate --------\n",
        "results = []\n",
        "for i, cat in enumerate(category_cols):\n",
        "    unique_classes = np.unique(Y_test[:, i])\n",
        "    average_type = 'binary' if (len(unique_classes) == 2 and set(unique_classes) == {0, 1}) else 'macro'\n",
        "\n",
        "    acc = accuracy_score(Y_test[:, i], Y_pred[:, i])\n",
        "    prec = precision_score(Y_test[:, i], Y_pred[:, i], zero_division=0, average=average_type)\n",
        "    rec = recall_score(Y_test[:, i], Y_pred[:, i], zero_division=0, average=average_type)\n",
        "    f1 = f1_score(Y_test[:, i], Y_pred[:, i], zero_division=0, average=average_type)\n",
        "    results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T08:35:00.677179Z",
          "iopub.execute_input": "2025-06-21T08:35:00.677696Z",
          "iopub.status.idle": "2025-06-21T08:38:52.020959Z",
          "shell.execute_reply.started": "2025-06-21T08:35:00.677675Z",
          "shell.execute_reply": "2025-06-21T08:38:52.019841Z"
        },
        "id": "vleG7Ji6STOW",
        "outputId": "687aacea-157d-4288-fe27-bfdff79d8e3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Encoding texts with BERT: 100%|██████████| 1465/1465 [03:35<00:00,  6.80it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "       Category  Accuracy  Precision    Recall  F1 Score\n0    Category 1  0.918089   0.937759  0.961702  0.949580\n1    Category 2  0.856655   0.806667  0.902985  0.852113\n2    Category 3  0.935154   0.929936  0.948052  0.938907\n3    Category 4  0.860068   0.774510  0.814433  0.793970\n4    Category 5  0.972696   0.800000  0.571429  0.666667\n5    Category 6  0.989761   0.000000  0.000000  0.000000\n6    Category 7  0.965870   0.818182  0.529412  0.642857\n7    Category 8  0.911263   0.111111  0.052632  0.071429\n8    Category 9  0.959044   0.000000  0.000000  0.000000\n9   Category 10  0.883959   0.743590  0.547170  0.630435\n10  Category 11  0.962457   0.666667  0.307692  0.421053\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This results clearly show that severe class imbalance in some categories, like Categories 6 and 9, causes the model to predict only the majority class, leading to zero recall and F1 scores despite high accuracy."
      ],
      "metadata": {
        "id": "jl_GvuifSTOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, cat in enumerate(category_cols):\n",
        "    print(f\"{cat}: {np.bincount(Y[:, i])}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T08:24:32.522201Z",
          "iopub.execute_input": "2025-06-21T08:24:32.522509Z",
          "iopub.status.idle": "2025-06-21T08:24:32.528164Z",
          "shell.execute_reply.started": "2025-06-21T08:24:32.522485Z",
          "shell.execute_reply": "2025-06-21T08:24:32.527359Z"
        },
        "id": "1yVeYx9VSTOY",
        "outputId": "531eccbe-94ed-45b0-edc9-2a292f201d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Category 1: [ 229 1236]\nCategory 2: [707 758]\nCategory 3: [671 794]\nCategory 4: [949 516]\nCategory 5: [1408   57]\nCategory 6: [1446   19]\nCategory 7: [1397   68]\nCategory 8: [1353  112]\nCategory 9: [1406   59]\nCategory 10: [1211  254]\nCategory 11: [1383   82]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see from the class distributions, most of categories like Category 1, 5, 7, 9, 10, 8, 6 are highly imbalanced, with very few positive examples. This can cause the model to ignore the minority class and perform poorly on those labels.\n",
        "\n",
        "To address that, we will use class_weight='balanced' in our logistic regression model. This helps the model give more importance to the minority class and improves its ability to detect rare cases."
      ],
      "metadata": {
        "id": "y3gSXBRHSTOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -------- Extraction --------\n",
        "X_texts = df[\"Responses\"].fillna(\"\").astype(str).tolist()\n",
        "Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "# -------- Load BERT --------\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "model.eval()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# -------- Encode with BERT --------\n",
        "def get_bert_embeddings(texts, tokenizer, model, max_length=128):\n",
        "    all_embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for text in tqdm(texts, desc=\"Encoding texts with BERT\"):\n",
        "            if not isinstance(text, str):\n",
        "                text = str(text) if text is not None else \"\"\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=max_length)\n",
        "            outputs = model(**inputs)\n",
        "            cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "            all_embeddings.append(cls_embedding)\n",
        "    return np.array(all_embeddings)\n",
        "\n",
        "X_embeddings = get_bert_embeddings(X_texts, tokenizer, model)\n",
        "\n",
        "# -------- Train/Test split --------\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_embeddings, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# -------- Classification with balanced --------\n",
        "clf = MultiOutputClassifier(LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
        "clf.fit(X_train, Y_train)\n",
        "Y_pred = clf.predict(X_test)\n",
        "\n",
        "# -------- Evaluate --------\n",
        "results = []\n",
        "for i, cat in enumerate(category_cols):\n",
        "    unique_classes = np.unique(Y_test[:, i])\n",
        "    average_type = 'binary' if (len(unique_classes) == 2 and set(unique_classes) == {0, 1}) else 'macro'\n",
        "\n",
        "    acc = accuracy_score(Y_test[:, i], Y_pred[:, i])\n",
        "    prec = precision_score(Y_test[:, i], Y_pred[:, i], zero_division=0, average=average_type)\n",
        "    rec = recall_score(Y_test[:, i], Y_pred[:, i], zero_division=0, average=average_type)\n",
        "    f1 = f1_score(Y_test[:, i], Y_pred[:, i], zero_division=0, average=average_type)\n",
        "    results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T08:38:52.023737Z",
          "iopub.execute_input": "2025-06-21T08:38:52.023966Z",
          "iopub.status.idle": "2025-06-21T08:42:40.848059Z",
          "shell.execute_reply.started": "2025-06-21T08:38:52.023948Z",
          "shell.execute_reply": "2025-06-21T08:42:40.847377Z"
        },
        "id": "NX4U0YCjSTOa",
        "outputId": "bf2fe185-9664-4a7d-85e9-bba9c8076de9"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Encoding texts with BERT: 100%|██████████| 1465/1465 [03:31<00:00,  6.92it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "       Category  Accuracy  Precision    Recall  F1 Score\n0    Category 1  0.914676   0.956522  0.936170  0.946237\n1    Category 2  0.860068   0.816327  0.895522  0.854093\n2    Category 3  0.931741   0.929487  0.941558  0.935484\n3    Category 4  0.877133   0.785047  0.865979  0.823529\n4    Category 5  0.972696   0.714286  0.714286  0.714286\n5    Category 6  0.982935   0.200000  0.500000  0.285714\n6    Category 7  0.972696   0.800000  0.705882  0.750000\n7    Category 8  0.849829   0.179487  0.368421  0.241379\n8    Category 9  0.921502   0.200000  0.363636  0.258065\n9   Category 10  0.890785   0.672131  0.773585  0.719298\n10  Category 11  0.945392   0.421053  0.615385  0.500000\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT With Training"
      ],
      "metadata": {
        "id": "sgGfdC8-STOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will fine-tune BERT using PyTorch directly, without using the BertForSequenceClassification class from Hugging Face.\n"
      ],
      "metadata": {
        "id": "PYN16kplSTOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine tuning with 3 epochs and eval on 20%\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "X_texts = df[\"Responses\"].fillna(\"\").astype(str).tolist()\n",
        "Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "# Split into train and validation sets\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ----------------------- Define Dataset -----------------------\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(text,truncation=True,\n",
        "            padding='max_length',max_length=self.max_length,\n",
        "            return_tensors='pt')\n",
        "\n",
        "        # Flatten batch dimension\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# ----------------------- Load Model & Tokenizer -----------------------\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",num_labels=len(category_cols),\n",
        "    problem_type=\"multi_label_classification\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# ----------------------- Create Dataloaders -----------------------\n",
        "batch_size = 8\n",
        "train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# ----------------------- Define Optimizer & Loss -----------------------\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# ----------------------- Training Loop -----------------------\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss = loss_fn(logits, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train loss = {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# ----------------------- Evaluation -----------------------\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).int()\n",
        "\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_probs.append(probs.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "# Concatenate all batches\n",
        "Y_pred = torch.cat(all_preds).numpy()\n",
        "Y_prob = torch.cat(all_probs).numpy()\n",
        "Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "# ----------------------- Metrics per Category -----------------------\n",
        "results = []\n",
        "for i, cat in enumerate(category_cols):\n",
        "    acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "    prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T09:34:08.627911Z",
          "iopub.execute_input": "2025-06-21T09:34:08.628470Z",
          "iopub.status.idle": "2025-06-21T09:40:10.151661Z",
          "shell.execute_reply.started": "2025-06-21T09:34:08.628439Z",
          "shell.execute_reply": "2025-06-21T09:40:10.150990Z"
        },
        "id": "z8xOZRbfSTOc",
        "outputId": "f2917989-3f31-42b6-fe54-8ff24d54da6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1: Train loss = 0.3912\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2: Train loss = 0.2423\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3: Train loss = 0.1854\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 37/37 [00:09<00:00,  3.87it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "       Category  Accuracy  Precision    Recall  F1 Score\n0    Category 1  0.948805   0.940239  1.000000  0.969199\n1    Category 2  0.901024   0.844720  0.971429  0.903654\n2    Category 3  0.982935   0.980132  0.986667  0.983389\n3    Category 4  0.911263   0.850467  0.900990  0.875000\n4    Category 5  0.965870   0.666667  0.181818  0.285714\n5    Category 6  0.993174   1.000000  0.333333  0.500000\n6    Category 7  0.945392   0.000000  0.000000  0.000000\n7    Category 8  0.921502   0.000000  0.000000  0.000000\n8    Category 9  0.931741   0.000000  0.000000  0.000000\n9   Category 10  0.921502   0.678571  0.883721  0.767677\n10  Category 11  0.948805   0.571429  0.250000  0.347826\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results show a class imbalance problem, especially in categories like 7, 8, and 9, where Precision, Recall, and F1 Score are zero, despite relatively high Accuracy. Categories (7–9) likely have very few positive samples, so the model learns to always predict 0 (the majority class). To avoid that, we can add hadling that (the code below) or add number of epoch from 3 to 10 (code after below)."
      ],
      "metadata": {
        "id": "Kke05VNRSTOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full fine-tuning code with imbalance handling\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "X_texts = df[\"Responses\"].fillna(\"\").astype(str).tolist()\n",
        "Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "# Split into train and validation sets\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ----------------------- Define Dataset -----------------------\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(text, truncation=True, padding='max_length',\n",
        "                                  max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# ----------------------- Load Model & Tokenizer -----------------------\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=len(category_cols), problem_type=\"multi_label_classification\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# ----------------------- Create Dataloaders -----------------------\n",
        "batch_size = 16\n",
        "train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# ----------------------- Compute Class Weights -----------------------\n",
        "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float)\n",
        "pos_counts = Y_train_tensor.sum(dim=0)\n",
        "neg_counts = Y_train_tensor.shape[0] - pos_counts\n",
        "pos_weights = neg_counts / (pos_counts + 1e-6)\n",
        "pos_weights = pos_weights.to(device)\n",
        "\n",
        "# ----------------------- Define Optimizer & Loss -----------------------\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
        "\n",
        "# ----------------------- Training Loop -----------------------\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss = loss_fn(logits, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train loss = {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# ----------------------- Evaluation -----------------------\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).int()\n",
        "\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_probs.append(probs.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "# Concatenate all batches\n",
        "Y_pred = torch.cat(all_preds).numpy()\n",
        "Y_prob = torch.cat(all_probs).numpy()\n",
        "Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "# ----------------------- Metrics per Category -----------------------\n",
        "results = []\n",
        "for i, cat in enumerate(category_cols):\n",
        "    acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "    prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T16:33:15.961231Z",
          "iopub.execute_input": "2025-06-21T16:33:15.961903Z",
          "iopub.status.idle": "2025-06-21T16:53:23.300867Z",
          "shell.execute_reply.started": "2025-06-21T16:33:15.961879Z",
          "shell.execute_reply": "2025-06-21T16:53:23.300101Z"
        },
        "id": "rjJC6RC5STOf",
        "outputId": "a4250ba9-8b97-443a-e0e0-ac4949deb9c0",
        "colab": {
          "referenced_widgets": [
            "1d0e59b35dc64284ada6a1f1e61544b3",
            "502c8321c48d44c49dedd70a2d5e07af",
            "56696e1fc29742998e7d2ec828ee502d",
            "badd06af96f2497faa1ebb06676f8588",
            "10093b9a245a4e31a083a10f5118eaf5"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-06-21 16:33:27.927858: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750523608.151267      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750523608.214846      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d0e59b35dc64284ada6a1f1e61544b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "502c8321c48d44c49dedd70a2d5e07af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56696e1fc29742998e7d2ec828ee502d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "badd06af96f2497faa1ebb06676f8588"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10093b9a245a4e31a083a10f5118eaf5"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1: Train loss = 1.0153\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2: Train loss = 0.8389\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3: Train loss = 0.6450\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4: Train loss = 0.5400\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5: Train loss = 0.4631\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 6: Train loss = 0.3916\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 7: Train loss = 0.3330\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 8: Train loss = 0.2804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 9: Train loss = 0.2489\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 10: Train loss = 0.2127\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 19/19 [00:10<00:00,  1.83it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "       Category  Accuracy  Precision    Recall  F1 Score\n0    Category 1  0.808874   0.963918  0.792373  0.869767\n1    Category 2  0.846416   0.787879  0.928571  0.852459\n2    Category 3  0.931741   0.945205  0.920000  0.932432\n3    Category 4  0.883959   0.755725  0.980198  0.853448\n4    Category 5  0.955631   0.454545  0.909091  0.606061\n5    Category 6  0.945392   0.117647  0.666667  0.200000\n6    Category 7  0.996587   0.941176  1.000000  0.969697\n7    Category 8  0.897611   0.387097  0.521739  0.444444\n8    Category 9  0.931741   0.500000  0.250000  0.333333\n9   Category 10  0.952218   0.822222  0.860465  0.840909\n10  Category 11  0.969283   0.640000  1.000000  0.780488\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine tuning with 10 epochs and eval on 20%\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ----------------------- Prepare Data -----------------------\n",
        "X_texts = df[\"Responses\"].fillna(\"\").astype(str).tolist()\n",
        "Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "# Split into train and validation sets\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ----------------------- Define Dataset -----------------------\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(text,truncation=True,\n",
        "            padding='max_length',max_length=self.max_length,\n",
        "            return_tensors='pt')\n",
        "\n",
        "        # Flatten batch dimension\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# ----------------------- Load Model & Tokenizer -----------------------\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",num_labels=len(category_cols),\n",
        "    problem_type=\"multi_label_classification\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# ----------------------- Create Dataloaders -----------------------\n",
        "batch_size = 16\n",
        "train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# ----------------------- Define Optimizer & Loss -----------------------\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# ----------------------- Training Loop -----------------------\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss = loss_fn(logits, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train loss = {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# ----------------------- Evaluation -----------------------\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).int()\n",
        "\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_probs.append(probs.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "# Concatenate all batches\n",
        "Y_pred = torch.cat(all_preds).numpy()\n",
        "Y_prob = torch.cat(all_probs).numpy()\n",
        "Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "# ----------------------- Metrics per Category -----------------------\n",
        "results = []\n",
        "for i, cat in enumerate(category_cols):\n",
        "    acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "    prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T09:59:06.308177Z",
          "iopub.execute_input": "2025-06-21T09:59:06.308457Z",
          "iopub.status.idle": "2025-06-21T10:18:38.126398Z",
          "shell.execute_reply.started": "2025-06-21T09:59:06.308440Z",
          "shell.execute_reply": "2025-06-21T10:18:38.125741Z"
        },
        "id": "aTJwM8LsSTOi",
        "outputId": "a26d3634-73c9-40f0-90d0-0baf2effd7f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1: Train loss = 0.4480\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2: Train loss = 0.3076\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3: Train loss = 0.2485\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4: Train loss = 0.1986\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5: Train loss = 0.1669\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 6: Train loss = 0.1421\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 7: Train loss = 0.1213\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 8: Train loss = 0.1050\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 9: Train loss = 0.0931\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 10: Train loss = 0.0835\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 19/19 [00:10<00:00,  1.89it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "       Category  Accuracy  Precision    Recall  F1 Score\n0    Category 1  0.945392   0.936508  1.000000  0.967213\n1    Category 2  0.911263   0.880000  0.942857  0.910345\n2    Category 3  0.969283   0.966887  0.973333  0.970100\n3    Category 4  0.924915   0.869159  0.920792  0.894231\n4    Category 5  0.976109   0.700000  0.636364  0.666667\n5    Category 6  0.989761   0.000000  0.000000  0.000000\n6    Category 7  1.000000   1.000000  1.000000  1.000000\n7    Category 8  0.948805   1.000000  0.347826  0.516129\n8    Category 9  0.931741   0.000000  0.000000  0.000000\n9   Category 10  0.962457   0.880952  0.860465  0.870588\n10  Category 11  0.959044   0.642857  0.562500  0.600000\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "By increasing the number of epochs, the model is able to learn more and achieve better results."
      ],
      "metadata": {
        "id": "GhE1BvkzSTOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SciBERT"
      ],
      "metadata": {
        "id": "pcENlnF9STOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As well before, we'll fine-tune SciBERT using PyTorch directly, without using the BertForSequenceClassification class from Hugging Face."
      ],
      "metadata": {
        "id": "eYULN-j3STOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SciBERT froozing parameters (without any update within the model)"
      ],
      "metadata": {
        "id": "5pirH1KTSTOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -------- Data Extraction --------\n",
        "X_texts = df[\"Responses\"].fillna(\"\").astype(str).tolist()\n",
        "Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "# -------- Load SciBERT --------\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "model.eval()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# -------- Encode with SciBERT --------\n",
        "def get_bert_embeddings(texts, tokenizer, model, max_length=128):\n",
        "    all_embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for text in tqdm(texts, desc=\"Encoding texts with SciBERT\"):\n",
        "            if not isinstance(text, str):\n",
        "                text = str(text) if text is not None else \"\"\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=max_length)\n",
        "            outputs = model(**inputs)\n",
        "            cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "            all_embeddings.append(cls_embedding)\n",
        "    return np.array(all_embeddings)\n",
        "\n",
        "X_embeddings = get_bert_embeddings(X_texts, tokenizer, model)\n",
        "\n",
        "# -------- Train/Test split --------\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_embeddings, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# -------- Classification --------\n",
        "clf = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
        "clf.fit(X_train, Y_train)\n",
        "Y_pred = clf.predict(X_test)\n",
        "\n",
        "# -------- Evaluation --------\n",
        "results = []\n",
        "for i, cat in enumerate(category_cols):\n",
        "    unique_classes = np.unique(Y_test[:, i])\n",
        "    average_type = 'binary' if (len(unique_classes) == 2 and set(unique_classes) == {0, 1}) else 'macro'\n",
        "\n",
        "    acc = accuracy_score(Y_test[:, i], Y_pred[:, i])\n",
        "    prec = precision_score(Y_test[:, i], Y_pred[:, i], zero_division=0, average=average_type)\n",
        "    rec = recall_score(Y_test[:, i], Y_pred[:, i], zero_division=0, average=average_type)\n",
        "    f1 = f1_score(Y_test[:, i], Y_pred[:, i], zero_division=0, average=average_type)\n",
        "    results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T17:19:12.577276Z",
          "iopub.execute_input": "2025-06-21T17:19:12.577587Z",
          "iopub.status.idle": "2025-06-21T17:23:43.258875Z",
          "shell.execute_reply.started": "2025-06-21T17:19:12.577565Z",
          "shell.execute_reply": "2025-06-21T17:23:43.257560Z"
        },
        "id": "nyKB_1iESTOl",
        "outputId": "eaf45d76-6ad5-4984-c672-ec0c610a2d28"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Encoding texts with SciBERT: 100%|██████████| 1464/1464 [04:08<00:00,  5.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "       Category  Accuracy  Precision    Recall  F1 Score\n0    Category 1  0.918089   0.930894  0.970339  0.950207\n1    Category 2  0.846416   0.810458  0.885714  0.846416\n2    Category 3  0.924915   0.932432  0.920000  0.926174\n3    Category 4  0.873720   0.826531  0.801980  0.814070\n4    Category 5  0.976109   0.833333  0.454545  0.588235\n5    Category 6  0.982935   0.000000  0.000000  0.000000\n6    Category 7  0.982935   0.923077  0.750000  0.827586\n7    Category 8  0.897611   0.111111  0.043478  0.062500\n8    Category 9  0.924915   0.000000  0.000000  0.000000\n9   Category 10  0.904437   0.714286  0.581395  0.641026\n10  Category 11  0.955631   0.636364  0.437500  0.518519\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "X_texts = df[\"Responses\"].fillna(\"\").astype(str).tolist()\n",
        "Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ----------------------- Custom Dataset -----------------------\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt')\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# ----------------------- Load SciBERT -----------------------\n",
        "model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(category_cols),\n",
        "    problem_type=\"multi_label_classification\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# ----------------------- Dataloaders -----------------------\n",
        "batch_size = 16\n",
        "\n",
        "train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# ----------------------- Optimizer & Loss -----------------------\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# ----------------------- Training Loop -----------------------\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        loss = loss_fn(logits, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# ----------------------- Evaluation -----------------------\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).int()\n",
        "\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_probs.append(probs.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "Y_pred = torch.cat(all_preds).numpy()\n",
        "Y_prob = torch.cat(all_probs).numpy()\n",
        "Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "# ----------------------- Metrics -----------------------\n",
        "results = []\n",
        "for i, cat in enumerate(category_cols):\n",
        "    acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "    prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T17:25:21.250449Z",
          "iopub.execute_input": "2025-06-21T17:25:21.250788Z",
          "iopub.status.idle": "2025-06-21T17:45:10.515053Z",
          "shell.execute_reply.started": "2025-06-21T17:25:21.250765Z",
          "shell.execute_reply": "2025-06-21T17:45:10.514235Z"
        },
        "id": "hkiqrdDWSTOl",
        "outputId": "e148a6bc-123b-4753-b732-bdc806ce4ad9"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.3836\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Train Loss: 0.2654\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Train Loss: 0.1959\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.1621\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.1346\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 6 - Train Loss: 0.1133\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 7 - Train Loss: 0.0956\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 8 - Train Loss: 0.0816\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 9 - Train Loss: 0.0712\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 10 - Train Loss: 0.0629\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 19/19 [00:10<00:00,  1.84it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "       Category  Accuracy  Precision    Recall  F1 Score\n0    Category 1  0.959044   0.959016  0.991525  0.975000\n1    Category 2  0.928328   0.894040  0.964286  0.927835\n2    Category 3  0.979522   0.980000  0.980000  0.980000\n3    Category 4  0.935154   0.901961  0.910891  0.906404\n4    Category 5  0.972696   0.600000  0.818182  0.692308\n5    Category 6  0.993174   1.000000  0.333333  0.500000\n6    Category 7  0.993174   1.000000  0.875000  0.933333\n7    Category 8  0.924915   0.521739  0.521739  0.521739\n8    Category 9  0.931741   0.000000  0.000000  0.000000\n9   Category 10  0.962457   0.900000  0.837209  0.867470\n10  Category 11  0.948805   0.526316  0.625000  0.571429\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best results actually!"
      ],
      "metadata": {
        "id": "w9MANk_ZSTOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eval on 40%\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "X_texts = df[\"Responses\"].fillna(\"\").astype(str).tolist()\n",
        "Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.4, random_state=42)\n",
        "\n",
        "# ----------------------- Custom Dataset -----------------------\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt')\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# ----------------------- Load SciBERT -----------------------\n",
        "model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(category_cols),\n",
        "    problem_type=\"multi_label_classification\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# ----------------------- Dataloaders -----------------------\n",
        "batch_size = 16\n",
        "\n",
        "train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# ----------------------- Optimizer & Loss -----------------------\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# ----------------------- Training Loop -----------------------\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        loss = loss_fn(logits, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# ----------------------- Evaluation -----------------------\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).int()\n",
        "\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_probs.append(probs.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "Y_pred = torch.cat(all_preds).numpy()\n",
        "Y_prob = torch.cat(all_probs).numpy()\n",
        "Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "# ----------------------- Metrics -----------------------\n",
        "results = []\n",
        "for i, cat in enumerate(category_cols):\n",
        "    acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "    prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-21T17:49:06.144853Z",
          "iopub.execute_input": "2025-06-21T17:49:06.145236Z",
          "iopub.status.idle": "2025-06-21T18:04:10.581681Z",
          "shell.execute_reply.started": "2025-06-21T17:49:06.145212Z",
          "shell.execute_reply": "2025-06-21T18:04:10.580728Z"
        },
        "id": "p4x9xlVNSTOn",
        "outputId": "57beba10-8508-42ab-ce9f-205e74be2d42"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.4043\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Train Loss: 0.2770\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Train Loss: 0.2119\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.1725\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.1409\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 6 - Train Loss: 0.1175\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 7 - Train Loss: 0.1011\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 8 - Train Loss: 0.0884\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 9 - Train Loss: 0.0778\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 10 - Train Loss: 0.0709\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 37/37 [00:20<00:00,  1.79it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "       Category  Accuracy  Precision    Recall  F1 Score\n0    Category 1  0.936860   0.932563  0.995885  0.963184\n1    Category 2  0.926621   0.903727  0.960396  0.931200\n2    Category 3  0.979522   0.987179  0.974684  0.980892\n3    Category 4  0.899317   0.830357  0.898551  0.863109\n4    Category 5  0.981229   0.736842  0.700000  0.717949\n5    Category 6  0.989761   0.000000  0.000000  0.000000\n6    Category 7  0.991468   1.000000  0.814815  0.897959\n7    Category 8  0.940273   0.812500  0.288889  0.426230\n8    Category 9  0.952218   0.000000  0.000000  0.000000\n9   Category 10  0.955631   0.812500  0.906977  0.857143\n10  Category 11  0.967577   0.678571  0.655172  0.666667\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "rF9YkoiPSTOo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "GjNBU55sSTOo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "xurgE4WQSTOo"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}