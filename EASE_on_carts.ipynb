{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12694513,
          "sourceType": "datasetVersion",
          "datasetId": 8022647
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"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\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-06T23:31:33.188714Z",
          "iopub.execute_input": "2025-08-06T23:31:33.188884Z",
          "iopub.status.idle": "2025-08-06T23:31:33.777675Z",
          "shell.execute_reply.started": "2025-08-06T23:31:33.188868Z",
          "shell.execute_reply": "2025-08-06T23:31:33.776881Z"
        },
        "id": "a5VAkubuM3IA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "import pandas as pd\n",
        "file_path = \"/kaggle/input/non-gpt-dataset/non-GPT_Responses.xlsx\"\n",
        "dataset = pd.read_excel(file_path)\n",
        "df = dataset\n",
        "print(f\"Number of rows: {len(df)}\")\n",
        "dataset.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-06T23:31:33.779080Z",
          "iopub.execute_input": "2025-08-06T23:31:33.779348Z",
          "iopub.status.idle": "2025-08-06T23:31:34.896834Z",
          "shell.execute_reply.started": "2025-08-06T23:31:33.779325Z",
          "shell.execute_reply": "2025-08-06T23:31:34.895957Z"
        },
        "id": "KX1qg_t_M3IC",
        "outputId": "f2f0036f-5ea8-4af6-dd4d-69a6fb138982"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of rows: 1466\n",
          "output_type": "stream"
        },
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      ID     Type                                          Responses  \\\n0  N1001  Student  Away from each other due to the fact that obje...   \n1  N1002  Student  They are negative so they will repel and they ...   \n2  N1003  Student  The cars will repel each other because there b...   \n3  N1004  Student  They will not make any force, therefore drivin...   \n4  N1005  Student  I believe that since they are the same ( they ...   \n\n   Category 1  Category 2  Category 3  Category 4  Category 5  Category 6  \\\n0           1           0           0           0           0           0   \n1           1           1           1           0           0           0   \n2           1           1           1           1           0           0   \n3           0           0           0           0           0           0   \n4           0           0           1           0           0           0   \n\n   Category 7 Category 8  Category 9  Category 10  Category 11  \n0           1          0           0            0            0  \n1           0          0           0            0            1  \n2           0          0           0            0            0  \n3           0          0           0            0            0  \n4           0          0           0            0            0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Type</th>\n      <th>Responses</th>\n      <th>Category 1</th>\n      <th>Category 2</th>\n      <th>Category 3</th>\n      <th>Category 4</th>\n      <th>Category 5</th>\n      <th>Category 6</th>\n      <th>Category 7</th>\n      <th>Category 8</th>\n      <th>Category 9</th>\n      <th>Category 10</th>\n      <th>Category 11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>N1001</td>\n      <td>Student</td>\n      <td>Away from each other due to the fact that obje...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>N1002</td>\n      <td>Student</td>\n      <td>They are negative so they will repel and they ...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>N1003</td>\n      <td>Student</td>\n      <td>The cars will repel each other because there b...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>N1004</td>\n      <td>Student</td>\n      <td>They will not make any force, therefore drivin...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>N1005</td>\n      <td>Student</td>\n      <td>I believe that since they are the same ( they ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "category_cols = [col for col in df.columns if col.startswith(\"Category\")]\n",
        "# Convert Category 8 to numeric (remove '`' or other non-numeric values)\n",
        "df[\"Category 8\"] = pd.to_numeric(df[\"Category 8\"], errors=\"coerce\")\n",
        "# Convert Category 10 to numeric as well\n",
        "df[\"Category 10\"] = pd.to_numeric(df[\"Category 10\"], errors=\"coerce\")\n",
        "# Remove the value '10'\n",
        "df.loc[df[\"Category 10\"] == 10, \"Category 10\"] = np.nan\n",
        "# -------- clean df --------\n",
        "df = df.dropna(subset=category_cols)\n",
        "df.isna().sum()\n",
        "print(f\"Number of rows: {len(df)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-06T23:31:34.897586Z",
          "iopub.execute_input": "2025-08-06T23:31:34.897874Z",
          "iopub.status.idle": "2025-08-06T23:31:34.917674Z",
          "shell.execute_reply.started": "2025-08-06T23:31:34.897857Z",
          "shell.execute_reply": "2025-08-06T23:31:34.917032Z"
        },
        "id": "t57R7nNwM3ID",
        "outputId": "eb5ac26d-3dcf-47f8-9e8c-e99f536e17e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of rows: 1464\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process EASE augmentation by first saving only the newly generated synthetic data, then merging it with the original dataset and saving the combined result."
      ],
      "metadata": {
        "id": "N6SfzW8nM3IE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from math import ceil\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Load dataset\n",
        "df[\"Source\"] = \"original\"\n",
        "\n",
        "# Function to calculate class distribution\n",
        "def get_class_distribution(df, categories):\n",
        "    distribution = {}\n",
        "    for cat in categories:\n",
        "        counts = df[cat].value_counts(normalize=True) * 100\n",
        "        distribution[cat] = {\n",
        "            '1s': counts.get(1, 0),\n",
        "            '0s': counts.get(0, 0)}\n",
        "    return distribution\n",
        "\n",
        "# Plot distribution before/after augmentation\n",
        "def plot_distribution(before_dist, after_dist, categories):\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    categories = sorted(categories)\n",
        "\n",
        "    before_1s = [before_dist[cat]['1s'] for cat in categories]\n",
        "    after_1s = [after_dist[cat]['1s'] for cat in categories]\n",
        "    before_0s = [before_dist[cat]['0s'] for cat in categories]\n",
        "    after_0s = [after_dist[cat]['0s'] for cat in categories]\n",
        "\n",
        "    x = np.arange(len(categories))\n",
        "    width = 0.2\n",
        "\n",
        "    plt.bar(x - width*1.5, before_0s, width, label='Before - 0s', color='lightblue')\n",
        "    plt.bar(x - width/2,  before_1s, width, label='Before - 1s', color='steelblue')\n",
        "    plt.bar(x + width/2,  after_0s, width, label='After - 0s', color='lightcoral')\n",
        "    plt.bar(x + width*1.5, after_1s, width, label='After - 1s', color='firebrick')\n",
        "\n",
        "    plt.xlabel('Categories')\n",
        "    plt.ylabel('Percentage')\n",
        "    plt.title('Class Distribution Before and After EASE Augmentation (0s and 1s)')\n",
        "    plt.xticks(x, categories, rotation=45)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Initialize DistilBERT for EASE augmentation\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "fill_mask = pipeline(\"fill-mask\", model=model_name, tokenizer=tokenizer)\n",
        "\n",
        "# Get embedding for a word\n",
        "def get_embedding(text, word, model, tokenizer):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    word_idx = tokens.index(word) if word in tokens else -1\n",
        "    if word_idx != -1:\n",
        "        return outputs.last_hidden_state[0, word_idx, :].numpy()\n",
        "    return None\n",
        "\n",
        "# EASE augmentation function\n",
        "def ease_augment(text, fill_mask, tokenizer, model, num_augments=2):\n",
        "    words = text.split()\n",
        "    augmented_texts = []\n",
        "\n",
        "    for _ in range(num_augments):\n",
        "        new_text = words.copy()\n",
        "        replace_idx = random.randint(0, len(words) - 1)\n",
        "        original_word = words[replace_idx]\n",
        "\n",
        "        embedding = get_embedding(text, original_word, model, tokenizer)\n",
        "        if embedding is None:\n",
        "            continue\n",
        "\n",
        "        masked_text = \" \".join(new_text[:replace_idx] + [\"[MASK]\"] + new_text[replace_idx + 1:])\n",
        "        predictions = fill_mask(masked_text, top_k=5)\n",
        "\n",
        "        for pred in predictions:\n",
        "            new_word = pred[\"token_str\"]\n",
        "            if new_word != original_word and new_word.isalpha():\n",
        "                new_text[replace_idx] = new_word\n",
        "                augmented_texts.append(\" \".join(new_text))\n",
        "                break\n",
        "\n",
        "    return augmented_texts\n",
        "\n",
        "# Get categories\n",
        "categories = [f\"Category {i}\" for i in range(1, 12)]\n",
        "\n",
        "# Calculate distribution before augmentation\n",
        "before_dist = get_class_distribution(df, categories)\n",
        "\n",
        "# Augmentation loop for minority classes\n",
        "target_categories = [\"Category 5\", \"Category 6\", \"Category 7\", \"Category 8\", \"Category 9\", \"Category 10\", \"Category 11\"]\n",
        "augmented_data = []\n",
        "\n",
        "print(\"\\n Class Balancing Summary:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for category in target_categories:\n",
        "    minority_rows = df[df[category] == 1]\n",
        "    num_ones = len(minority_rows)\n",
        "    num_zeros = len(df[df[category] == 0])\n",
        "    num_needed = num_zeros - num_ones\n",
        "\n",
        "    if num_needed <= 0:\n",
        "        print(f\"{category}: Already balanced or dominant → Skipped.\")\n",
        "        continue\n",
        "\n",
        "    augments_per_sample = ceil(num_needed / num_ones)\n",
        "    new_count = 0\n",
        "\n",
        "    for _, row in minority_rows.iterrows():\n",
        "        text = row[\"Responses\"]\n",
        "        if isinstance(text, str) and text.strip() and text.lower() != \"not answered\":\n",
        "            augmented_texts = ease_augment(text, fill_mask, tokenizer, model, num_augments=augments_per_sample)\n",
        "            for aug_text in augmented_texts:\n",
        "                new_row = row.copy()\n",
        "                new_row[\"Responses\"] = aug_text\n",
        "                new_row[\"ID\"] = f\"AUG_{row['ID']}_{len(augmented_data)}\"\n",
        "                new_row[\"Source\"] = \"augmented\"\n",
        "                augmented_data.append(new_row)\n",
        "                new_count += 1\n",
        "                if new_count >= num_needed:\n",
        "                    break\n",
        "        if new_count >= num_needed:\n",
        "            break\n",
        "\n",
        "    print(f\"{category}: 1s={num_ones}, 0s={num_zeros} → Target=~{num_zeros} | Added={new_count} samples\")\n",
        "\n",
        "# Build augmented dataframe\n",
        "augmented_df = pd.DataFrame(augmented_data)\n",
        "\n",
        "#Save ONLY augmented data\n",
        "augmented_df.to_excel(\"augmented_only_non-GPT_Responses.xlsx\", index=False)\n",
        "\n",
        "# Merge with original\n",
        "final_df = pd.concat([df, augmented_df], ignore_index=True)\n",
        "\n",
        "# Calculate distribution after augmentation\n",
        "after_dist = get_class_distribution(final_df, categories)\n",
        "\n",
        "# Plot and save the distribution comparison\n",
        "plot_distribution(before_dist, after_dist, categories)\n",
        "\n",
        "# Save merged dataset\n",
        "final_df.to_excel(\"augmented_merged_with_original.xlsx\", index=False)\n",
        "\n",
        "# Summary\n",
        "print(\"\\n Summary\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Original dataset size: {len(df)}\")\n",
        "print(f\"Augmented dataset size: {len(final_df)}\")\n",
        "print(f\"Added {len(augmented_data)} synthetic samples for minority classes.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-06T23:31:34.918412Z",
          "iopub.execute_input": "2025-08-06T23:31:34.918622Z",
          "iopub.status.idle": "2025-08-06T23:41:02.362911Z",
          "shell.execute_reply.started": "2025-08-06T23:31:34.918602Z",
          "shell.execute_reply": "2025-08-06T23:41:02.362213Z"
        },
        "colab": {
          "referenced_widgets": [
            "80bc163c364e42c6bdff11e0e95cddfd",
            "5bcc8621faef455db2e1f30e85161eeb",
            "0be78347537a44b485beff6b622cd171",
            "7028aa086b324fc4b495baed659bf1c6",
            "e75f529bfaf24a0db8a6f29d7f5222f4"
          ]
        },
        "id": "xY2RNLD8M3IG",
        "outputId": "9ba3fcfd-3be4-448b-8aa5-afd974eb4f42"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-08-06 23:31:47.513526: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754523107.796768      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754523107.881370      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/tmp/ipykernel_36/3091242025.py:16: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"Source\"] = \"original\"\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80bc163c364e42c6bdff11e0e95cddfd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bcc8621faef455db2e1f30e85161eeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0be78347537a44b485beff6b622cd171"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7028aa086b324fc4b495baed659bf1c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e75f529bfaf24a0db8a6f29d7f5222f4"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Device set to use cuda:0\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n Class Balancing Summary:\n----------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Category 5: 1s=56, 0s=1408 → Target=~1408 | Added=1195 samples\nCategory 6: 1s=19, 0s=1445 → Target=~1445 | Added=1246 samples\nCategory 7: 1s=68, 0s=1396 → Target=~1396 | Added=1164 samples\nCategory 8: 1s=112, 0s=1352 → Target=~1352 | Added=1178 samples\nCategory 9: 1s=59, 0s=1405 → Target=~1405 | Added=1187 samples\nCategory 10: 1s=254, 0s=1210 → Target=~1210 | Added=871 samples\nCategory 11: 1s=81, 0s=1383 → Target=~1383 | Added=1199 samples\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1400x600 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n Summary\n----------------------------------------\nOriginal dataset size: 1464\nAugmented dataset size: 9504\nAdded 8040 synthetic samples for minority classes.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on Initial dataset"
      ],
      "metadata": {
        "id": "DfGLD0icM3IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --------------------- 1. Load Augmented Dataset ---------------------\n",
        "#df = pd.read_excel(\"augmented_non-GPT_Responses.xlsx\")\n",
        "category_cols = [f\"Category {i}\" for i in range(1, 12)]\n",
        "\n",
        "X_texts = df[\"Responses\"].fillna(\"\").astype(str).tolist()\n",
        "Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "# --------------------- 2. Split (20/80) Train/Val ---------------------\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --------------------- 3. Custom Dataset ---------------------\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# --------------------- 4. Load SciBERT ---------------------\n",
        "model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(category_cols),\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# --------------------- 5. DataLoaders ---------------------\n",
        "batch_size = 8\n",
        "\n",
        "train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# --------------------- 6. Optimizer & Loss ---------------------\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# --------------------- 7. Training Loop ---------------------\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = loss_fn(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# --------------------- 8. Evaluation ---------------------\n",
        "model.eval()\n",
        "all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).int()\n",
        "\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_probs.append(probs.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "Y_pred = torch.cat(all_preds).numpy()\n",
        "Y_prob = torch.cat(all_probs).numpy()\n",
        "Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "# --------------------- 9. Metrics ---------------------\n",
        "results = []\n",
        "for i, cat in enumerate(category_cols):\n",
        "    acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "    prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(\"\\n SciBERT Evaluation on Initial Dataset:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-06T23:41:02.364359Z",
          "iopub.execute_input": "2025-08-06T23:41:02.364589Z",
          "iopub.status.idle": "2025-08-06T23:51:28.543001Z",
          "shell.execute_reply.started": "2025-08-06T23:41:02.364549Z",
          "shell.execute_reply": "2025-08-06T23:51:28.542357Z"
        },
        "colab": {
          "referenced_widgets": [
            "aa87e2787c054e7686d36a007d56556c",
            "c83efef212a341a98b0ad629ca058a6d",
            "59c59ae2fb794cf99dd6f7d0026418fb",
            "a60845ebfcb145e78d5a8b8b1262890b"
          ]
        },
        "id": "TDcPN6L9M3IH",
        "outputId": "21c3c3db-08b4-4145-ce62-818672fea364"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa87e2787c054e7686d36a007d56556c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c83efef212a341a98b0ad629ca058a6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59c59ae2fb794cf99dd6f7d0026418fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a60845ebfcb145e78d5a8b8b1262890b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\nEpoch 1/5:   0%|          | 0/147 [00:00<?, ?it/s]\u001b[A\nEpoch 1/5:   0%|          | 0/147 [00:01<?, ?it/s, loss=0.669]\u001b[A\nEpoch 1/5:   1%|          | 1/147 [00:01<04:10,  1.72s/it, loss=0.669]\u001b[A\nEpoch 1/5:   1%|          | 1/147 [00:02<04:10,  1.72s/it, loss=0.663]\u001b[A\nEpoch 1/5:   1%|▏         | 2/147 [00:02<02:55,  1.21s/it, loss=0.663]\u001b[A\nEpoch 1/5:   1%|▏         | 2/147 [00:03<02:55,  1.21s/it, loss=0.604]\u001b[A\nEpoch 1/5:   2%|▏         | 3/147 [00:03<02:29,  1.04s/it, loss=0.604]\u001b[A\nEpoch 1/5:   2%|▏         | 3/147 [00:04<02:29,  1.04s/it, loss=0.593]\u001b[A\nEpoch 1/5:   3%|▎         | 4/147 [00:04<02:17,  1.04it/s, loss=0.593]\u001b[A\nEpoch 1/5:   3%|▎         | 4/147 [00:05<02:17,  1.04it/s, loss=0.556]\u001b[A\nEpoch 1/5:   3%|▎         | 5/147 [00:05<02:09,  1.09it/s, loss=0.556]\u001b[A\nEpoch 1/5:   3%|▎         | 5/147 [00:05<02:09,  1.09it/s, loss=0.547]\u001b[A\nEpoch 1/5:   4%|▍         | 6/147 [00:05<02:05,  1.12it/s, loss=0.547]\u001b[A\nEpoch 1/5:   4%|▍         | 6/147 [00:06<02:05,  1.12it/s, loss=0.541]\u001b[A\nEpoch 1/5:   5%|▍         | 7/147 [00:06<02:03,  1.14it/s, loss=0.541]\u001b[A\nEpoch 1/5:   5%|▍         | 7/147 [00:07<02:03,  1.14it/s, loss=0.533]\u001b[A\nEpoch 1/5:   5%|▌         | 8/147 [00:07<02:01,  1.15it/s, loss=0.533]\u001b[A\nEpoch 1/5:   5%|▌         | 8/147 [00:08<02:01,  1.15it/s, loss=0.489]\u001b[A\nEpoch 1/5:   6%|▌         | 9/147 [00:08<01:59,  1.16it/s, loss=0.489]\u001b[A\nEpoch 1/5:   6%|▌         | 9/147 [00:09<01:59,  1.16it/s, loss=0.475]\u001b[A\nEpoch 1/5:   7%|▋         | 10/147 [00:09<01:58,  1.16it/s, loss=0.475]\u001b[A\nEpoch 1/5:   7%|▋         | 10/147 [00:10<01:58,  1.16it/s, loss=0.455]\u001b[A\nEpoch 1/5:   7%|▋         | 11/147 [00:10<01:57,  1.16it/s, loss=0.455]\u001b[A\nEpoch 1/5:   7%|▋         | 11/147 [00:11<01:57,  1.16it/s, loss=0.451]\u001b[A\nEpoch 1/5:   8%|▊         | 12/147 [00:11<01:55,  1.16it/s, loss=0.451]\u001b[A\nEpoch 1/5:   8%|▊         | 12/147 [00:11<01:55,  1.16it/s, loss=0.464]\u001b[A\nEpoch 1/5:   9%|▉         | 13/147 [00:11<01:55,  1.16it/s, loss=0.464]\u001b[A\nEpoch 1/5:   9%|▉         | 13/147 [00:12<01:55,  1.16it/s, loss=0.406]\u001b[A\nEpoch 1/5:  10%|▉         | 14/147 [00:12<01:54,  1.16it/s, loss=0.406]\u001b[A\nEpoch 1/5:  10%|▉         | 14/147 [00:13<01:54,  1.16it/s, loss=0.443]\u001b[A\nEpoch 1/5:  10%|█         | 15/147 [00:13<01:54,  1.15it/s, loss=0.443]\u001b[A\nEpoch 1/5:  10%|█         | 15/147 [00:14<01:54,  1.15it/s, loss=0.417]\u001b[A\nEpoch 1/5:  11%|█         | 16/147 [00:14<01:54,  1.15it/s, loss=0.417]\u001b[A\nEpoch 1/5:  11%|█         | 16/147 [00:15<01:54,  1.15it/s, loss=0.404]\u001b[A\nEpoch 1/5:  12%|█▏        | 17/147 [00:15<01:53,  1.14it/s, loss=0.404]\u001b[A\nEpoch 1/5:  12%|█▏        | 17/147 [00:16<01:53,  1.14it/s, loss=0.373]\u001b[A\nEpoch 1/5:  12%|█▏        | 18/147 [00:16<01:53,  1.14it/s, loss=0.373]\u001b[A\nEpoch 1/5:  12%|█▏        | 18/147 [00:17<01:53,  1.14it/s, loss=0.409]\u001b[A\nEpoch 1/5:  13%|█▎        | 19/147 [00:17<01:52,  1.13it/s, loss=0.409]\u001b[A\nEpoch 1/5:  13%|█▎        | 19/147 [00:18<01:52,  1.13it/s, loss=0.391]\u001b[A\nEpoch 1/5:  14%|█▎        | 20/147 [00:18<01:52,  1.13it/s, loss=0.391]\u001b[A\nEpoch 1/5:  14%|█▎        | 20/147 [00:18<01:52,  1.13it/s, loss=0.401]\u001b[A\nEpoch 1/5:  14%|█▍        | 21/147 [00:18<01:51,  1.13it/s, loss=0.401]\u001b[A\nEpoch 1/5:  14%|█▍        | 21/147 [00:19<01:51,  1.13it/s, loss=0.41] \u001b[A\nEpoch 1/5:  15%|█▍        | 22/147 [00:19<01:51,  1.12it/s, loss=0.41]\u001b[A\nEpoch 1/5:  15%|█▍        | 22/147 [00:20<01:51,  1.12it/s, loss=0.386]\u001b[A\nEpoch 1/5:  16%|█▌        | 23/147 [00:20<01:50,  1.12it/s, loss=0.386]\u001b[A\nEpoch 1/5:  16%|█▌        | 23/147 [00:21<01:50,  1.12it/s, loss=0.378]\u001b[A\nEpoch 1/5:  16%|█▋        | 24/147 [00:21<01:50,  1.11it/s, loss=0.378]\u001b[A\nEpoch 1/5:  16%|█▋        | 24/147 [00:22<01:50,  1.11it/s, loss=0.39] \u001b[A\nEpoch 1/5:  17%|█▋        | 25/147 [00:22<01:49,  1.11it/s, loss=0.39]\u001b[A\nEpoch 1/5:  17%|█▋        | 25/147 [00:23<01:49,  1.11it/s, loss=0.375]\u001b[A\nEpoch 1/5:  18%|█▊        | 26/147 [00:23<01:49,  1.11it/s, loss=0.375]\u001b[A\nEpoch 1/5:  18%|█▊        | 26/147 [00:24<01:49,  1.11it/s, loss=0.343]\u001b[A\nEpoch 1/5:  18%|█▊        | 27/147 [00:24<01:48,  1.10it/s, loss=0.343]\u001b[A\nEpoch 1/5:  18%|█▊        | 27/147 [00:25<01:48,  1.10it/s, loss=0.391]\u001b[A\nEpoch 1/5:  19%|█▉        | 28/147 [00:25<01:48,  1.10it/s, loss=0.391]\u001b[A\nEpoch 1/5:  19%|█▉        | 28/147 [00:26<01:48,  1.10it/s, loss=0.347]\u001b[A\nEpoch 1/5:  20%|█▉        | 29/147 [00:26<01:47,  1.10it/s, loss=0.347]\u001b[A\nEpoch 1/5:  20%|█▉        | 29/147 [00:27<01:47,  1.10it/s, loss=0.316]\u001b[A\nEpoch 1/5:  20%|██        | 30/147 [00:27<01:46,  1.10it/s, loss=0.316]\u001b[A\nEpoch 1/5:  20%|██        | 30/147 [00:28<01:46,  1.10it/s, loss=0.413]\u001b[A\nEpoch 1/5:  21%|██        | 31/147 [00:28<01:45,  1.10it/s, loss=0.413]\u001b[A\nEpoch 1/5:  21%|██        | 31/147 [00:28<01:45,  1.10it/s, loss=0.345]\u001b[A\nEpoch 1/5:  22%|██▏       | 32/147 [00:28<01:44,  1.10it/s, loss=0.345]\u001b[A\nEpoch 1/5:  22%|██▏       | 32/147 [00:29<01:44,  1.10it/s, loss=0.391]\u001b[A\nEpoch 1/5:  22%|██▏       | 33/147 [00:29<01:43,  1.10it/s, loss=0.391]\u001b[A\nEpoch 1/5:  22%|██▏       | 33/147 [00:30<01:43,  1.10it/s, loss=0.427]\u001b[A\nEpoch 1/5:  23%|██▎       | 34/147 [00:30<01:42,  1.11it/s, loss=0.427]\u001b[A\nEpoch 1/5:  23%|██▎       | 34/147 [00:31<01:42,  1.11it/s, loss=0.307]\u001b[A\nEpoch 1/5:  24%|██▍       | 35/147 [00:31<01:40,  1.11it/s, loss=0.307]\u001b[A\nEpoch 1/5:  24%|██▍       | 35/147 [00:32<01:40,  1.11it/s, loss=0.335]\u001b[A\nEpoch 1/5:  24%|██▍       | 36/147 [00:32<01:39,  1.12it/s, loss=0.335]\u001b[A\nEpoch 1/5:  24%|██▍       | 36/147 [00:33<01:39,  1.12it/s, loss=0.417]\u001b[A\nEpoch 1/5:  25%|██▌       | 37/147 [00:33<01:38,  1.12it/s, loss=0.417]\u001b[A\nEpoch 1/5:  25%|██▌       | 37/147 [00:34<01:38,  1.12it/s, loss=0.334]\u001b[A\nEpoch 1/5:  26%|██▌       | 38/147 [00:34<01:36,  1.13it/s, loss=0.334]\u001b[A\nEpoch 1/5:  26%|██▌       | 38/147 [00:35<01:36,  1.13it/s, loss=0.33] \u001b[A\nEpoch 1/5:  27%|██▋       | 39/147 [00:35<01:34,  1.14it/s, loss=0.33]\u001b[A\nEpoch 1/5:  27%|██▋       | 39/147 [00:36<01:34,  1.14it/s, loss=0.437]\u001b[A\nEpoch 1/5:  27%|██▋       | 40/147 [00:36<01:33,  1.14it/s, loss=0.437]\u001b[A\nEpoch 1/5:  27%|██▋       | 40/147 [00:36<01:33,  1.14it/s, loss=0.399]\u001b[A\nEpoch 1/5:  28%|██▊       | 41/147 [00:36<01:32,  1.15it/s, loss=0.399]\u001b[A\nEpoch 1/5:  28%|██▊       | 41/147 [00:37<01:32,  1.15it/s, loss=0.34] \u001b[A\nEpoch 1/5:  29%|██▊       | 42/147 [00:37<01:31,  1.15it/s, loss=0.34]\u001b[A\nEpoch 1/5:  29%|██▊       | 42/147 [00:38<01:31,  1.15it/s, loss=0.32]\u001b[A\nEpoch 1/5:  29%|██▉       | 43/147 [00:38<01:29,  1.16it/s, loss=0.32]\u001b[A\nEpoch 1/5:  29%|██▉       | 43/147 [00:39<01:29,  1.16it/s, loss=0.262]\u001b[A\nEpoch 1/5:  30%|██▉       | 44/147 [00:39<01:28,  1.16it/s, loss=0.262]\u001b[A\nEpoch 1/5:  30%|██▉       | 44/147 [00:40<01:28,  1.16it/s, loss=0.334]\u001b[A\nEpoch 1/5:  31%|███       | 45/147 [00:40<01:27,  1.17it/s, loss=0.334]\u001b[A\nEpoch 1/5:  31%|███       | 45/147 [00:41<01:27,  1.17it/s, loss=0.327]\u001b[A\nEpoch 1/5:  31%|███▏      | 46/147 [00:41<01:26,  1.17it/s, loss=0.327]\u001b[A\nEpoch 1/5:  31%|███▏      | 46/147 [00:41<01:26,  1.17it/s, loss=0.405]\u001b[A\nEpoch 1/5:  32%|███▏      | 47/147 [00:41<01:24,  1.18it/s, loss=0.405]\u001b[A\nEpoch 1/5:  32%|███▏      | 47/147 [00:42<01:24,  1.18it/s, loss=0.302]\u001b[A\nEpoch 1/5:  33%|███▎      | 48/147 [00:42<01:23,  1.18it/s, loss=0.302]\u001b[A\nEpoch 1/5:  33%|███▎      | 48/147 [00:43<01:23,  1.18it/s, loss=0.379]\u001b[A\nEpoch 1/5:  33%|███▎      | 49/147 [00:43<01:23,  1.18it/s, loss=0.379]\u001b[A\nEpoch 1/5:  33%|███▎      | 49/147 [00:44<01:23,  1.18it/s, loss=0.37] \u001b[A\nEpoch 1/5:  34%|███▍      | 50/147 [00:44<01:21,  1.19it/s, loss=0.37]\u001b[A\nEpoch 1/5:  34%|███▍      | 50/147 [00:45<01:21,  1.19it/s, loss=0.369]\u001b[A\nEpoch 1/5:  35%|███▍      | 51/147 [00:45<01:20,  1.19it/s, loss=0.369]\u001b[A\nEpoch 1/5:  35%|███▍      | 51/147 [00:46<01:20,  1.19it/s, loss=0.391]\u001b[A\nEpoch 1/5:  35%|███▌      | 52/147 [00:46<01:19,  1.19it/s, loss=0.391]\u001b[A\nEpoch 1/5:  35%|███▌      | 52/147 [00:47<01:19,  1.19it/s, loss=0.292]\u001b[A\nEpoch 1/5:  36%|███▌      | 53/147 [00:47<01:18,  1.20it/s, loss=0.292]\u001b[A\nEpoch 1/5:  36%|███▌      | 53/147 [00:47<01:18,  1.20it/s, loss=0.484]\u001b[A\nEpoch 1/5:  37%|███▋      | 54/147 [00:47<01:17,  1.20it/s, loss=0.484]\u001b[A\nEpoch 1/5:  37%|███▋      | 54/147 [00:48<01:17,  1.20it/s, loss=0.328]\u001b[A\nEpoch 1/5:  37%|███▋      | 55/147 [00:48<01:16,  1.20it/s, loss=0.328]\u001b[A\nEpoch 1/5:  37%|███▋      | 55/147 [00:49<01:16,  1.20it/s, loss=0.263]\u001b[A\nEpoch 1/5:  38%|███▊      | 56/147 [00:49<01:15,  1.21it/s, loss=0.263]\u001b[A\nEpoch 1/5:  38%|███▊      | 56/147 [00:50<01:15,  1.21it/s, loss=0.32] \u001b[A\nEpoch 1/5:  39%|███▉      | 57/147 [00:50<01:14,  1.20it/s, loss=0.32]\u001b[A\nEpoch 1/5:  39%|███▉      | 57/147 [00:51<01:14,  1.20it/s, loss=0.362]\u001b[A\nEpoch 1/5:  39%|███▉      | 58/147 [00:51<01:13,  1.20it/s, loss=0.362]\u001b[A\nEpoch 1/5:  39%|███▉      | 58/147 [00:51<01:13,  1.20it/s, loss=0.276]\u001b[A\nEpoch 1/5:  40%|████      | 59/147 [00:51<01:12,  1.21it/s, loss=0.276]\u001b[A\nEpoch 1/5:  40%|████      | 59/147 [00:52<01:12,  1.21it/s, loss=0.294]\u001b[A\nEpoch 1/5:  41%|████      | 60/147 [00:52<01:12,  1.21it/s, loss=0.294]\u001b[A\nEpoch 1/5:  41%|████      | 60/147 [00:53<01:12,  1.21it/s, loss=0.315]\u001b[A\nEpoch 1/5:  41%|████▏     | 61/147 [00:53<01:11,  1.21it/s, loss=0.315]\u001b[A\nEpoch 1/5:  41%|████▏     | 61/147 [00:54<01:11,  1.21it/s, loss=0.361]\u001b[A\nEpoch 1/5:  42%|████▏     | 62/147 [00:54<01:10,  1.21it/s, loss=0.361]\u001b[A\nEpoch 1/5:  42%|████▏     | 62/147 [00:55<01:10,  1.21it/s, loss=0.327]\u001b[A\nEpoch 1/5:  43%|████▎     | 63/147 [00:55<01:08,  1.22it/s, loss=0.327]\u001b[A\nEpoch 1/5:  43%|████▎     | 63/147 [00:56<01:08,  1.22it/s, loss=0.394]\u001b[A\nEpoch 1/5:  44%|████▎     | 64/147 [00:56<01:08,  1.22it/s, loss=0.394]\u001b[A\nEpoch 1/5:  44%|████▎     | 64/147 [00:56<01:08,  1.22it/s, loss=0.29] \u001b[A\nEpoch 1/5:  44%|████▍     | 65/147 [00:56<01:07,  1.22it/s, loss=0.29]\u001b[A\nEpoch 1/5:  44%|████▍     | 65/147 [00:57<01:07,  1.22it/s, loss=0.268]\u001b[A\nEpoch 1/5:  45%|████▍     | 66/147 [00:57<01:06,  1.23it/s, loss=0.268]\u001b[A\nEpoch 1/5:  45%|████▍     | 66/147 [00:58<01:06,  1.23it/s, loss=0.338]\u001b[A\nEpoch 1/5:  46%|████▌     | 67/147 [00:58<01:05,  1.23it/s, loss=0.338]\u001b[A\nEpoch 1/5:  46%|████▌     | 67/147 [00:59<01:05,  1.23it/s, loss=0.258]\u001b[A\nEpoch 1/5:  46%|████▋     | 68/147 [00:59<01:04,  1.23it/s, loss=0.258]\u001b[A\nEpoch 1/5:  46%|████▋     | 68/147 [01:00<01:04,  1.23it/s, loss=0.282]\u001b[A\nEpoch 1/5:  47%|████▋     | 69/147 [01:00<01:03,  1.23it/s, loss=0.282]\u001b[A\nEpoch 1/5:  47%|████▋     | 69/147 [01:00<01:03,  1.23it/s, loss=0.401]\u001b[A\nEpoch 1/5:  48%|████▊     | 70/147 [01:00<01:02,  1.23it/s, loss=0.401]\u001b[A\nEpoch 1/5:  48%|████▊     | 70/147 [01:01<01:02,  1.23it/s, loss=0.29] \u001b[A\nEpoch 1/5:  48%|████▊     | 71/147 [01:01<01:01,  1.23it/s, loss=0.29]\u001b[A\nEpoch 1/5:  48%|████▊     | 71/147 [01:02<01:01,  1.23it/s, loss=0.22]\u001b[A\nEpoch 1/5:  49%|████▉     | 72/147 [01:02<01:00,  1.23it/s, loss=0.22]\u001b[A\nEpoch 1/5:  49%|████▉     | 72/147 [01:03<01:00,  1.23it/s, loss=0.252]\u001b[A\nEpoch 1/5:  50%|████▉     | 73/147 [01:03<00:59,  1.24it/s, loss=0.252]\u001b[A\nEpoch 1/5:  50%|████▉     | 73/147 [01:04<00:59,  1.24it/s, loss=0.335]\u001b[A\nEpoch 1/5:  50%|█████     | 74/147 [01:04<00:59,  1.23it/s, loss=0.335]\u001b[A\nEpoch 1/5:  50%|█████     | 74/147 [01:04<00:59,  1.23it/s, loss=0.236]\u001b[A\nEpoch 1/5:  51%|█████     | 75/147 [01:04<00:58,  1.24it/s, loss=0.236]\u001b[A\nEpoch 1/5:  51%|█████     | 75/147 [01:05<00:58,  1.24it/s, loss=0.215]\u001b[A\nEpoch 1/5:  52%|█████▏    | 76/147 [01:05<00:57,  1.24it/s, loss=0.215]\u001b[A\nEpoch 1/5:  52%|█████▏    | 76/147 [01:06<00:57,  1.24it/s, loss=0.395]\u001b[A\nEpoch 1/5:  52%|█████▏    | 77/147 [01:06<00:56,  1.23it/s, loss=0.395]\u001b[A\nEpoch 1/5:  52%|█████▏    | 77/147 [01:07<00:56,  1.23it/s, loss=0.23] \u001b[A\nEpoch 1/5:  53%|█████▎    | 78/147 [01:07<00:55,  1.24it/s, loss=0.23]\u001b[A\nEpoch 1/5:  53%|█████▎    | 78/147 [01:08<00:55,  1.24it/s, loss=0.338]\u001b[A\nEpoch 1/5:  54%|█████▎    | 79/147 [01:08<00:55,  1.24it/s, loss=0.338]\u001b[A\nEpoch 1/5:  54%|█████▎    | 79/147 [01:09<00:55,  1.24it/s, loss=0.452]\u001b[A\nEpoch 1/5:  54%|█████▍    | 80/147 [01:09<00:54,  1.23it/s, loss=0.452]\u001b[A\nEpoch 1/5:  54%|█████▍    | 80/147 [01:09<00:54,  1.23it/s, loss=0.298]\u001b[A\nEpoch 1/5:  55%|█████▌    | 81/147 [01:09<00:53,  1.23it/s, loss=0.298]\u001b[A\nEpoch 1/5:  55%|█████▌    | 81/147 [01:10<00:53,  1.23it/s, loss=0.352]\u001b[A\nEpoch 1/5:  56%|█████▌    | 82/147 [01:10<00:52,  1.23it/s, loss=0.352]\u001b[A\nEpoch 1/5:  56%|█████▌    | 82/147 [01:11<00:52,  1.23it/s, loss=0.325]\u001b[A\nEpoch 1/5:  56%|█████▋    | 83/147 [01:11<00:52,  1.23it/s, loss=0.325]\u001b[A\nEpoch 1/5:  56%|█████▋    | 83/147 [01:12<00:52,  1.23it/s, loss=0.274]\u001b[A\nEpoch 1/5:  57%|█████▋    | 84/147 [01:12<00:51,  1.23it/s, loss=0.274]\u001b[A\nEpoch 1/5:  57%|█████▋    | 84/147 [01:13<00:51,  1.23it/s, loss=0.387]\u001b[A\nEpoch 1/5:  58%|█████▊    | 85/147 [01:13<00:50,  1.23it/s, loss=0.387]\u001b[A\nEpoch 1/5:  58%|█████▊    | 85/147 [01:13<00:50,  1.23it/s, loss=0.234]\u001b[A\nEpoch 1/5:  59%|█████▊    | 86/147 [01:13<00:49,  1.23it/s, loss=0.234]\u001b[A\nEpoch 1/5:  59%|█████▊    | 86/147 [01:14<00:49,  1.23it/s, loss=0.283]\u001b[A\nEpoch 1/5:  59%|█████▉    | 87/147 [01:14<00:48,  1.23it/s, loss=0.283]\u001b[A\nEpoch 1/5:  59%|█████▉    | 87/147 [01:15<00:48,  1.23it/s, loss=0.347]\u001b[A\nEpoch 1/5:  60%|█████▉    | 88/147 [01:15<00:47,  1.23it/s, loss=0.347]\u001b[A\nEpoch 1/5:  60%|█████▉    | 88/147 [01:16<00:47,  1.23it/s, loss=0.229]\u001b[A\nEpoch 1/5:  61%|██████    | 89/147 [01:16<00:47,  1.23it/s, loss=0.229]\u001b[A\nEpoch 1/5:  61%|██████    | 89/147 [01:17<00:47,  1.23it/s, loss=0.395]\u001b[A\nEpoch 1/5:  61%|██████    | 90/147 [01:17<00:46,  1.23it/s, loss=0.395]\u001b[A\nEpoch 1/5:  61%|██████    | 90/147 [01:18<00:46,  1.23it/s, loss=0.249]\u001b[A\nEpoch 1/5:  62%|██████▏   | 91/147 [01:18<00:45,  1.22it/s, loss=0.249]\u001b[A\nEpoch 1/5:  62%|██████▏   | 91/147 [01:18<00:45,  1.22it/s, loss=0.272]\u001b[A\nEpoch 1/5:  63%|██████▎   | 92/147 [01:18<00:45,  1.22it/s, loss=0.272]\u001b[A\nEpoch 1/5:  63%|██████▎   | 92/147 [01:19<00:45,  1.22it/s, loss=0.275]\u001b[A\nEpoch 1/5:  63%|██████▎   | 93/147 [01:19<00:44,  1.22it/s, loss=0.275]\u001b[A\nEpoch 1/5:  63%|██████▎   | 93/147 [01:20<00:44,  1.22it/s, loss=0.255]\u001b[A\nEpoch 1/5:  64%|██████▍   | 94/147 [01:20<00:43,  1.22it/s, loss=0.255]\u001b[A\nEpoch 1/5:  64%|██████▍   | 94/147 [01:21<00:43,  1.22it/s, loss=0.251]\u001b[A\nEpoch 1/5:  65%|██████▍   | 95/147 [01:21<00:42,  1.23it/s, loss=0.251]\u001b[A\nEpoch 1/5:  65%|██████▍   | 95/147 [01:22<00:42,  1.23it/s, loss=0.265]\u001b[A\nEpoch 1/5:  65%|██████▌   | 96/147 [01:22<00:41,  1.22it/s, loss=0.265]\u001b[A\nEpoch 1/5:  65%|██████▌   | 96/147 [01:22<00:41,  1.22it/s, loss=0.358]\u001b[A\nEpoch 1/5:  66%|██████▌   | 97/147 [01:22<00:41,  1.22it/s, loss=0.358]\u001b[A\nEpoch 1/5:  66%|██████▌   | 97/147 [01:23<00:41,  1.22it/s, loss=0.239]\u001b[A\nEpoch 1/5:  67%|██████▋   | 98/147 [01:23<00:40,  1.21it/s, loss=0.239]\u001b[A\nEpoch 1/5:  67%|██████▋   | 98/147 [01:24<00:40,  1.21it/s, loss=0.228]\u001b[A\nEpoch 1/5:  67%|██████▋   | 99/147 [01:24<00:39,  1.21it/s, loss=0.228]\u001b[A\nEpoch 1/5:  67%|██████▋   | 99/147 [01:25<00:39,  1.21it/s, loss=0.347]\u001b[A\nEpoch 1/5:  68%|██████▊   | 100/147 [01:25<00:38,  1.21it/s, loss=0.347]\u001b[A\nEpoch 1/5:  68%|██████▊   | 100/147 [01:26<00:38,  1.21it/s, loss=0.364]\u001b[A\nEpoch 1/5:  69%|██████▊   | 101/147 [01:26<00:38,  1.21it/s, loss=0.364]\u001b[A\nEpoch 1/5:  69%|██████▊   | 101/147 [01:27<00:38,  1.21it/s, loss=0.272]\u001b[A\nEpoch 1/5:  69%|██████▉   | 102/147 [01:27<00:37,  1.21it/s, loss=0.272]\u001b[A\nEpoch 1/5:  69%|██████▉   | 102/147 [01:27<00:37,  1.21it/s, loss=0.29] \u001b[A\nEpoch 1/5:  70%|███████   | 103/147 [01:27<00:36,  1.20it/s, loss=0.29]\u001b[A\nEpoch 1/5:  70%|███████   | 103/147 [01:28<00:36,  1.20it/s, loss=0.267]\u001b[A\nEpoch 1/5:  71%|███████   | 104/147 [01:28<00:35,  1.20it/s, loss=0.267]\u001b[A\nEpoch 1/5:  71%|███████   | 104/147 [01:29<00:35,  1.20it/s, loss=0.23] \u001b[A\nEpoch 1/5:  71%|███████▏  | 105/147 [01:29<00:34,  1.20it/s, loss=0.23]\u001b[A\nEpoch 1/5:  71%|███████▏  | 105/147 [01:30<00:34,  1.20it/s, loss=0.242]\u001b[A\nEpoch 1/5:  72%|███████▏  | 106/147 [01:30<00:34,  1.20it/s, loss=0.242]\u001b[A\nEpoch 1/5:  72%|███████▏  | 106/147 [01:31<00:34,  1.20it/s, loss=0.286]\u001b[A\nEpoch 1/5:  73%|███████▎  | 107/147 [01:31<00:33,  1.20it/s, loss=0.286]\u001b[A\nEpoch 1/5:  73%|███████▎  | 107/147 [01:32<00:33,  1.20it/s, loss=0.279]\u001b[A\nEpoch 1/5:  73%|███████▎  | 108/147 [01:32<00:32,  1.20it/s, loss=0.279]\u001b[A\nEpoch 1/5:  73%|███████▎  | 108/147 [01:32<00:32,  1.20it/s, loss=0.301]\u001b[A\nEpoch 1/5:  74%|███████▍  | 109/147 [01:32<00:31,  1.20it/s, loss=0.301]\u001b[A\nEpoch 1/5:  74%|███████▍  | 109/147 [01:33<00:31,  1.20it/s, loss=0.241]\u001b[A\nEpoch 1/5:  75%|███████▍  | 110/147 [01:33<00:30,  1.20it/s, loss=0.241]\u001b[A\nEpoch 1/5:  75%|███████▍  | 110/147 [01:34<00:30,  1.20it/s, loss=0.275]\u001b[A\nEpoch 1/5:  76%|███████▌  | 111/147 [01:34<00:30,  1.20it/s, loss=0.275]\u001b[A\nEpoch 1/5:  76%|███████▌  | 111/147 [01:35<00:30,  1.20it/s, loss=0.244]\u001b[A\nEpoch 1/5:  76%|███████▌  | 112/147 [01:35<00:29,  1.20it/s, loss=0.244]\u001b[A\nEpoch 1/5:  76%|███████▌  | 112/147 [01:36<00:29,  1.20it/s, loss=0.181]\u001b[A\nEpoch 1/5:  77%|███████▋  | 113/147 [01:36<00:28,  1.20it/s, loss=0.181]\u001b[A\nEpoch 1/5:  77%|███████▋  | 113/147 [01:37<00:28,  1.20it/s, loss=0.326]\u001b[A\nEpoch 1/5:  78%|███████▊  | 114/147 [01:37<00:27,  1.19it/s, loss=0.326]\u001b[A\nEpoch 1/5:  78%|███████▊  | 114/147 [01:37<00:27,  1.19it/s, loss=0.267]\u001b[A\nEpoch 1/5:  78%|███████▊  | 115/147 [01:37<00:26,  1.20it/s, loss=0.267]\u001b[A\nEpoch 1/5:  78%|███████▊  | 115/147 [01:38<00:26,  1.20it/s, loss=0.347]\u001b[A\nEpoch 1/5:  79%|███████▉  | 116/147 [01:38<00:25,  1.20it/s, loss=0.347]\u001b[A\nEpoch 1/5:  79%|███████▉  | 116/147 [01:39<00:25,  1.20it/s, loss=0.18] \u001b[A\nEpoch 1/5:  80%|███████▉  | 117/147 [01:39<00:25,  1.20it/s, loss=0.18]\u001b[A\nEpoch 1/5:  80%|███████▉  | 117/147 [01:40<00:25,  1.20it/s, loss=0.184]\u001b[A\nEpoch 1/5:  80%|████████  | 118/147 [01:40<00:24,  1.20it/s, loss=0.184]\u001b[A\nEpoch 1/5:  80%|████████  | 118/147 [01:41<00:24,  1.20it/s, loss=0.253]\u001b[A\nEpoch 1/5:  81%|████████  | 119/147 [01:41<00:23,  1.19it/s, loss=0.253]\u001b[A\nEpoch 1/5:  81%|████████  | 119/147 [01:42<00:23,  1.19it/s, loss=0.235]\u001b[A\nEpoch 1/5:  82%|████████▏ | 120/147 [01:42<00:22,  1.19it/s, loss=0.235]\u001b[A\nEpoch 1/5:  82%|████████▏ | 120/147 [01:42<00:22,  1.19it/s, loss=0.226]\u001b[A\nEpoch 1/5:  82%|████████▏ | 121/147 [01:42<00:21,  1.19it/s, loss=0.226]\u001b[A\nEpoch 1/5:  82%|████████▏ | 121/147 [01:43<00:21,  1.19it/s, loss=0.281]\u001b[A\nEpoch 1/5:  83%|████████▎ | 122/147 [01:43<00:21,  1.19it/s, loss=0.281]\u001b[A\nEpoch 1/5:  83%|████████▎ | 122/147 [01:44<00:21,  1.19it/s, loss=0.222]\u001b[A\nEpoch 1/5:  84%|████████▎ | 123/147 [01:44<00:20,  1.18it/s, loss=0.222]\u001b[A\nEpoch 1/5:  84%|████████▎ | 123/147 [01:45<00:20,  1.18it/s, loss=0.303]\u001b[A\nEpoch 1/5:  84%|████████▍ | 124/147 [01:45<00:19,  1.18it/s, loss=0.303]\u001b[A\nEpoch 1/5:  84%|████████▍ | 124/147 [01:46<00:19,  1.18it/s, loss=0.249]\u001b[A\nEpoch 1/5:  85%|████████▌ | 125/147 [01:46<00:18,  1.18it/s, loss=0.249]\u001b[A\nEpoch 1/5:  85%|████████▌ | 125/147 [01:47<00:18,  1.18it/s, loss=0.281]\u001b[A\nEpoch 1/5:  86%|████████▌ | 126/147 [01:47<00:17,  1.18it/s, loss=0.281]\u001b[A\nEpoch 1/5:  86%|████████▌ | 126/147 [01:48<00:17,  1.18it/s, loss=0.229]\u001b[A\nEpoch 1/5:  86%|████████▋ | 127/147 [01:48<00:16,  1.18it/s, loss=0.229]\u001b[A\nEpoch 1/5:  86%|████████▋ | 127/147 [01:48<00:16,  1.18it/s, loss=0.284]\u001b[A\nEpoch 1/5:  87%|████████▋ | 128/147 [01:48<00:16,  1.18it/s, loss=0.284]\u001b[A\nEpoch 1/5:  87%|████████▋ | 128/147 [01:49<00:16,  1.18it/s, loss=0.217]\u001b[A\nEpoch 1/5:  88%|████████▊ | 129/147 [01:49<00:15,  1.18it/s, loss=0.217]\u001b[A\nEpoch 1/5:  88%|████████▊ | 129/147 [01:50<00:15,  1.18it/s, loss=0.286]\u001b[A\nEpoch 1/5:  88%|████████▊ | 130/147 [01:50<00:14,  1.18it/s, loss=0.286]\u001b[A\nEpoch 1/5:  88%|████████▊ | 130/147 [01:51<00:14,  1.18it/s, loss=0.215]\u001b[A\nEpoch 1/5:  89%|████████▉ | 131/147 [01:51<00:13,  1.18it/s, loss=0.215]\u001b[A\nEpoch 1/5:  89%|████████▉ | 131/147 [01:52<00:13,  1.18it/s, loss=0.274]\u001b[A\nEpoch 1/5:  90%|████████▉ | 132/147 [01:52<00:12,  1.18it/s, loss=0.274]\u001b[A\nEpoch 1/5:  90%|████████▉ | 132/147 [01:53<00:12,  1.18it/s, loss=0.27] \u001b[A\nEpoch 1/5:  90%|█████████ | 133/147 [01:53<00:11,  1.18it/s, loss=0.27]\u001b[A\nEpoch 1/5:  90%|█████████ | 133/147 [01:54<00:11,  1.18it/s, loss=0.284]\u001b[A\nEpoch 1/5:  91%|█████████ | 134/147 [01:54<00:11,  1.18it/s, loss=0.284]\u001b[A\nEpoch 1/5:  91%|█████████ | 134/147 [01:54<00:11,  1.18it/s, loss=0.286]\u001b[A\nEpoch 1/5:  92%|█████████▏| 135/147 [01:54<00:10,  1.18it/s, loss=0.286]\u001b[A\nEpoch 1/5:  92%|█████████▏| 135/147 [01:55<00:10,  1.18it/s, loss=0.301]\u001b[A\nEpoch 1/5:  93%|█████████▎| 136/147 [01:55<00:09,  1.18it/s, loss=0.301]\u001b[A\nEpoch 1/5:  93%|█████████▎| 136/147 [01:56<00:09,  1.18it/s, loss=0.218]\u001b[A\nEpoch 1/5:  93%|█████████▎| 137/147 [01:56<00:08,  1.18it/s, loss=0.218]\u001b[A\nEpoch 1/5:  93%|█████████▎| 137/147 [01:57<00:08,  1.18it/s, loss=0.235]\u001b[A\nEpoch 1/5:  94%|█████████▍| 138/147 [01:57<00:07,  1.18it/s, loss=0.235]\u001b[A\nEpoch 1/5:  94%|█████████▍| 138/147 [01:58<00:07,  1.18it/s, loss=0.277]\u001b[A\nEpoch 1/5:  95%|█████████▍| 139/147 [01:58<00:06,  1.18it/s, loss=0.277]\u001b[A\nEpoch 1/5:  95%|█████████▍| 139/147 [01:59<00:06,  1.18it/s, loss=0.228]\u001b[A\nEpoch 1/5:  95%|█████████▌| 140/147 [01:59<00:05,  1.18it/s, loss=0.228]\u001b[A\nEpoch 1/5:  95%|█████████▌| 140/147 [01:59<00:05,  1.18it/s, loss=0.179]\u001b[A\nEpoch 1/5:  96%|█████████▌| 141/147 [01:59<00:05,  1.18it/s, loss=0.179]\u001b[A\nEpoch 1/5:  96%|█████████▌| 141/147 [02:00<00:05,  1.18it/s, loss=0.209]\u001b[A\nEpoch 1/5:  97%|█████████▋| 142/147 [02:00<00:04,  1.18it/s, loss=0.209]\u001b[A\nEpoch 1/5:  97%|█████████▋| 142/147 [02:01<00:04,  1.18it/s, loss=0.214]\u001b[A\nEpoch 1/5:  97%|█████████▋| 143/147 [02:01<00:03,  1.18it/s, loss=0.214]\u001b[A\nEpoch 1/5:  97%|█████████▋| 143/147 [02:02<00:03,  1.18it/s, loss=0.211]\u001b[A\nEpoch 1/5:  98%|█████████▊| 144/147 [02:02<00:02,  1.19it/s, loss=0.211]\u001b[A\nEpoch 1/5:  98%|█████████▊| 144/147 [02:03<00:02,  1.19it/s, loss=0.277]\u001b[A\nEpoch 1/5:  99%|█████████▊| 145/147 [02:03<00:01,  1.18it/s, loss=0.277]\u001b[A\nEpoch 1/5:  99%|█████████▊| 145/147 [02:04<00:01,  1.18it/s, loss=0.14] \u001b[A\nEpoch 1/5:  99%|█████████▉| 146/147 [02:04<00:00,  1.18it/s, loss=0.14]\u001b[A\nEpoch 1/5:  99%|█████████▉| 146/147 [02:04<00:00,  1.18it/s, loss=0.209]\u001b[A\nEpoch 1/5: 100%|██████████| 147/147 [02:04<00:00,  1.43it/s, loss=0.209]\u001b[A\n                                                                        \u001b[A",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.3272\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Train Loss: 0.2000\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Train Loss: 0.1540\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.1182\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.0956\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 37/37 [00:10<00:00,  3.59it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n SciBERT Evaluation on Initial Dataset:\n       Category  Accuracy  Precision    Recall  F1 Score\n0    Category 1  0.969283   0.967078  0.995763  0.981211\n1    Category 2  0.914676   0.870968  0.964286  0.915254\n2    Category 3  0.976109   0.979866  0.973333  0.976589\n3    Category 4  0.907850   0.849057  0.891089  0.869565\n4    Category 5  0.982935   1.000000  0.545455  0.705882\n5    Category 6  0.989761   0.000000  0.000000  0.000000\n6    Category 7  0.989761   1.000000  0.812500  0.896552\n7    Category 8  0.928328   1.000000  0.086957  0.160000\n8    Category 9  0.931741   0.000000  0.000000  0.000000\n9   Category 10  0.955631   0.894737  0.790698  0.839506\n10  Category 11  0.955631   0.800000  0.250000  0.380952\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# On \"Synthetic\" only"
      ],
      "metadata": {
        "id": "_ThI8GeTM3II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --------------------- 1. Load Augmented Dataset ---------------------\n",
        "df = pd.read_excel(\"/kaggle/working/augmented_only_non-GPT_Responses.xlsx\")\n",
        "category_cols = [f\"Category {i}\" for i in range(1, 12)]\n",
        "\n",
        "X_texts = df[\"Responses\"].fillna(\"\").astype(str).tolist()\n",
        "Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "# --------------------- 2. Split (20/80) Train/Val ---------------------\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --------------------- 3. Custom Dataset ---------------------\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt')\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# --------------------- 4. Load SciBERT ---------------------\n",
        "model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(category_cols),\n",
        "    problem_type=\"multi_label_classification\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# --------------------- 5. DataLoaders ---------------------\n",
        "batch_size = 8\n",
        "\n",
        "train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# --------------------- 6. Optimizer & Loss ---------------------\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# --------------------- 7. Training Loop ---------------------\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = loss_fn(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# --------------------- 8. Evaluation ---------------------\n",
        "model.eval()\n",
        "all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).int()\n",
        "\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_probs.append(probs.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "Y_pred = torch.cat(all_preds).numpy()\n",
        "Y_prob = torch.cat(all_probs).numpy()\n",
        "Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "# --------------------- 9. Metrics ---------------------\n",
        "results = []\n",
        "for i, cat in enumerate(category_cols):\n",
        "    acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "    prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(\"\\n SciBERT Evaluation on Synthe Dataset:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-06T23:51:28.543721Z",
          "iopub.execute_input": "2025-08-06T23:51:28.543907Z",
          "iopub.status.idle": "2025-08-07T00:48:47.437058Z",
          "shell.execute_reply.started": "2025-08-06T23:51:28.543892Z",
          "shell.execute_reply": "2025-08-07T00:48:47.436262Z"
        },
        "id": "pSob6hhiM3IJ",
        "outputId": "3b5d2de1-dd22-4ca9-cb0e-011db0a41224"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.2058\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Train Loss: 0.0435\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Train Loss: 0.0193\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                          \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.0106\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                          \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.0087\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 201/201 [00:56<00:00,  3.54it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n SciBERT Evaluation on Synthe Dataset:\n       Category  Accuracy  Precision    Recall  F1 Score\n0    Category 1  0.998756   1.000000  0.998600  0.999300\n1    Category 2  0.998756   1.000000  0.997599  0.998798\n2    Category 3  0.990672   1.000000  0.984818  0.992351\n3    Category 4  0.988806   1.000000  0.964497  0.981928\n4    Category 5  0.999378   0.997685  1.000000  0.998841\n5    Category 6  0.963308   0.822289  1.000000  0.902479\n6    Category 7  0.998134   0.992832  0.996403  0.994614\n7    Category 8  0.998756   1.000000  0.993939  0.996960\n8    Category 9  1.000000   1.000000  1.000000  1.000000\n9   Category 10  0.984453   0.997831  0.950413  0.973545\n10  Category 11  0.986940   0.959302  1.000000  0.979228\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# On Merged = Original + Synthetic\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ksNiDuIVM3IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --------------------- 1. Load Augmented Dataset ---------------------\n",
        "df = pd.read_excel(\"/kaggle/working/augmented_merged_with_original.xlsx\")\n",
        "category_cols = [f\"Category {i}\" for i in range(1, 12)]\n",
        "\n",
        "X_texts = df[\"Responses\"].fillna(\"\").astype(str).tolist()\n",
        "Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "# --------------------- 2. Split (20/80) Train/Val ---------------------\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --------------------- 3. Custom Dataset ---------------------\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# --------------------- 4. Load SciBERT ---------------------\n",
        "model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(category_cols),\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# --------------------- 5. DataLoaders ---------------------\n",
        "batch_size = 8\n",
        "\n",
        "train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# --------------------- 6. Optimizer & Loss ---------------------\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# --------------------- 7. Training Loop ---------------------\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = loss_fn(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# --------------------- 8. Evaluation ---------------------\n",
        "model.eval()\n",
        "all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).int()\n",
        "\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_probs.append(probs.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "Y_pred = torch.cat(all_preds).numpy()\n",
        "Y_prob = torch.cat(all_probs).numpy()\n",
        "Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "# --------------------- 9. Metrics ---------------------\n",
        "results = []\n",
        "for i, cat in enumerate(category_cols):\n",
        "    acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "    prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "    results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(\"\\n SciBERT Evaluation on Initial Dataset:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:48:47.437826Z",
          "iopub.execute_input": "2025-08-07T00:48:47.438084Z",
          "iopub.status.idle": "2025-08-07T01:56:20.672280Z",
          "shell.execute_reply.started": "2025-08-07T00:48:47.438067Z",
          "shell.execute_reply": "2025-08-07T01:56:20.671473Z"
        },
        "id": "f5a2say_M3IK",
        "outputId": "1c1a799d-84e5-4cef-981c-a25a80673c54"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.1900\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Train Loss: 0.0426\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                          \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Train Loss: 0.0196\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                          \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.0104\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                          \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.0109\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 238/238 [01:07<00:00,  3.54it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n SciBERT Evaluation on Initial Dataset:\n       Category  Accuracy  Precision    Recall  F1 Score\n0    Category 1  0.990531   0.999392  0.989765  0.994555\n1    Category 2  0.995266   0.997923  0.992769  0.995339\n2    Category 3  0.994740   0.992864  0.998206  0.995528\n3    Category 4  0.994214   0.996558  0.984694  0.990590\n4    Category 5  1.000000   1.000000  1.000000  1.000000\n5    Category 6  0.999474   0.996528  1.000000  0.998261\n6    Category 7  0.997370   0.993266  0.989933  0.991597\n7    Category 8  0.994740   0.980000  0.991329  0.985632\n8    Category 9  0.995792   0.972028  1.000000  0.985816\n9   Category 10  0.990531   0.981884  0.985455  0.983666\n10  Category 11  0.995792   0.987705  0.995868  0.991770\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "XM7bZ7L0M3IL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "9gRydgaTM3IL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 2"
      ],
      "metadata": {
        "id": "0e5jGEiEM3IL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "rBgJrkoXM3IM"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}