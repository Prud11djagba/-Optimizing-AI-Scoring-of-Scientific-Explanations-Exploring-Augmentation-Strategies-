{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12704409,
          "sourceType": "datasetVersion",
          "datasetId": 8029271
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = \"/kaggle/input/electroscope-model-just-noimages-studentid1-xlsx/Electroscope_model_just_noimages_studentID(1).xlsx\"\n",
        "df = pd.read_excel(file_path, sheet_name=\"Original doc with scores\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-09T21:11:57.159979Z",
          "iopub.execute_input": "2025-08-09T21:11:57.160142Z",
          "iopub.status.idle": "2025-08-09T21:11:58.323161Z",
          "shell.execute_reply.started": "2025-08-09T21:11:57.160127Z",
          "shell.execute_reply": "2025-08-09T21:11:58.322536Z"
        },
        "id": "t4qkTOmKMjnE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = df[df[\"Justification\"].notna() & (df[\"Justification\"].str.strip() != \"\")]\n",
        "print(f\"{len(df) - len(df_cleaned)}\")\n",
        "print(len(df))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-09T21:12:15.705019Z",
          "iopub.execute_input": "2025-08-09T21:12:15.705702Z",
          "iopub.status.idle": "2025-08-09T21:12:15.725996Z",
          "shell.execute_reply.started": "2025-08-09T21:12:15.705657Z",
          "shell.execute_reply": "2025-08-09T21:12:15.725313Z"
        },
        "id": "lPyeFgcnMjnG",
        "outputId": "ddc1cf7f-b192-43af-de72-9e6e23e7740d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "128\n1151\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_cleaned"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-09T21:12:18.975335Z",
          "iopub.execute_input": "2025-08-09T21:12:18.976090Z",
          "iopub.status.idle": "2025-08-09T21:12:18.980260Z",
          "shell.execute_reply.started": "2025-08-09T21:12:18.976054Z",
          "shell.execute_reply": "2025-08-09T21:12:18.979420Z"
        },
        "id": "x7oz2DbRMjnG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# --------------------\n",
        "# 1. Setup\n",
        "# --------------------\n",
        "nltk.download('punkt')\n",
        "\n",
        "MODEL_PATH = \"allenai/scibert_scivocab_uncased\"\n",
        "CATEGORY_COLS = [f\"Category {i}\" for i in range(14, 22)]\n",
        "MIN_UNIT_LEN = 5  # Min words in a unit\n",
        "THRESHOLD = 0.5   # Multi-label prediction threshold\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
        "model.eval()\n",
        "\n",
        "def acquire_labels_multilabel(text):\n",
        "    \"\"\"Predict multi-label categories for the given text.\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "    probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n",
        "    return (probs >= THRESHOLD).astype(int)\n",
        "\n",
        "# --------------------\n",
        "# 3. Extract Units (EASE Step 1)\n",
        "# --------------------\n",
        "def extract_units_from_text(text):\n",
        "    if pd.isna(text) or len(str(text).strip()) < 15:\n",
        "        return []\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    units = [s.strip() for s in sentences if len(s.split()) >= MIN_UNIT_LEN]\n",
        "    return units\n",
        "\n",
        "# --------------------\n",
        "# 4. Augmentation (Full EASE)\n",
        "# --------------------\n",
        "def augment_categories_14_21(df):\n",
        "    print(\"Starting EASE data augmentation (multi-label)...\")\n",
        "\n",
        "    # Filter rows with justification & at least one non-null category\n",
        "    df_clean = df.dropna(subset=[\"Justification\"]).copy()\n",
        "    df_clean = df_clean[df_clean[CATEGORY_COLS].notna().any(axis=1)]\n",
        "\n",
        "    print(f\"Original dataset size: {len(df)}\")\n",
        "    print(f\"Filtered dataset size: {len(df_clean)}\")\n",
        "\n",
        "    augmented_rows =[]\n",
        "\n",
        "    for _, row in df_clean.iterrows():\n",
        "        units = extract_units_from_text(row[\"Justification\"])\n",
        "        for unit in units:\n",
        "            # Predict labels using fine-tuned model\n",
        "            predicted_labels = acquire_labels_multilabel(unit)\n",
        "\n",
        "            # Create augmented row\n",
        "            new_row = row.copy()\n",
        "            new_row[\"Justification\"] = unit\n",
        "            for col, label in zip(CATEGORY_COLS, predicted_labels):\n",
        "                new_row[col] = label\n",
        "\n",
        "            augmented_rows.append(new_row)\n",
        "\n",
        "    # Sift: limit over-augmentation\n",
        "    if len(augmented_rows) > len(df_clean) * 2:\n",
        "        augmented_rows = shuffle(augmented_rows, random_state=42)[:len(df_clean) * 2]\n",
        "\n",
        "    augmented_df = pd.DataFrame(augmented_rows)\n",
        "    merged_df = pd.concat([df_clean, augmented_df], ignore_index=True)\n",
        "\n",
        "    print(f\"Generated {len(augmented_df)} augmented samples\")\n",
        "    print(f\"Merged dataset size: {len(merged_df)}\")\n",
        "\n",
        "    augmented_df.to_csv(\"generated_augmented_data.csv\", index=False)\n",
        "    merged_df.to_csv(\"merged_dataset.csv\", index=False)\n",
        "\n",
        "    print(\"Saved:\")\n",
        "    print(\"- generated_augmented_data.csv (only augmented)\")\n",
        "    print(\"- merged_dataset.csv (original + augmented)\")\n",
        "\n",
        "    return augmented_df, merged_df\n",
        "\n",
        "# --------------------\n",
        "# 5. Run\n",
        "# --------------------\n",
        "generated_only, merged_data = augment_categories_14_21(df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-09T21:25:40.395268Z",
          "iopub.execute_input": "2025-08-09T21:25:40.395632Z",
          "iopub.status.idle": "2025-08-09T21:27:54.974145Z",
          "shell.execute_reply.started": "2025-08-09T21:25:40.395604Z",
          "shell.execute_reply": "2025-08-09T21:27:54.973355Z"
        },
        "colab": {
          "referenced_widgets": [
            "26c3b228c36547a2ba7cb305e2cf58cd",
            "722a2f0208b84857bc04bece7937483f",
            "17b4391c39084628926351e1970f99a5",
            "ecc273fa680b4fe8aeb580cb8b41595f"
          ]
        },
        "id": "3Mr-iEoPMjnI",
        "outputId": "6eff238b-faa0-4ca9-fb6b-a2ee8b8d1ffe"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26c3b228c36547a2ba7cb305e2cf58cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "722a2f0208b84857bc04bece7937483f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "2025-08-09 21:26:00.291146: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754774760.589046      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754774760.668371      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17b4391c39084628926351e1970f99a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecc273fa680b4fe8aeb580cb8b41595f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Starting EASE data augmentation (multi-label)...\nOriginal dataset size: 1023\nFiltered dataset size: 1023\nGenerated 1287 augmented samples\nMerged dataset size: 2310\nSaved:\n- generated_augmented_data.csv (only augmented)\n- merged_dataset.csv (original + augmented)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_dataset_with_scibert(df, dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Evaluate a dataset using SciBERT for Categories 14-21\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with 'Justification' column and Category 14-21 columns OR file path string\n",
        "        dataset_name: Name for display purposes\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"SciBERT Evaluation on {dataset_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # --------------------- 1. Load Data if needed ---------------------\n",
        "    # Check if df is a file path string\n",
        "    if isinstance(df, str):\n",
        "        print(f\"Loading dataset from: {df}\")\n",
        "        df = pd.read_csv(df)\n",
        "        print(f\"Dataset loaded successfully!\")\n",
        "\n",
        "    # --------------------- 2. Prepare Data ---------------------\n",
        "    category_cols = [f\"Category {i}\" for i in range(14, 22)]\n",
        "\n",
        "    # Use Justification column for SciBERT evaluation\n",
        "    X_texts = df[\"Justification\"].fillna(\"\").astype(str).tolist()\n",
        "    Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "    print(f\"Dataset size: {len(df)}\")\n",
        "    print(f\"Categories evaluated: {category_cols}\")\n",
        "\n",
        "    # Check for empty dataset\n",
        "    if len(X_texts) == 0:\n",
        "        print(f\"Warning: {dataset_name} is empty!\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # --------------------- 2. Split (20/80) Train/Val ---------------------\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Validation samples: {len(X_val)}\")\n",
        "\n",
        "    # --------------------- 3. Custom Dataset ---------------------\n",
        "    class MultiLabelDataset(Dataset):\n",
        "        def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "            self.texts = texts\n",
        "            self.labels = labels\n",
        "            self.tokenizer = tokenizer\n",
        "            self.max_length = max_length\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.texts)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            text = self.texts[idx]\n",
        "            label = self.labels[idx]\n",
        "            encoding = self.tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_length,\n",
        "                return_tensors='pt')\n",
        "            item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "            item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "            return item\n",
        "\n",
        "    # --------------------- 4. Load SciBERT ---------------------\n",
        "    model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        model_name,num_labels=len(category_cols),\n",
        "        problem_type=\"multi_label_classification\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # --------------------- 5. DataLoaders ---------------------\n",
        "    batch_size = 8\n",
        "\n",
        "    train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "    val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # --------------------- 6. Optimizer & Loss ---------------------\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # --------------------- 7. Training Loop ---------------------\n",
        "    epochs = 5\n",
        "    print(f\"\\nTraining for {epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "        for batch in loop:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = loss_fn(outputs.logits, labels)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # --------------------- 8. Evaluation ---------------------\n",
        "    print(\"Evaluating model...\")\n",
        "    model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).int()\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_probs.append(probs.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    Y_pred = torch.cat(all_preds).numpy()\n",
        "    Y_prob = torch.cat(all_probs).numpy()\n",
        "    Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "    # --------------------- 9. Metrics ---------------------\n",
        "    results = []\n",
        "    for i, cat in enumerate(category_cols):\n",
        "        acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "        prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "    results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "    results_df[\"Dataset\"] = dataset_name  # Add dataset identifier\n",
        "\n",
        "    print(f\"\\nSciBERT Evaluation Results for {dataset_name}:\")\n",
        "    print(results_df[[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]])\n",
        "\n",
        "    # Clear GPU memory\n",
        "    del model, optimizer, train_dataset, val_dataset\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    return results_df\n",
        "\n",
        "results = evaluate_dataset_with_scibert(\"/kaggle/working/merged_dataset.csv\", \"Merged Dataset\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-09T21:30:59.135701Z",
          "iopub.execute_input": "2025-08-09T21:30:59.136467Z",
          "iopub.status.idle": "2025-08-09T21:46:19.370759Z",
          "shell.execute_reply.started": "2025-08-09T21:30:59.136428Z",
          "shell.execute_reply": "2025-08-09T21:46:19.369941Z"
        },
        "id": "wqmPSIH_MjnJ",
        "outputId": "8a1eb7c4-90ab-498f-be33-a42b917f70f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n============================================================\nSciBERT Evaluation on Merged Dataset\n============================================================\nLoading dataset from: /kaggle/working/merged_dataset.csv\nDataset loaded successfully!\nDataset size: 2310\nCategories evaluated: ['Category 14', 'Category 15', 'Category 16', 'Category 17', 'Category 18', 'Category 19', 'Category 20', 'Category 21']\nTraining samples: 1848\nValidation samples: 462\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Using device: cuda\n\nTraining for 5 epochs...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.3298\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Train Loss: 0.2245\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Train Loss: 0.1701\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.1296\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.1054\nEvaluating model...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 58/58 [00:14<00:00,  3.89it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nSciBERT Evaluation Results for Merged Dataset:\n      Category  Accuracy  Precision    Recall  F1 Score\n0  Category 14  0.846320   0.500000  0.338028  0.403361\n1  Category 15  0.909091   0.357143  0.131579  0.192308\n2  Category 16  0.922078   0.831169  0.735632  0.780488\n3  Category 17  0.952381   0.966667  0.580000  0.725000\n4  Category 18  0.974026   0.888889  0.727273  0.800000\n5  Category 19  0.980519   0.850000  0.918919  0.883117\n6  Category 20  0.976190   0.951456  0.942308  0.946860\n7  Category 21  0.939394   0.694118  0.967213  0.808219\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_dataset_with_scibert(df, dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Evaluate a dataset using SciBERT for Categories 14-21\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with 'Justification' column and Category 14-21 columns OR file path string\n",
        "        dataset_name: Name for display purposes\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"SciBERT Evaluation on {dataset_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # --------------------- 1. Load Data if needed ---------------------\n",
        "    # Check if df is a file path string\n",
        "    if isinstance(df, str):\n",
        "        print(f\"Loading dataset from: {df}\")\n",
        "        df = pd.read_csv(df)\n",
        "        print(f\"Dataset loaded successfully!\")\n",
        "\n",
        "    # --------------------- 2. Prepare Data ---------------------\n",
        "    category_cols = [f\"Category {i}\" for i in range(14, 22)]\n",
        "\n",
        "    # Use Justification column for SciBERT evaluation\n",
        "    X_texts = df[\"Justification\"].fillna(\"\").astype(str).tolist()\n",
        "    Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "    print(f\"Dataset size: {len(df)}\")\n",
        "    print(f\"Categories evaluated: {category_cols}\")\n",
        "\n",
        "    # Check for empty dataset\n",
        "    if len(X_texts) == 0:\n",
        "        print(f\"Warning: {dataset_name} is empty!\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # --------------------- 2. Split (20/80) Train/Val ---------------------\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Validation samples: {len(X_val)}\")\n",
        "\n",
        "    # --------------------- 3. Custom Dataset ---------------------\n",
        "    class MultiLabelDataset(Dataset):\n",
        "        def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "            self.texts = texts\n",
        "            self.labels = labels\n",
        "            self.tokenizer = tokenizer\n",
        "            self.max_length = max_length\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.texts)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            text = self.texts[idx]\n",
        "            label = self.labels[idx]\n",
        "            encoding = self.tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_length,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "            item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "            return item\n",
        "\n",
        "    # --------------------- 4. Load SciBERT ---------------------\n",
        "    model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        model_name,num_labels=len(category_cols),\n",
        "        problem_type=\"multi_label_classification\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # --------------------- 5. DataLoaders ---------------------\n",
        "    batch_size = 8\n",
        "\n",
        "    train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "    val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # --------------------- 6. Optimizer & Loss ---------------------\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # --------------------- 7. Training Loop ---------------------\n",
        "    epochs = 5\n",
        "    print(f\"\\nTraining for {epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "        for batch in loop:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = loss_fn(outputs.logits, labels)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # --------------------- 8. Evaluation ---------------------\n",
        "    print(\"Evaluating model...\")\n",
        "    model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).int()\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_probs.append(probs.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    Y_pred = torch.cat(all_preds).numpy()\n",
        "    Y_prob = torch.cat(all_probs).numpy()\n",
        "    Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "    # --------------------- 9. Metrics ---------------------\n",
        "    results = []\n",
        "    for i, cat in enumerate(category_cols):\n",
        "        acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "        prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "    results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "    results_df[\"Dataset\"] = dataset_name  # Add dataset identifier\n",
        "\n",
        "    print(f\"\\nSciBERT Evaluation Results for {dataset_name}:\")\n",
        "    print(results_df[[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]])\n",
        "\n",
        "    # Clear GPU memory\n",
        "    del model, optimizer, train_dataset, val_dataset\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    return results_df\n",
        "\n",
        "results = evaluate_dataset_with_scibert(\"/kaggle/working/generated_augmented_data.csv\", \"Generated Dataset\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-09T21:51:17.764752Z",
          "iopub.execute_input": "2025-08-09T21:51:17.765035Z",
          "iopub.status.idle": "2025-08-09T21:59:56.292693Z",
          "shell.execute_reply.started": "2025-08-09T21:51:17.765015Z",
          "shell.execute_reply": "2025-08-09T21:59:56.291799Z"
        },
        "id": "t4lUCPtJMjnK",
        "outputId": "d3872e60-3ec9-4962-f357-e7621443ba4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n============================================================\nSciBERT Evaluation on Generated Dataset\n============================================================\nLoading dataset from: /kaggle/working/generated_augmented_data.csv\nDataset loaded successfully!\nDataset size: 1287\nCategories evaluated: ['Category 14', 'Category 15', 'Category 16', 'Category 17', 'Category 18', 'Category 19', 'Category 20', 'Category 21']\nTraining samples: 1029\nValidation samples: 258\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Using device: cuda\n\nTraining for 5 epochs...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.3249\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Train Loss: 0.2272\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Train Loss: 0.1743\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.1391\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.1043\nEvaluating model...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 33/33 [00:08<00:00,  4.02it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nSciBERT Evaluation Results for Generated Dataset:\n      Category  Accuracy  Precision    Recall  F1 Score\n0  Category 14  0.996124   1.000000  0.500000  0.666667\n1  Category 15  0.957364   0.750000  0.230769  0.352941\n2  Category 16  0.810078   0.666667  0.579710  0.620155\n3  Category 17  0.891473   0.720000  0.461538  0.562500\n4  Category 18  0.930233   0.588235  0.476190  0.526316\n5  Category 19  0.922481   0.520000  0.619048  0.565217\n6  Category 20  0.934109   0.836735  0.820000  0.828283\n7  Category 21  0.864341   0.636364  0.184211  0.285714\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_dataset_with_scibert(df, dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Evaluate a dataset using SciBERT for Categories 14-21\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with 'Justification' column and Category 14-21 columns OR file path string\n",
        "        dataset_name: Name for display purposes\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"SciBERT Evaluation on {dataset_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # --------------------- 1. Load Data if needed ---------------------\n",
        "    # Check if df is a file path string\n",
        "    if isinstance(df, str):\n",
        "        print(f\"Loading dataset from: {df}\")\n",
        "        df = pd.read_csv(df)\n",
        "        print(f\"Dataset loaded successfully!\")\n",
        "\n",
        "    # --------------------- 2. Prepare Data ---------------------\n",
        "    category_cols = [f\"Category {i}\" for i in range(14, 22)]\n",
        "\n",
        "    # Use Justification column for SciBERT evaluation\n",
        "    X_texts = df[\"Justification\"].fillna(\"\").astype(str).tolist()\n",
        "    Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "    print(f\"Dataset size: {len(df)}\")\n",
        "    print(f\"Categories evaluated: {category_cols}\")\n",
        "\n",
        "    # Check for empty dataset\n",
        "    if len(X_texts) == 0:\n",
        "        print(f\"Warning: {dataset_name} is empty!\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # --------------------- 2. Split (20/80) Train/Val ---------------------\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Validation samples: {len(X_val)}\")\n",
        "\n",
        "    # --------------------- 3. Custom Dataset ---------------------\n",
        "    class MultiLabelDataset(Dataset):\n",
        "        def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "            self.texts = texts\n",
        "            self.labels = labels\n",
        "            self.tokenizer = tokenizer\n",
        "            self.max_length = max_length\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.texts)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            text = self.texts[idx]\n",
        "            label = self.labels[idx]\n",
        "            encoding = self.tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_length,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "            item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "            return item\n",
        "\n",
        "    # --------------------- 4. Load SciBERT ---------------------\n",
        "    model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=len(category_cols),\n",
        "        problem_type=\"multi_label_classification\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # --------------------- 5. DataLoaders ---------------------\n",
        "    batch_size = 8\n",
        "\n",
        "    train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "    val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # --------------------- 6. Optimizer & Loss ---------------------\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # --------------------- 7. Training Loop ---------------------\n",
        "    epochs = 5\n",
        "    print(f\"\\nTraining for {epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "        for batch in loop:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = loss_fn(outputs.logits, labels)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # --------------------- 8. Evaluation ---------------------\n",
        "    print(\"Evaluating model...\")\n",
        "    model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).int()\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_probs.append(probs.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    Y_pred = torch.cat(all_preds).numpy()\n",
        "    Y_prob = torch.cat(all_probs).numpy()\n",
        "    Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "    # --------------------- 9. Metrics ---------------------\n",
        "    results = []\n",
        "    for i, cat in enumerate(category_cols):\n",
        "        acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "        prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "    results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "    results_df[\"Dataset\"] = dataset_name  # Add dataset identifier\n",
        "\n",
        "    print(f\"\\nSciBERT Evaluation Results for {dataset_name}:\")\n",
        "    print(results_df[[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]])\n",
        "\n",
        "    # Clear GPU memory\n",
        "    del model, optimizer, train_dataset, val_dataset\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    return results_df\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def compare_all_datasets(initial_df, generated_df, merged_df):\n",
        "    \"\"\"\n",
        "    Compare SciBERT performance across all three datasets and plot graphs\n",
        "    \"\"\"\n",
        "    print(\"Starting SciBERT evaluation...\")\n",
        "    print(\"Initial → Generated → Merged datasets\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # Evaluate Initial Dataset\n",
        "    if len(initial_df) > 0:\n",
        "        initial_results = evaluate_dataset_with_scibert(initial_df, \"Initial Dataset\")\n",
        "        all_results.append(initial_results)\n",
        "\n",
        "    # Evaluate Generated Dataset\n",
        "    if len(generated_df) > 0:\n",
        "        generated_results = evaluate_dataset_with_scibert(generated_df, \"Generated Dataset\")\n",
        "        all_results.append(generated_results)\n",
        "\n",
        "    # Evaluate Merged Dataset\n",
        "    if len(merged_df) > 0:\n",
        "        merged_results = evaluate_dataset_with_scibert(merged_df, \"Merged Dataset\")\n",
        "        all_results.append(merged_results)\n",
        "\n",
        "    # Combine all results for comparison\n",
        "    if all_results:\n",
        "        comparison_df = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "        # Pivot for easier comparison\n",
        "        comparison_pivot = comparison_df.pivot_table(\n",
        "            index='Category',\n",
        "            columns='Dataset',\n",
        "            values=['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
        "            aggfunc='first')\n",
        "\n",
        "        # Plot F1 score comparison\n",
        "        if 'F1 Score' in comparison_pivot.columns.levels[0]:\n",
        "            f1_scores = comparison_pivot['F1 Score']\n",
        "            f1_scores.plot(kind='bar', figsize=(12,6))\n",
        "            plt.title(\"F1 Score Comparison Across Datasets\")\n",
        "            plt.ylabel(\"F1 Score\")\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            plt.legend(title=\"Dataset\")\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(\"f1_score_comparison.png\")\n",
        "            plt.show()\n",
        "\n",
        "        # Plot Accuracy comparison\n",
        "        if 'Accuracy' in comparison_pivot.columns.levels[0]:\n",
        "            acc_scores = comparison_pivot['Accuracy']\n",
        "            acc_scores.plot(kind='bar', figsize=(12,6))\n",
        "            plt.title(\"Accuracy Comparison Across Datasets\")\n",
        "            plt.ylabel(\"Accuracy\")\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            plt.legend(title=\"Dataset\")\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(\"accuracy_comparison.png\")\n",
        "            plt.show()\n",
        "\n",
        "        # Save results table\n",
        "        comparison_df.to_csv('scibert_evaluation_results.csv', index=False)\n",
        "        print(f\"\\nResults saved to 'scibert_evaluation_results.csv'\")\n",
        "        print(\"Graphs saved as 'f1_score_comparison.png' and 'accuracy_comparison.png'\")\n",
        "\n",
        "        return comparison_df\n",
        "\n",
        "    return pd.DataFrame()\n",
        "\n",
        "generated_df = pd.read_csv(\"/kaggle/working/generated_augmented_data.csv\")\n",
        "merged_df = pd.read_csv(\"/kaggle/working/merged_dataset.csv\")\n",
        "comparison = compare_all_datasets(df, generated_df, merged_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-09T22:25:04.436905Z",
          "iopub.execute_input": "2025-08-09T22:25:04.437230Z",
          "iopub.status.idle": "2025-08-09T22:56:01.195578Z",
          "shell.execute_reply.started": "2025-08-09T22:25:04.437208Z",
          "shell.execute_reply": "2025-08-09T22:56:01.194849Z"
        },
        "id": "M8ubrtG-MjnK",
        "outputId": "4afbbfad-a11b-4274-db4f-f45d95e32e2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Starting SciBERT evaluation...\nInitial → Generated → Merged datasets\n\n============================================================\nSciBERT Evaluation on Initial Dataset\n============================================================\nDataset size: 1023\nCategories evaluated: ['Category 14', 'Category 15', 'Category 16', 'Category 17', 'Category 18', 'Category 19', 'Category 20', 'Category 21']\nTraining samples: 818\nValidation samples: 205\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Using device: cuda\n\nTraining for 5 epochs...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.3903\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Train Loss: 0.2442\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Train Loss: 0.1737\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.1327\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.1003\nEvaluating model...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 26/26 [00:06<00:00,  3.99it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nSciBERT Evaluation Results for Initial Dataset:\n      Category  Accuracy  Precision    Recall  F1 Score\n0  Category 14  0.892683   0.759036  0.969231  0.851351\n1  Category 15  0.960976   0.766667  0.958333  0.851852\n2  Category 16  0.878049   0.647059  0.825000  0.725275\n3  Category 17  0.931707   0.000000  0.000000  0.000000\n4  Category 18  0.960976   1.000000  0.272727  0.428571\n5  Category 19  0.941463   0.545455  0.461538  0.500000\n6  Category 20  0.956098   0.897959  0.916667  0.907216\n7  Category 21  0.902439   0.789474  0.483871  0.600000\n\n============================================================\nSciBERT Evaluation on Generated Dataset\n============================================================\nDataset size: 1287\nCategories evaluated: ['Category 14', 'Category 15', 'Category 16', 'Category 17', 'Category 18', 'Category 19', 'Category 20', 'Category 21']\nTraining samples: 1029\nValidation samples: 258\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Using device: cuda\n\nTraining for 5 epochs...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.3214\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Train Loss: 0.2255\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Train Loss: 0.1803\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.1430\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.1053\nEvaluating model...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 33/33 [00:08<00:00,  4.03it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nSciBERT Evaluation Results for Generated Dataset:\n      Category  Accuracy  Precision    Recall  F1 Score\n0  Category 14  0.996124   1.000000  0.500000  0.666667\n1  Category 15  0.961240   1.000000  0.230769  0.375000\n2  Category 16  0.759690   0.534653  0.782609  0.635294\n3  Category 17  0.891473   0.720000  0.461538  0.562500\n4  Category 18  0.953488   0.764706  0.619048  0.684211\n5  Category 19  0.934109   0.600000  0.571429  0.585366\n6  Category 20  0.949612   0.849057  0.900000  0.873786\n7  Category 21  0.875969   1.000000  0.157895  0.272727\n\n============================================================\nSciBERT Evaluation on Merged Dataset\n============================================================\nDataset size: 2310\nCategories evaluated: ['Category 14', 'Category 15', 'Category 16', 'Category 17', 'Category 18', 'Category 19', 'Category 20', 'Category 21']\nTraining samples: 1848\nValidation samples: 462\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Using device: cuda\n\nTraining for 5 epochs...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.3270\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Train Loss: 0.2129\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Train Loss: 0.1597\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.1212\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.0977\nEvaluating model...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 58/58 [00:14<00:00,  3.96it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nSciBERT Evaluation Results for Merged Dataset:\n      Category  Accuracy  Precision    Recall  F1 Score\n0  Category 14  0.824675   0.421875  0.380282  0.400000\n1  Category 15  0.885281   0.258065  0.210526  0.231884\n2  Category 16  0.906926   0.750000  0.758621  0.754286\n3  Category 17  0.932900   0.672727  0.740000  0.704762\n4  Category 18  0.967532   0.750000  0.818182  0.782609\n5  Category 19  0.974026   0.903226  0.756757  0.823529\n6  Category 20  0.969697   0.950000  0.913462  0.931373\n7  Category 21  0.932900   0.666667  0.983607  0.794702\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x600 with 1 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACBuUlEQVR4nOzdd1yV5f/H8fcBZImAAwUVBfdeWGruHGhqavbV1MqRmqllmpo2nCWZZo5M03JUlpaz3CNHuXducyCW4lbEAcq5f3/44+QJNI7BfRRez8eDR577vu7r/pzDh/Xuuu9jMQzDEAAAAAAAAGAiF2cXAAAAAAAAgIyHUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAMBEISEhat++vbPLAAAAcDpCKQAAHsL06dNlsViS/ejfv79t3IoVK/TKK6+oVKlScnV1VUhIiEPniY2N1aBBg1SqVCllzpxZ2bNnV7ly5dSzZ0+dPn06lZ+VOc6ePas+ffqoWLFi8vb2VubMmRUWFqYPPvhAV65ccXZ5+H8tW7aUxWLR22+/7exS0sy9X7dubm7Kli2bwsLC1LNnTx04cOCh571x44YGDx6stWvXpl6x/8HGjRs1ePBgvr4AAI8ci2EYhrOLAADgcTN9+nR16NBBQ4cOVWhoqN2+UqVKqVy5cpKk9u3ba/bs2apQoYKioqLk6uqqyMjIFJ3j9u3bqlSpkg4dOqR27dqpXLlyio2N1f79+/Xzzz/rxx9/VK1atVL3iaWxbdu26ZlnnlFsbKxefPFFhYWFSZK2b9+uWbNm6amnntKKFSucXGXaiouLk4uLizJlyuTsUu4rJiZGuXLlUmBgoBISEnTy5ElZLBZnl5XqLBaL6tWrp5dfflmGYejq1avas2ePfvzxR12/fl0jRoxQ7969HZ73woULCggI0KBBgzR48ODUL9xBo0aNUt++fXXixAmHg3EAANKSm7MLAADgcdawYUNVrFjxvvuHDx+uKVOmKFOmTGrcuLH27duX4rkXLFigXbt2aebMmWrTpo3dvlu3bik+Pv6h63bU9evXlTlz5v80x5UrV9S8eXO5urpq165dKlasmN3+Dz/8UFOmTPlP53hUGYahW7duycvLSx4eHs4u51/NnTtXCQkJmjp1qp5++mmtX79eNWvWTJW5U6OXUlORIkX04osv2m376KOP1KRJE7311lsqVqyYnnnmGSdVBwBA+sblewAApKHcuXM/9IqYY8eOSZKqVq2aZJ+np6d8fX3tth06dEgtW7ZUQECAvLy8VLRoUb377rt2Y3bt2qWGDRvK19dXPj4+qlOnjjZv3mw3JvHSxHXr1qlbt27KmTOn8ubNa9u/dOlSVa9eXZkzZ1aWLFnUqFEj7d+//1+fzxdffKG//vpLo0ePThJISVKuXLn03nvv2W37/PPPVbJkSXl4eCh37tzq3r17kkuQatWqpVKlSun3339XzZo15e3trUKFCmnOnDmSpHXr1qlSpUq212TVqlV2xw8ePFgWi8X2+vn6+ip79uzq2bOnbt26ZTd22rRpevrpp5UzZ055eHioRIkSmjhxYpLnEhISosaNG2v58uWqWLGivLy89MUXX9j23XtPqdu3b2vIkCEqXLiwPD09lT17dlWrVk0rV660m/OXX36xve7+/v5q2rSpDh48mOxzOXr0qNq3by9/f3/5+fmpQ4cOunHjRjKfleTNnDlT9erVU+3atVW8eHHNnDkz2XH/1nOJ9Rw4cEBt2rRR1qxZVa1aNUnSnTt3NGzYMBUsWFAeHh4KCQnRO++8o7i4OLtzbN++XeHh4cqRI4e8vLwUGhqqjh072o2ZNWuWwsLClCVLFvn6+qp06dIaO3Zsip/vP2XPnl2zZs2Sm5ubPvzwQ9v2+Ph4DRw4UGFhYfLz81PmzJlVvXp1rVmzxjYmMjJSAQEBkqQhQ4bYLg9MXDH1+++/q3379ipQoIA8PT0VGBiojh076uLFi3Y1XLt2TW+++aZCQkLk4eGhnDlzql69etq5c6fduC1btqhBgwby8/OTt7e3atasqQ0bNtj2Dx48WH379pUkhYaG2upJXLG5cuVKVatWTf7+/vLx8VHRokX1zjvvPPRrBwCAI1gpBQDAf3D16lVduHDBbluOHDlSZe78+fNLkr7++mu99957D7x86vfff1f16tWVKVMmdenSRSEhITp27Jh+/vln2x/V+/fvV/Xq1eXr66t+/fopU6ZM+uKLL1SrVi1bcHOvbt26KSAgQAMHDtT169clSd98843atWun8PBwjRgxQjdu3NDEiRNVrVo17dq164GXBv3000/y8vLS888/n6LnP3jwYA0ZMkR169bVa6+9psOHD2vixInatm2bNmzYYBf2Xb58WY0bN9YLL7yg//3vf5o4caJeeOEFzZw5U2+++aa6du2qNm3aaOTIkXr++ed16tQpZcmSxe58LVu2VEhIiCIiIrR582aNGzdOly9f1tdff20bM3HiRJUsWVLPPvus3Nzc9PPPP6tbt26yWq3q3r273XyHDx9W69at9eqrr6pz584qWrTofZ9nRESEOnXqpCeffFIxMTHavn27du7cqXr16kmSVq1apYYNG6pAgQIaPHiwbt68qfHjx6tq1arauXNnkte9ZcuWCg0NVUREhHbu3Kkvv/xSOXPm1IgRI/71dT99+rTWrFmjGTNmSJJat26tTz/9VJ999pnc3d1t41LSc4n+97//qXDhwho+fLgS7xzRqVMnzZgxQ88//7zeeustbdmyRRERETp48KDmz58vSTp37pzq16+vgIAA9e/fX/7+/oqMjNS8efNsc69cuVKtW7dWnTp1bM/v4MGD2rBhg3r27Pmvz/d+8uXLp5o1a2rNmjWKiYmRr6+vYmJi9OWXX6p169bq3Lmzrl27pq+++krh4eHaunWrypUrp4CAAE2cOFGvvfaamjdvrueee06SVKZMGVu9x48fV4cOHRQYGKj9+/dr8uTJ2r9/vzZv3mz7Ou/atavmzJmjHj16qESJErp48aJ+++03HTx4UBUqVJB0N6hs2LChwsLCNGjQILm4uNiC019//VVPPvmknnvuOR05ckTff/+9Pv30U9v3p4CAAO3fv1+NGzdWmTJlNHToUHl4eOjo0aN2oRYAAGnKAAAADps2bZohKdmP+2nUqJGRP3/+FJ/jxo0bRtGiRQ1JRv78+Y327dsbX331lXH27NkkY2vUqGFkyZLFOHnypN12q9Vq+3ezZs0Md3d349ixY7Ztp0+fNrJkyWLUqFEjyXOrVq2acefOHdv2a9euGf7+/kbnzp3tzhEdHW34+fkl2f5PWbNmNcqWLZui537u3DnD3d3dqF+/vpGQkGDb/tlnnxmSjKlTp9q21axZ05BkfPfdd7Zthw4dMiQZLi4uxubNm23bly9fbkgypk2bZts2aNAgQ5Lx7LPP2tXQrVs3Q5KxZ88e27YbN24kqTU8PNwoUKCA3bb8+fMbkoxly5YlGZ8/f36jXbt2tsdly5Y1GjVq9IBXwzDKlStn5MyZ07h48aJt2549ewwXFxfj5ZdfTvJcOnbsaHd88+bNjezZsz/wHIlGjRpleHl5GTExMYZhGMaRI0cMScb8+fPtxqWk5xLrad26td2Y3bt3G5KMTp062W3v06ePIcn45ZdfDMMwjPnz5xuSjG3btt233p49exq+vr52vZpSkozu3bs/cO57e+DOnTtGXFyc3ZjLly8buXLlsnvNz58/b0gyBg0alGTO5Hro+++/NyQZ69evt23z8/N7YG1Wq9UoXLiwER4ebvea37hxwwgNDTXq1atn2zZy5EhDknHixAm7OT799FNDknH+/Pn7ngcAgLTE5XsAAPwHEyZM0MqVK+0+UouXl5e2bNliu/Rm+vTpeuWVVxQUFKTXX3/ddpnT+fPntX79enXs2FH58uWzmyNx1UVCQoJWrFihZs2aqUCBArb9QUFBatOmjX777TfFxMTYHdu5c2e5urraHq9cuVJXrlxR69atdeHCBduHq6urKlWqZHcJU3JiYmKSrE66n1WrVik+Pl5vvvmmXFz+/nWlc+fO8vX11eLFi+3G+/j46IUXXrA9Llq0qPz9/VW8eHG7FWCJ/z5+/HiSc/5zpdPrr78uSVqyZIltm5eXl+3fiavkatasqePHj+vq1at2x4eGhio8PPxfn6u/v7/279+vP/74I9n9Z86c0e7du9W+fXtly5bNtr1MmTKqV6+eXX2Junbtave4evXqunjxYpLPcXJmzpypRo0a2T5XhQsXVlhYmN0lfCnpuQfVk1jzP28i/tZbb0mS7fPr7+8vSVq0aJFu376dbL3+/v66fv16qn7tJfLx8ZF091I6SXJ1dbWtFrNarbp06ZLu3LmjihUrJrms7n7u7aFbt27pwoULqly5siTZzeHv768tW7bc9102d+/erT/++ENt2rTRxYsXbV+P169fV506dbR+/XpZrdYH1pL4+i5cuPBfxwIAkBYIpQAA+A+efPJJ1a1b1+4jNfn5+enjjz9WZGSkIiMj9dVXX6lo0aL67LPPNGzYMEl/ByylSpW67zznz5/XjRs3kr2ErHjx4rJarTp16pTd9n++q2BiaPL0008rICDA7mPFihU6d+7cA5+Lr6+v7Y/7f3Py5ElJSlKvu7u7ChQoYNufKG/evEnCED8/PwUHByfZJt293O+fChcubPe4YMGCcnFxsXu3xA0bNqhu3bq2+zoFBATY7r+TXCiVEkOHDtWVK1dUpEgRlS5dWn379tXvv/9u23+/10K6+7lLDCLu9c+gKGvWrJKSf973OnjwoHbt2qWqVavq6NGjto9atWpp0aJFtlArJT13r3++FidPnpSLi4sKFSpktz0wMFD+/v6251yzZk21aNFCQ4YMUY4cOdS0aVNNmzbN7r5T3bp1U5EiRdSwYUPlzZtXHTt21LJly1JU17+JjY2VJLswdcaMGSpTpozt/l8BAQFavHhxks///Vy6dEk9e/ZUrly55OXlpYCAANvrc+8cH3/8sfbt26fg4GA9+eSTGjx4sF2Ymvj12K5duyRfj19++aXi4uL+taZWrVqpatWq6tSpk3LlyqUXXnhBP/zwAwEVAMA03FMKAIDHRP78+dWxY0c1b95cBQoU0MyZM/XBBx+k2fnuXdEhyfaH6jfffKPAwMAk493cHvxrRbFixbR7927Fx8fb3ZsoNdy7oisl243/v6/Rg/wz5Dp27Jjq1KmjYsWKafTo0QoODpa7u7uWLFmiTz/9NMkf8v98/e6nRo0aOnbsmBYuXKgVK1boyy+/1KeffqpJkyapU6dOKZrjnx72eX/77beSpF69eqlXr15J9s+dO1cdOnRwuJ77vRYPuk9a4v45c+Zo8+bN+vnnn7V8+XJ17NhRn3zyiTZv3iwfHx/lzJlTu3fv1vLly7V06VItXbpU06ZN08svv2y7L9bD2rdvn1xdXW2h0bfffqv27durWbNm6tu3r3LmzClXV1dFRETY3pjg37Rs2VIbN25U3759Va5cOfn4+MhqtapBgwZ2PdSyZUtVr15d8+fP14oVKzRy5EiNGDFC8+bNU8OGDW1jR44cqXLlyiV7rsSVXvfj5eWl9evXa82aNVq8eLGWLVum2bNn6+mnn9aKFSvu20cAAKQWQikAAB4zWbNmVcGCBbVv3z5Jsl2Ol/g4OQEBAfL29tbhw4eT7Dt06JBcXFySrCr6p4IFC0qScubM+VArwpo0aaJNmzZp7ty5at269QPHJt7k/fDhw3aXG8bHx+vEiROpviJNurvy5N4VPUePHpXVarXdRPznn39WXFycfvrpJ7uVSP922WJKZMuWTR06dFCHDh0UGxurGjVqaPDgwerUqZPda/FPhw4dUo4cOZQ5c+b/XINhGPruu+9Uu3ZtdevWLcn+YcOGaebMmerQoUOKeu5B8ufPL6vVqj/++EPFixe3bT979qyuXLlie86JKleurMqVK+vDDz/Ud999p7Zt22rWrFm20M7d3V1NmjRRkyZNZLVa1a1bN33xxRd6//33k6zGSqmoqCitW7dOVapUsa2UmjNnjgoUKKB58+bZBWqDBg2yO/Z+Ydvly5e1evVqDRkyRAMHDrRtv9+lm0FBQerWrZu6deumc+fOqUKFCvrwww/VsGFD29ejr6/vv349PCj8c3FxUZ06dVSnTh2NHj1aw4cP17vvvqs1a9akydcZAAD34vI9AAAeUXv27Enyzn7S3UufDhw4YLucKyAgQDVq1NDUqVMVFRVlNzZxZYyrq6vq16+vhQsX2l2OdvbsWX333XeqVq2afH19H1hPeHi4fH19NXz48GTv73P+/PkHHt+1a1cFBQXprbfe0pEjR5LsP3funG3lV926deXu7q5x48bZre756quvdPXqVTVq1OiB53oYEyZMsHs8fvx4SVLDhg0l/b366N56rl69qmnTpv2n8168eNHusY+PjwoVKmS7RC0oKEjlypXTjBkzdOXKFdu4ffv2acWKFXrmmWf+0/kTbdiwQZGRkerQoYOef/75JB+tWrXSmjVrdPr06RT13IMk1jxmzBi77aNHj5Yk2+f38uXLSeZLXBWU+Pr88/VzcXGxvdPdvZf5OeLSpUtq3bq1EhIS9O6779q2J9cDW7Zs0aZNm+yO9/b2liS7z9f9jpeSvg4JCQlJLr3LmTOncufObXtOYWFhKliwoEaNGmW7zPBe9349JoaW/6zn0qVLSY775+sLAEBaYqUUAABp6Pfff9dPP/0k6e7Km6tXr9qCl7Jly6pJkyb3PXblypUaNGiQnn32WVWuXFk+Pj46fvy4pk6dqri4OA0ePNg2dty4capWrZoqVKigLl26KDQ0VJGRkVq8eLF2794tSfrggw+0cuVKVatWTd26dZObm5u++OILxcXF6eOPP/7X5+Lr66uJEyfqpZdeUoUKFfTCCy8oICBAUVFRWrx4sapWrarPPvvsvsdnzZpV8+fP1zPPPKNy5crpxRdfVFhYmKS7N3j+/vvvVaVKFUl3g7YBAwZoyJAhatCggZ599lkdPnxYn3/+uZ544gm9+OKL/1qvo06cOKFnn31WDRo00KZNm/Ttt9+qTZs2Klu2rCSpfv36thU5r776qmJjYzVlyhTlzJlTZ86ceejzlihRQrVq1VJYWJiyZcum7du3a86cOerRo4dtzMiRI9WwYUNVqVJFr7zyim7evKnx48fLz8/Prg/+i5kzZ8rV1fW+gd+zzz6rd999V7NmzVLv3r1T1HP3U7ZsWbVr106TJ0/WlStXVLNmTW3dulUzZsxQs2bNVLt2bUl379/0+eefq3nz5ipYsKCuXbumKVOmyNfX1xZsderUSZcuXdLTTz+tvHnz6uTJkxo/frzKlStntwrrfo4cOaJvv/1WhmEoJiZGe/bs0Y8//qjY2FiNHj1aDRo0sI1t3Lix5s2bp+bNm6tRo0Y6ceKEJk2apBIlStgFQ15eXipRooRmz56tIkWKKFu2bCpVqpRKlSqlGjVq6OOPP9bt27eVJ08erVixQidOnLCr6dq1a8qbN6+ef/55lS1bVj4+Plq1apW2bdumTz75RNLd8O3LL79Uw4YNVbJkSXXo0EF58uTRX3/9pTVr1sjX11c///yzJNm+zt5991298MILypQpk5o0aaKhQ4dq/fr1atSokfLnz69z587p888/V968eVWtWrV/fe0AAPjPnPSufwAAPNamTZv2r29Vf++45D7atWv3wGOPHz9uDBw40KhcubKRM2dOw83NzQgICDAaNWpk/PLLL0nG79u3z2jevLnh7+9veHp6GkWLFjXef/99uzE7d+40wsPDDR8fH8Pb29uoXbu2sXHjRoee25o1a4zw8HDDz8/P8PT0NAoWLGi0b9/e2L59+wOfT6LTp08bvXr1MooUKWJ4enoa3t7eRlhYmPHhhx8aV69etRv72WefGcWKFTMyZcpk5MqVy3jttdeMy5cv242pWbOmUbJkySTnyZ8/v9GoUaMk2yUZ3bt3tz0eNGiQIck4cOCA8fzzzxtZsmQxsmbNavTo0cO4efOm3bE//fSTUaZMGcPT09MICQkxRowYYUydOtWQZJw4ceJfz524797P/QcffGA8+eSThr+/v+Hl5WUUK1bM+PDDD434+Hi741atWmVUrVrV8PLyMnx9fY0mTZoYBw4csBuT+FzOnz9vtz3xc3pvjfeKj483smfPblSvXj3Z/YlCQ0ON8uXL2x7/W8/drx7DMIzbt28bQ4YMMUJDQ41MmTIZwcHBxoABA4xbt27ZxuzcudNo3bq1kS9fPsPDw8PImTOn0bhxY7temzNnjlG/fn0jZ86chru7u5EvXz7j1VdfNc6cOfPA52IYht3Xo4uLi+Hv72+UL1/e6Nmzp7F///4k461WqzF8+HAjf/78hoeHh1G+fHlj0aJFRrt27Yz8+fPbjd24caMRFhZmuLu7G5KMQYMGGYZhGH/++aftNfPz8zP+97//GadPn7YbExcXZ/Tt29coW7askSVLFiNz5sxG2bJljc8//zxJTbt27TKee+45I3v27IaHh4eRP39+o2XLlsbq1avtxg0bNszIkyeP4eLiYuuF1atXG02bNjVy585tuLu7G7lz5zZat25tHDly5F9fOwAAUoPFMFKwxhoAACCdGjx4sIYMGaLz588rR44czi4HAAAgw+CeUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA03FPKQAAAAAAAJiOlVIAAAAAAAAwHaEUAAAAAAAATOfm7ALMZrVadfr0aWXJkkUWi8XZ5QAAAAAAAKQrhmHo2rVryp07t1xc7r8eKsOFUqdPn1ZwcLCzywAAAAAAAEjXTp06pbx58953f4YLpbJkySLp7gvj6+vr5GoAAAAAAADSl5iYGAUHB9symPvJcKFU4iV7vr6+hFIAAAAAAABp5N9um8SNzgEAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApstw95RKqYSEBN2+fdvZZQD/WaZMmeTq6ursMgAAAAAAsEMo9Q+GYSg6OlpXrlxxdilAqvH391dgYOC/3mQOAAAAAACzEEr9Q2IglTNnTnl7e/NHPB5rhmHoxo0bOnfunCQpKCjIyRUBAAAAAHAXodQ9EhISbIFU9uzZnV0OkCq8vLwkSefOnVPOnDm5lA8AAAAA8EjgRuf3SLyHlLe3t5MrAVJXYk9znzQAAAAAwKOCUCoZXLKH9IaeBgAAAAA8agilAAAAAAAAYDpCKQAAAAAAAJiOUArJat++vSwWiywWizJlyqRcuXKpXr16mjp1qqxWa4rnmT59uvz9/dOu0Pto3769mjVrZvp5AQAAAABAyhBK4b4aNGigM2fOKDIyUkuXLlXt2rXVs2dPNW7cWHfu3HF2eQAAAAAA4DFGKIX78vDwUGBgoPLkyaMKFSronXfe0cKFC7V06VJNnz5dkjR69GiVLl1amTNnVnBwsLp166bY2FhJ0tq1a9WhQwddvXrVtupq8ODBkqRvvvlGFStWVJYsWRQYGKg2bdro3LlztnNfvnxZbdu2VUBAgLy8vFS4cGFNmzbNtv/UqVNq2bKl/P39lS1bNjVt2lSRkZGSpMGDB2vGjBlauHCh7bxr16414yUDAAAAAAApRCgFhzz99NMqW7as5s2bJ0lycXHRuHHjtH//fs2YMUO//PKL+vXrJ0l66qmnNGbMGPn6+urMmTM6c+aM+vTpI0m6ffu2hg0bpj179mjBggWKjIxU+/btbed5//33deDAAS1dulQHDx7UxIkTlSNHDtux4eHhypIli3799Vdt2LBBPj4+atCggeLj49WnTx+1bNnSttLrzJkzeuqpp8x9oQAAAAAAwAO5ObsAPH6KFSum33//XZL05ptv2raHhITogw8+UNeuXfX555/L3d1dfn5+slgsCgwMtJujY8eOtn8XKFBA48aN0xNPPKHY2Fj5+PgoKipK5cuXV8WKFW1zJ5o9e7asVqu+/PJLWSwWSdK0adPk7++vtWvXqn79+vLy8lJcXFyS8wIAAAAAgEcDK6XgMMMwbGHQqlWrVKdOHeXJk0dZsmTRSy+9pIsXL+rGjRsPnGPHjh1q0qSJ8uXLpyxZsqhmzZqSpKioKEnSa6+9plmzZqlcuXLq16+fNm7caDt2z549Onr0qLJkySIfHx/5+PgoW7ZsunXrlo4dO5ZGzxoAAAAAAKQmQik47ODBgwoNDVVkZKQaN26sMmXKaO7cudqxY4cmTJggSYqPj7/v8devX1d4eLh8fX01c+ZMbdu2TfPnz7c7rmHDhjp58qR69eql06dPq06dOrZL/2JjYxUWFqbdu3fbfRw5ckRt2rRJ42cPAAAAAABSA5fvwSG//PKL9u7dq169emnHjh2yWq365JNP5OJyN9/84Ycf7Ma7u7srISHBbtuhQ4d08eJFffTRRwoODpYkbd++Pcm5AgIC1K5dO7Vr107Vq1dX3759NWrUKFWoUEGzZ89Wzpw55evrm2ydyZ0XAAAAAAA8OgilcF9xcXGKjo5WQkKCzp49q2XLlikiIkKNGzfWyy+/rH379un27dsaP368mjRpog0bNmjSpEl2c4SEhCg2NlarV69W2bJl5e3trXz58snd3V3jx49X165dtW/fPg0bNszuuIEDByosLEwlS5ZUXFycFi1apOLFi0uS2rZtq5EjR6pp06YaOnSo8ubNq5MnT2revHnq16+f8ubNq5CQEC1fvlyHDx9W9uzZ5efnp0yZMpn22gEAAADIOErPKJ1mc+9ttzfN5gacjcv3cF/Lli1TUFCQQkJC1KBBA61Zs0bjxo3TwoUL5erqqrJly2r06NEaMWKESpUqpZkzZyoiIsJujqeeekpdu3ZVq1atFBAQoI8//lgBAQGaPn26fvzxR5UoUUIfffSRRo0aZXecu7u7BgwYoDJlyqhGjRpydXXVrFmzJEne3t5av3698uXLp+eee07FixfXK6+8olu3btlWTnXu3FlFixZVxYoVFRAQoA0bNpjzogEAAAAAgBSxGIZhOLsIM8XExMjPz09Xr15NcunXrVu3dOLECYWGhsrT09NJFQKpj94GAAAA0g4rpQB7D8pe7sVKKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDo3ZxcAAAAAAECaG+yXdnOH5ku7uYF0jJVSSNdCQkI0ZswYZ5cBAAAAAAD+gZVSKRTSf7Gp54v8qJHDx0RHRysiIkKLFy/Wn3/+KT8/PxUqVEgvvvii2rVrJ29v7zSoNPWFhITozTff1Jtvvpnm5xo8eLCGDBkiSXJ1dZW/v79KlCih5557Tq+99po8PDxSPNfatWtVu3ZtXb58Wf7+/mlUcVKDBw/WggULtHv3btPOCQAAAADAf0UolU4cP35cVatWlb+/v4YPH67SpUvLw8NDe/fu1eTJk5UnTx49++yzTqvPMAwlJCTIze3Ra7mSJUtq1apVslqtunjxotauXasPPvhA33zzjdauXassWbI4u0QAAAAAANIdLt9LJ7p16yY3Nzdt375dLVu2VPHixVWgQAE1bdpUixcvVpMmTWxjr1y5ok6dOikgIEC+vr56+umntWfPHtv+wYMHq1y5cvrmm28UEhIiPz8/vfDCC7p27ZptjNVqVUREhEJDQ+Xl5aWyZctqzpw5tv1r166VxWLR0qVLFRYWJg8PD/322286duyYmjZtqly5csnHx0dPPPGEVq1aZTuuVq1aOnnypHr16iWLxSKLxWLb99tvv6l69ery8vJScHCw3njjDV2/ft22/9y5c2rSpIm8vLwUGhqqmTNnpui1c3NzU2BgoHLnzq3SpUvr9ddf17p167Rv3z6NGDHCNu6bb75RxYoVlSVLFgUGBqpNmzY6d+6cJCkyMlK1a9eWJGXNmlUWi0Xt27eXJC1btkzVqlWTv7+/smfPrsaNG+vYsWO2eePj49WjRw8FBQXJ09NT+fPnV0RERIo+X9OnT9eQIUO0Z88e2+s1ffr0FD1vAAAAAACciVAqHbh48aJWrFih7t27K3PmzMmOuTfc+d///qdz585p6dKl2rFjhypUqKA6dero0qVLtjHHjh3TggULtGjRIi1atEjr1q3TRx99ZNsfERGhr7/+WpMmTdL+/fvVq1cvvfjii1q3bp3defv376+PPvpIBw8eVJkyZRQbG6tnnnlGq1ev1q5du9SgQQM1adJEUVFRkqR58+Ypb968Gjp0qM6cOaMzZ87Y6mnQoIFatGih33//XbNnz9Zvv/2mHj162M7Vvn17nTp1SmvWrNGcOXP0+eef20IjRxUrVkwNGzbUvHnzbNtu376tYcOGac+ePVqwYIEiIyNtwVNwcLDmzp0rSTp8+LDOnDmjsWPHSpKuX7+u3r17a/v27Vq9erVcXFzUvHlzWa1WSdK4ceP0008/6YcfftDhw4c1c+ZMhYSEpOjz1apVK7311lsqWbKk7fVq1arVQz1nAAAAAADM9OhdSwWHHT16VIZhqGjRonbbc+TIoVu3bkmSunfvrhEjRui3337T1q1bde7cOdv9kkaNGqUFCxZozpw56tKli6S7K6GmT59uu3TtpZde0urVq/Xhhx8qLi5Ow4cP16pVq1SlShVJUoECBfTbb7/piy++UM2aNW01DB06VPXq1bM9zpYtm8qWLWt7PGzYMM2fP18//fSTevTooWzZssnV1dW2GilRRESE2rZta7vPVOHChTVu3DjVrFlTEydOVFRUlJYuXaqtW7fqiSeekCR99dVXKl68+EO/rsWKFdOKFStsjzt27Gj7d4ECBTRu3Dg98cQTio2NlY+Pj7JlyyZJypkzp909pVq0aGE379SpUxUQEKADBw6oVKlSioqKUuHChVWtWjVZLBblz5/fNjYlny8fHx/bai8AAAAAAB4XhFLp2NatW2W1WtW2bVvFxcVJkvbs2aPY2Fhlz57dbuzNmzftLikLCQmxu5dSUFCQbdXR0aNHdePGDbuwSbp7GVr58uXttlWsWNHucWxsrAYPHqzFixfrzJkzunPnjm7evGlbKXU/e/bs0e+//253SZ5hGLJarTpx4oSOHDkiNzc3hYWF2fYXK1bsP91w3DAMuxVmO3bs0ODBg7Vnzx5dvnzZttIpKipKJUqUuO88f/zxhwYOHKgtW7bowoULdseVKlVK7du3V7169VS0aFE1aNBAjRs3Vv369W3POyWfLwAAAAAAHjeEUulAoUKFZLFYdPjwYbvtBQoUkCR5eXnZtsXGxiooKEhr165NMs+9AU6mTJns9lksFluYEhsbK0lavHix8uTJYzfun+9W98/LCfv06aOVK1dq1KhRKlSokLy8vPT8888rPj7+gc8xNjZWr776qt54440k+/Lly6cjR4488PiHcfDgQYWGhkq6ewleeHi4wsPDNXPmTAUEBCgqKkrh4eH/WnuTJk2UP39+TZkyRblz55bValWpUqVsx1WoUEEnTpzQ0qVLtWrVKrVs2VJ169bVnDlzUvz5AgAAAADgcUMolQ5kz55d9erV02effabXX3/9vveVku4GINHR0XJzc7O7b5EjSpQoIQ8PD0VFRdldqpcSGzZsUPv27dW8eXNJd8OmyMhIuzHu7u5KSEhIUveBAwdUqFChZOctVqyY7ty5ox07dtgu3zt8+LCuXLniUH2JDh06pGXLlmnAgAG2xxcvXtRHH32k4OBgSdL27duT1C3JrvaLFy/q8OHDmjJliqpXry7p7iV5/+Tr66tWrVqpVatWev7559WgQQNdunQpRZ+v5F4vAAAAAAAeddzoPJ34/PPPdefOHVWsWFGzZ8/WwYMHdfjwYX377bc6dOiQXF1dJUl169ZVlSpV1KxZM61YsUKRkZHauHGj3n333SQhy/1kyZJFffr0Ua9evTRjxgwdO3ZMO3fu1Pjx4zVjxowHHlu4cGHNmzdPu3fv1p49e9SmTRvbCqxEISEhWr9+vf766y9duHBBkvT2229r48aN6tGjh3bv3q0//vhDCxcutN3oPPHSt1dffVVbtmzRjh071KlTJ7tVYvdz584dRUdH6/Tp09q7d6/Gjx+vmjVrqly5curbt6+ku6ux3N3dNX78eB0/flw//fSThg0bZjdP/vz5ZbFYtGjRIp0/f16xsbHKmjWrsmfPrsmTJ+vo0aP65Zdf1Lt3b7vjRo8ere+//16HDh3SkSNH9OOPPyowMFD+/v4p+nyFhIToxIkT2r17ty5cuGC7VBMAAAAAgEcZoVQ6UbBgQe3atUt169bVgAEDVLZsWVWsWFHjx49Xnz59bAGKxWLRkiVLVKNGDXXo0EFFihTRCy+8oJMnTypXrlwpPt+wYcP0/vvvKyIiQsWLF1eDBg20ePFi2+Vu9zN69GhlzZpVTz31lJo0aaLw8HBVqFDBbszQoUMVGRmpggULKiAgQJJUpkwZrVu3TkeOHFH16tVVvnx5DRw4ULlz57YdN23aNOXOnVs1a9bUc889py5duihnzpz/+lz279+voKAg5cuXT7Vq1dIPP/ygAQMG6Ndff5WPj48kKSAgQNOnT9ePP/6oEiVK6KOPPtKoUaPs5smTJ4+GDBmi/v37K1euXOrRo4dcXFw0a9Ys7dixQ6VKlVKvXr00cuRIu+OyZMmijz/+WBUrVtQTTzyhyMhILVmyRC4uLin6fLVo0UINGjRQ7dq1FRAQoO+///5fnzMAAAAAAM5mMQzDcHYRZoqJiZGfn5+uXr0qX19fu323bt3SiRMnFBoaKk9PTydVCKQ+ehsAAAAZ3mC/NJu6dGi+NJt7b7u9aTY3kFYelL3ci5VSAAAAAAAAMB2hFAAAAAAAAEzHu+8BAAAAAJwupP/iNJ0/krtYAI8cVkoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hVAZmsVi0YMGCB45p3769mjVrluI5IyMjZbFYtHv37v9UGwAAAAAASN/cnF3AY2Own8nnu+rQ8Pbt2+vKlSv/GjLd68yZM8qaNauku2FSaGiodu3apXLlytnGjB07VoZhOFTLv6lVq5bWrVsnSXJ3d1eOHDlUoUIFdejQQc8995xDcw0ePFgLFiwwPQSrVauWypUrpzFjxph6XgAAAAAA0gtWSmVggYGB8vDweOAYPz8/+fv7p/q5O3furDNnzujYsWOaO3euSpQooRdeeEFdunRJ9XMBAAAAAIBHDyul0qlatWqpTJky8rxzVV9+v0DumTKp60stNPitrrYxljwVNP+rT9SsQW2FhlaQJJUvX16SVLNKmNbOmaL2bw7SlZhrWjB1tCRp2ZoN+mDsV9p3+Khc3dxVpUoVjR07VgULFnSoPm9vbwUGBkqS8ubNq8qVK6tYsWLq2LGjWrZsqbp160qS3n77bc2fP19//vmnAgMD1bZtWw0cOFCZMmXS9OnTNWTIkLvPxWKRJE2bNk3t27fX6NGjNW3aNB0/flzZsmVTkyZN9PHHH8vHx0eSdPLkSfXo0UO//fab4uPjFRISopEjR+qZZ56RJO3bt099+/bVr7/+qsyZM6t+/fr69NNPlSNHDrVv317r1q3TunXrNHbsWEnSiRMnFBIS4vDn6ZGS1qsBHVz9BwAAAABI31gplY7NmDFDmb29tOXnr/Xxuz019NMpWrl+c7Jjty7+RpK0atZEndm1QvOmjEp23PUbt9S7S1ttX/KtVq9eLRcXFzVv3lxWq/U/19uuXTtlzZpV8+bNs23LkiWLpk+frgMHDmjs2LGaMmWKPv30U0lSq1at9NZbb6lkyZI6c+aMzpw5o1atWkmSXFxcNG7cOO3fv18zZszQL7/8on79+tnm7d69u+Li4rR+/Xrt3btXI0aMsAVWV65c0dNPP63y5ctr+/btWrZsmc6ePauWLVtKuntJY5UqVWyrvc6cOaPg4OD//PwBAAAAAMhIWCmVjpUpU0aDer8qSSpcIJ8+mz5bq3/bqno1KicZG5D97r2lsmf1V2DOHPeds0WjOn8/yF1OU6dOVUBAgA4cOKBSpUr9p3pdXFxUpEgRRUZG2ra99957tn+HhISoT58+mjVrlvr16ycvLy/5+PjIzc3Ntuoq0Ztvvml33AcffKCuXbvq888/lyRFRUWpRYsWKl26tCSpQIECtvGfffaZypcvr+HDh9u2TZ06VcHBwTpy5IiKFCkid3d3u9VeAAAAAADAMYRS6ViZMmXsHgflzKFzFy79pzn/OB6lgaMmasuufbpwOca2QioqKuo/h1KSZBiG7VI8SZo9e7bGjRunY8eOKTY2Vnfu3JGvr++/zrNq1SpFRETo0KFDiomJ0Z07d3Tr1i3duHFD3t7eeuONN/Taa69pxYoVqlu3rlq0aGF7vfbs2aM1a9bYVk7d69ixYypSpMh/fp4AAAAAAGR0XL6XjmXKlMnuscVikdX6395Jr0n7N3XpylVN+fg9bdmyRVu2bJEkxcfH/6d5JSkhIUF//PGHQkNDJUmbNm1S27Zt9cwzz2jRokXatWuX3n333X89V2RkpBo3bqwyZcpo7ty52rFjhyZMmGBXZ6dOnXT8+HG99NJL2rt3rypWrKjx48dLkmJjY9WkSRPt3r3b7uOPP/5QjRo1/vPzBAAAAAAArJTC/3P//wArwZpw3zEXL13R4WORmjLyPVWvVEHKXVy//fZbqtUwY8YMXb58WS1atJAkbdy4Ufnz59e7775rG3Py5En7ut3dlZBgX/OOHTtktVr1ySefyMXlbu76ww8/JDlfcHCwunbtqq5du2rAgAGaMmWKXn/9dVWoUEFz585VSEiI3NyS/xJJ7rwAAAAAACDlWCkFSVLOHFnl5empZWs26uz5i7oacy3JmKz+vsqe1V+Tv52noyei9Msvv6h3794Pdb4bN24oOjpaf/75pzZv3qy3335bXbt21WuvvabatWtLkgoXLqyoqCjNmjVLx44d07hx4zR//ny7eUJCQnTixAnt3r1bFy5cUFxcnAoVKqTbt29r/PjxOn78uL755htNmjTJ7rg333xTy5cv14kTJ7Rz506tWbNGxYsXl3T3JuiXLl1S69attW3bNh07dkzLly9Xhw4dbEFUSEiItmzZosjISF24cCFVbvQOAAAAAEBGQigFSZKbm5vGDeurL76dp9wVwtW0Y9KwycXFRbM+j9COvQdVqk5L9erVSyNHjnyo802ZMkVBQUEqWLCgnnvuOR04cECzZ8+23Yhckp599ln16tVLPXr0ULly5bRx40a9//77dvO0aNFCDRo0UO3atRUQEKDvv/9eZcuW1ejRozVixAiVKlVKM2fOVEREhN1xCQkJ6t69u4oXL64GDRqoSJEitnPnzp1bGzZsUEJCgurXr6/SpUvrzTfflL+/v23lVZ8+feTq6qoSJUooICBAUVFRD/U6AAAAAACQUVkMw/hvNxl6zMTExMjPz09Xr15NcsPsW7du6cSJEwoNDZWnp6eTKkxlp3el3dy5y6fd3EhVKertwX5pW8Tgq2k7PwAAAB5rIf0Xp+n8kZ5t0mzu0qH50mzuve32ptncQFp5UPZyL1ZKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA07k5uwAAAAAAeNSUnlE6zebmxtUAcBcrpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpfBImD59uvz9/Z1dBgAAAAAAMInT331vwoQJGjlypKKjo1W2bFmNHz9eTz755H3HjxkzRhMnTlRUVJRy5Mih559/XhEREfL09EzTOtPy3TeS4+g7crRv314zZszQq6++qkmTJtnt6/5OhD6f8aPa/a+Jpo8Zkpplmspisdj+7e3trdy5c6tq1ap6/fXXFRYW5tBctWrVUrly5TRmzJhUrvLBLBaL5s+fr2bNmpl6XgAAAAAAHjVOXSk1e/Zs9e7dW4MGDdLOnTtVtmxZhYeH69y5c8mO/+6779S/f38NGjRIBw8e1FdffaXZs2frnXfeMbnyR1NwcLBmzZqlmzdv2rbduhWn7xYsU748gf9pbsMwdOfOnf9a4n82bdo0nTlzRvv379eECRMUGxurSpUq6euvv3Z2aQAAAAAAwAFODaVGjx6tzp07q0OHDipRooQmTZokb29vTZ06NdnxGzduVNWqVdWmTRuFhISofv36at26tbZu3Wpy5Y+mChUqKDg4WPPmzbNtm7f0F+XLHajypYrZjbVarYoYP1WhlRvLq2AVla3bSnMWrbLtX7txuyx5KmjpLxsU1qCNPEIr6betu3Ut9rra9nhXmQs9paCgIH366aeqVauW3nzzTduxcXFx6tOnj/LkyaPMmTOrUqVKWrt2rd35p0+frnz58snb21vNmzfXxYsXU/Qc/f39FRgYaPv8z5kzR23btlWPHj10+fJlSdLFixfVunVr5cmTR97e3ipdurS+//572xzt27fXunXrNHbsWFksFlksFkVGRiohIUGvvPKKQkND5eXlpaJFi2rs2LF251+7dq2efPJJZc6cWf7+/qpatapOnjxp279w4UJVqFBBnp6eKlCggIYMGWIL80JCQiRJzZs3l8VisT0GAAAAACAjclooFR8frx07dqhu3bp/F+Piorp162rTpk3JHvPUU09px44dthDq+PHjWrJkiZ555hlTan4cdOzYUdOmTbM9njproTq0ejbJuIjxU/X1nEWa9NE72v/Lj+rVua1efOM9rdu0w25c/+Hj9NE7b+jg2rkqU7yweg8ZrQ3bduunaZ9q5cqV+vXXX7Vz5067Y3r06KFNmzZp1qxZ+v333/W///1PDRo00B9//CFJ2rJli1555RX16NFDu3fvVu3atfXBBx889HPu1auXrl27ppUrV0qSbt26pbCwMC1evFj79u1Tly5d9NJLL9n6ZuzYsapSpYo6d+6sM2fO6MyZMwoODpbValXevHn1448/6sCBAxo4cKDeeecd/fDDD5KkO3fuqFmzZqpZs6Z+//13bdq0SV26dLFdVvjrr7/q5ZdfVs+ePXXgwAF98cUXmj59uj788ENJ0rZt2yT9vdor8TEAAAAAABmR0+4pdeHCBSUkJChXrlx223PlyqVDhw4le0ybNm104cIFVatWzXY5WdeuXR94+V5cXJzi4uJsj2NiYlLnCTyiXnzxRQ0YMMC2emfD9j2aNTFCa+8Jm+Li4jV8/FStmjVRVSqWlSQVyJ9Xv23brS++nauaVf6+P9PQvq+pXo3KkqRrsdc148ef9d1nw1WneiUpdylNmzZNuXPnto2PiorStGnTFBUVZdvep08fLVu2TNOmTdPw4cM1duxYNWjQQP369ZMkFSlSRBs3btSyZcse6jkXK3Z3FVhkZKQkKU+ePOrTp49t/+uvv67ly5frhx9+0JNPPik/Pz+5u7vL29tbgYF/X9bo6uqqIUP+vudWaGioNm3apB9++EEtW7ZUTEyMrl69qsaNG6tgwYKSpOLFi9vGDxkyRP3791e7du3uvqYFCmjYsGHq16+fBg0apICAAEl/r/YCAAAAACAjc/qNzh2xdu1aDR8+XJ9//rkqVaqko0ePqmfPnho2bJjef//9ZI+JiIiwCxrSu4CAADVq1EjTp0+XYRhq9HQ15ciW1W7M0chTunHzluq17ma3Pf727SSX+VUsU8L27+Mn/9Lt23f0ZPmStm1+fn4qWrSo7fHevXuVkJCgIkWK2M0TFxen7NmzS5IOHjyo5s2b2+2vUqXKQ4dShmFI+vtG6AkJCRo+fLh++OEH/fXXX4qPj1dcXJy8vb3/da4JEyZo6tSpioqK0s2bNxUfH69y5cpJkrJly6b27dsrPDxc9erVU926ddWyZUsFBQVJkvbs2aMNGzbYVkYl1nLr1i3duHEjRecHAAAAACCjcFoolSNHDrm6uurs2bN228+ePXvfVSTvv/++XnrpJXXq1EmSVLp0aV2/fl1dunTRu+++KxeXpFcjDhgwQL1797Y9jomJUXBwcCo+k0dPx44d1aNHD0nShKG9k+yPvX5DkrT463HKExhgt8/D3d3ucWZvL4fOHRsbK1dXV+3YsUOurq52+3x8fByaK6UOHjwo6e7KJkkaOXKkxo4dqzFjxqh06dLKnDmz3nzzTcXHxz9wnlmzZqlPnz765JNPVKVKFWXJkkUjR47Uli1bbGOmTZumN954Q8uWLdPs2bP13nvvaeXKlapcubJiY2M1ZMgQPffcc0nmTut3hwQAAAAA4HHjtFDK3d1dYWFhWr16tZo1aybp7s23V69ebQtU/unGjRtJgqfE4CNxtcw/eXh4yMPDI/UKfww0aNBA8fHxslgsCq9VJcn+EkUKyMPDXVF/nbG7VO/fFMifR5kyuWnb7gPKl+fu6qCrV6/qyJEjqlGjhiSpfPnySkhI0Llz51S9evVk5ylevLhd0CNJmzdvTnEd/zRmzBj5+vra7k+2YcMGNW3aVC+++KKku3115MgRlSjx96ovd3d3JSQk2M2zYcMGPfXUU+rW7e8VZMeOHUtyvvLly6t8+fIaMGCAqlSpou+++06VK1dWhQoVdPjwYRUqVOi+tWbKlCnJeQEAAAAAGUfpGaXTbO697fam2dxpwamX7/Xu3Vvt2rVTxYoV9eSTT2rMmDG6fv26OnToIEl6+eWXlSdPHkVEREiSmjRpotGjR6t8+fK2y/fef/99NWnSJMmqnIzM1dXVtnrINTZpqJLFJ7P6vPqSeg0eLavVULUny+nqtVht2LZHvj6Z1a5lk2TnzeKTWe3+10R9PxijbP6+ylnCXYMGDZKLi4vt0rkiRYqobdu2evnll/XJJ5+ofPnyOn/+vFavXq0yZcqoUaNGeuONN1S1alWNGjVKTZs21fLly1N86d6VK1cUHR2tuLg4HTlyRF988YUWLFigr7/+Wv7+/pKkwoULa86cOdq4caOyZs2q0aNH6+zZs3ahVEhIiLZs2aLIyEj5+PgoW7ZsKly4sL7++mstX75coaGh+uabb7Rt2zbbCqwTJ05o8uTJevbZZ5U7d24dPnxYf/zxh15++WVJ0sCBA9W4cWPly5dPzz//vFxcXLRnzx7t27fPdiP3kJAQrV69WlWrVpWHh4eyZrW/tBIAAAAAgIzCqaFUq1atdP78eQ0cOFDR0dEqV66cli1bZrv5eVRUlN3KqPfee08Wi0Xvvfee/vrrLwUEBKhJkyZ29/DBXb6+vnf/EZv8/mH9uikge1ZFfDZNx6P+lL9vFlUoXUzvvN7xgfOOHtRbXfsPV+N2PeXr569+/frp1KlTdpenTZs2TR988IHeeust/fXXX8qRI4cqV66sxo0bS5IqV66sKVOmaNCgQRo4cKDq1q2r9957T8OGDfvX55UYWHp6eipPnjyqVq2atm7dqgoVKtjGvPfeezp+/LjCw8Pl7e2tLl26qFmzZrp69aptTJ8+fdSuXTuVKFFCN2/e1IkTJ/Tqq69q165datWqlSwWi1q3bq1u3bpp6dKlkiRvb28dOnRIM2bM0MWLFxUUFKTu3bvr1VdflSSFh4dr0aJFGjp0qEaMGKFMmTKpWLFitstNJemTTz5R7969NWXKFOXJk8d2c3YAAAAAADIai3G/697SqZiYGPn5+enq1at/Bzf/79atWzpx4oRCQ0PTzz2ATu9Ku7lzl9f169eVJ08effLJJ3rllVfS7lz4T1LU24P90raIwVf/fQwAAMAjgstrzBfSf3Gazh/p2SbN5i4dmi/N5qZf0p+M8P3lQdnLvR6rd9+D8+3ad0iHjkbqyXIldTXa0NChQyVJTZs2dXJlAAAAAADgcUIoBYeNmvS1Dh87KXcPT4WFhenXX39Vjhw5nF0WAAAAAAB4jBBKwSHlSxXTjmXf3X2Qu7xziwEAAHBAWl4uIT06l0wAAPC4cPn3IQAAAAAAAEDqIpRKRga79zsyAHoaAAAAAPCoIZS6R6ZMmSRJN27ccHIlQOpK7OnEHgcAAAAAwNm4p9Q9XF1d5e/vr3PnzkmSvL29ZbFYnFzVf3QnDVfI3LqVdnMjVRiGoRs3bujcuXPy9/eXq6urs0sCAAAAAEASoVQSgYGBkmQLph57V86n3dzXT6Td3EhV/v7+tt4GAAAAAOBRQCj1DxaLRUFBQcqZM6du377t7HL+u8/+l3Zz99iednMj1WTKlIkVUgAAAACARw6h1H24urqmjz/kY0+l3dyenmk3NwAAAAAASNe40TkAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMx7vvAQAeOaVnlE6zufe225tmcwMAAABIOVZKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA07k5uwAAwGNosF/azh+aL23nBwAAAOB0rJQCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmc3N2AQAAAA+r9IzSaTr/3nZ703R+AACAjIyVUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADCdm7MLAAAAwOMlpP/iNJs78qNGaTY3AAB4tLBSCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOjdnF5DRhfRfnKbzR3qm6fQAAAAAAAAPhZVSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMJ2bswsAAKSNkP6L02zuSM80mxoAAABABsFKKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6ZweSk2YMEEhISHy9PRUpUqVtHXr1geOv3Llirp3766goCB5eHioSJEiWrJkiUnVAgAAAAAAIDW4OfPks2fPVu/evTVp0iRVqlRJY8aMUXh4uA4fPqycOXMmGR8fH6969eopZ86cmjNnjvLkyaOTJ0/K39/f/OIBAAAAAADw0JwaSo0ePVqdO3dWhw4dJEmTJk3S4sWLNXXqVPXv3z/J+KlTp+rSpUvauHGjMmXKJEkKCQkxs2QAAAAAAACkAqddvhcfH68dO3aobt26fxfj4qK6detq06ZNyR7z008/qUqVKurevbty5cqlUqVKafjw4UpISLjveeLi4hQTE2P3AQAAAAAAAOdy2kqpCxcuKCEhQbly5bLbnitXLh06dCjZY44fP65ffvlFbdu21ZIlS3T06FF169ZNt2/f1qBBg5I9JiIiQkOGDEn1+gEAAAAAQDo02C9t5w/Nl7bzP0acfqNzR1itVuXMmVOTJ09WWFiYWrVqpXfffVeTJk267zEDBgzQ1atXbR+nTp0ysWIAAAAAAAAkx2krpXLkyCFXV1edPXvWbvvZs2cVGBiY7DFBQUHKlCmTXF1dbduKFy+u6OhoxcfHy93dPckxHh4e8vDwSN3iAQAAAAAA8J84baWUu7u7wsLCtHr1ats2q9Wq1atXq0qVKskeU7VqVR09elRWq9W27ciRIwoKCko2kAIAAAAAAMCjyamX7/Xu3VtTpkzRjBkzdPDgQb322mu6fv267d34Xn75ZQ0YMMA2/rXXXtOlS5fUs2dPHTlyRIsXL9bw4cPVvXt3Zz0FAAAAAAAAPASnXb4nSa1atdL58+c1cOBARUdHq1y5clq2bJnt5udRUVFycfk7NwsODtby5cvVq1cvlSlTRnny5FHPnj319ttvO+spAAAAAAAA4CE4NZSSpB49eqhHjx7J7lu7dm2SbVWqVNHmzZvTuCoAAAAAAACkJaeHUgAAAADSp5D+i9N0/siPGqXp/ACAtOXUe0oBAAAAAAAgYyKUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOncnF0AAABwvpD+i9Ns7siPGqXZ3AAAAHh8sVIKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGC6hwql7ty5o1WrVumLL77QtWvXJEmnT59WbGxsqhYHAAAAAACA9MnhG52fPHlSDRo0UFRUlOLi4lSvXj1lyZJFI0aMUFxcnCZNmpQWdQIAAAAAACAdcXilVM+ePVWxYkVdvnxZXl5etu3NmzfX6tWrU7U4AAAAAAAApE8Or5T69ddftXHjRrm7u9ttDwkJ0V9//ZVqhQEAAAAAACD9cnillNVqVUJCQpLtf/75p7JkyZIqRQEAAAAAACB9cziUql+/vsaMGWN7bLFYFBsbq0GDBumZZ55JzdoAAAAAAACQTjl8+d6oUaPUoEEDlShRQrdu3VKbNm30xx9/KEeOHPr+++/TokYAAAAAAACkMw6HUsHBwdqzZ49mz56tPXv2KDY2Vq+88oratm1rd+NzAAAAAAAA4H4cCqVu376tYsWKadGiRWrbtq3atm2bVnUBAAAAAAAgHXPonlKZMmXSrVu30qoWAAAAAAAAZBAO3+i8e/fuGjFihO7cuZMW9QAAAAAAACADcPieUtu2bdPq1au1YsUKlS5dWpkzZ7bbP2/evFQrDgAAAAAAAOmTw6GUv7+/WrRokRa1AAAAAAAAIINwOJSaNm1aWtQBAAAAAACADMThUCrR+fPndfjwYUlS0aJFFRAQkGpFAQAAAAAAIH1z+Ebn169fV8eOHRUUFKQaNWqoRo0ayp07t1555RXduHEjLWoEAAAAAABAOuNwKNW7d2+tW7dOP//8s65cuaIrV65o4cKFWrdund566620qBEAAAAAAADpjMOX782dO1dz5sxRrVq1bNueeeYZeXl5qWXLlpo4cWJq1gcAAAAAAIB0yOGVUjdu3FCuXLmSbM+ZMyeX7wEAAAAAACBFHA6lqlSpokGDBunWrVu2bTdv3tSQIUNUpUqVVC0OAAAAAAAA6ZPDl++NHTtW4eHhyps3r8qWLStJ2rNnjzw9PbV8+fJULxAAAAAAAADpj8OhVKlSpfTHH39o5syZOnTokCSpdevWatu2rby8vFK9QAAAAAAAAKQ/DodSkuTt7a3OnTundi0AAAAAAADIIBy+p1RERISmTp2aZPvUqVM1YsSIVCkKAAAAAAAA6ZvDK6W++OILfffdd0m2lyxZUi+88ILefvvtVCkMAAAAAB5osF/azR2aL+3mBgBIeoiVUtHR0QoKCkqyPSAgQGfOnEmVogAAAAAAAJC+ORxKBQcHa8OGDUm2b9iwQblz506VogAAAAAAAJC+OXz5XufOnfXmm2/q9u3bevrppyVJq1evVr9+/fTWW2+leoEAAAAAAABIfxwOpfr27auLFy+qW7duio+PlyR5enrq7bff1oABA1K9QAAAAAAAAKQ/DodSFotFI0aM0Pvvv6+DBw/Ky8tLhQsXloeHR1rUBwAAAAAAgHTI4XtKJfLx8dETTzyhLFmy6NixY7JaralZFwAAAAAAANKxFIdSU6dO1ejRo+22denSRQUKFFDp0qVVqlQpnTp1KtULBAAAAAAAQPqT4lBq8uTJypo1q+3xsmXLNG3aNH399dfatm2b/P39NWTIkDQpEgAAAAAAAOlLiu8p9ccff6hixYq2xwsXLlTTpk3Vtm1bSdLw4cPVoUOH1K8QAAAAAAAA6U6KV0rdvHlTvr6+tscbN25UjRo1bI8LFCig6Ojo1K0OAAAAAAAA6VKKQ6n8+fNrx44dkqQLFy5o//79qlq1qm1/dHS0/Pz8Ur9CAAAAAAAApDspvnyvXbt26t69u/bv369ffvlFxYoVU1hYmG3/xo0bVapUqTQpEgAAAAAAAOlLikOpfv366caNG5o3b54CAwP1448/2u3fsGGDWrduneoFAgAAAAAAIP1JcSjl4uKioUOHaujQocnu/2dIBQAAAAAAANxPiu8pBQAAAAAAAKQWQikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGC6VAulTp06pY4dO6bWdAAAAAAAAEjHUi2UunTpkmbMmJFa0wEAAAAAACAdc0vpwJ9++umB+48fP/6fiwEAAAAAAEDGkOJQqlmzZrJYLDIM475jLBZLqhQFAAAAAACA9C3Fl+8FBQVp3rx5slqtyX7s3LkzLesEAAAAAABAOpLiUCosLEw7duy47/5/W0UFAAAAAAAAJErx5Xt9+/bV9evX77u/UKFCWrNmTaoUBQAAAAAAgPQtxaFU9erVH7g/c+bMqlmz5n8uCAAAAAAAAOlfii/fO378OJfnAQAAAAAAIFWkOJQqXLiwzp8/b3vcqlUrnT17Nk2KAgAAAAAAQPqW4lDqn6uklixZ8sB7TAEAAAAAAAD3k+JQCgAAAAAAAEgtKQ6lLBaLLBZLkm0AAAAAAACAo1L87nuGYah9+/by8PCQJN26dUtdu3ZV5syZ7cbNmzcvdSsEAABAxjHYL+3mDs2XdnMDAACHpTiUateund3jF198MdWLAQAAAAAAQMaQ4lBq2rRpaVkHAAAAAAAAMhBudA4AAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTPRKh1IQJExQSEiJPT09VqlRJW7duTdFxs2bNksViUbNmzdK2QAAAAAAAAKQqp4dSs2fPVu/evTVo0CDt3LlTZcuWVXh4uM6dO/fA4yIjI9WnTx9Vr17dpEoBAAAAAACQWpweSo0ePVqdO3dWhw4dVKJECU2aNEne3t6aOnXqfY9JSEhQ27ZtNWTIEBUoUMDEagEAAAAAAJAanBpKxcfHa8eOHapbt65tm4uLi+rWratNmzbd97ihQ4cqZ86ceuWVV8woEwAAAAAAAKnMzZknv3DhghISEpQrVy677bly5dKhQ4eSPea3337TV199pd27d6foHHFxcYqLi7M9jomJeeh6AQAAAAAAkDqcGko56tq1a3rppZc0ZcoU5ciRI0XHREREaMiQIWlcWcZUekbpNJt7b7u9aTY3AAAAAABwPqeGUjly5JCrq6vOnj1rt/3s2bMKDAxMMv7YsWOKjIxUkyZNbNusVqskyc3NTYcPH1bBggXtjhkwYIB69+5texwTE6Pg4ODUfBoAAAAAAABwkFNDKXd3d4WFhWn16tVq1qyZpLsh0+rVq9WjR48k44sVK6a9e+1X0Lz33nu6du2axo4dm2zY5OHhIQ8PjzSpHwAAAAAAAA/H6Zfv9e7dW+3atVPFihX15JNPasyYMbp+/bo6dOggSXr55ZeVJ08eRUREyNPTU6VKlbI73t/fX5KSbAcAAAAAAMCjy+mhVKtWrXT+/HkNHDhQ0dHRKleunJYtW2a7+XlUVJRcXJz6JoEAAAAAAABIZU4PpSSpR48eyV6uJ0lr16594LHTp09P/YIAAAAAAACQpliCBAAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANM9Eu++ByBlQvovTrO5Iz3TbGoAAAAAAJJgpRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA07k5uwAAAAAAAABHhPRfnGZzR3qm2dT4B1ZKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADCdm7MLAJAxlJ5ROs3m3ttub5rNDQAAAABIG6yUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkeiVBqwoQJCgkJkaenpypVqqStW7fed+yUKVNUvXp1Zc2aVVmzZlXdunUfOB4AAAAAAACPHqeHUrNnz1bv3r01aNAg7dy5U2XLllV4eLjOnTuX7Pi1a9eqdevWWrNmjTZt2qTg4GDVr19ff/31l8mVAwAAAAAA4GE5PZQaPXq0OnfurA4dOqhEiRKaNGmSvL29NXXq1GTHz5w5U926dVO5cuVUrFgxffnll7JarVq9erXJlQMAAAAAAOBhOTWUio+P144dO1S3bl3bNhcXF9WtW1ebNm1K0Rw3btzQ7du3lS1btrQqEwAAAAAAAKnMzZknv3DhghISEpQrVy677bly5dKhQ4dSNMfbb7+t3Llz2wVb94qLi1NcXJztcUxMzMMXDAAAAAAAgFTh9Mv3/ouPPvpIs2bN0vz58+Xp6ZnsmIiICPn5+dk+goODTa4SAAAAAAAA/+TUUCpHjhxydXXV2bNn7bafPXtWgYGBDzx21KhR+uijj7RixQqVKVPmvuMGDBigq1ev2j5OnTqVKrUDAAAAAADg4Tk1lHJ3d1dYWJjdTcoTb1pepUqV+x738ccfa9iwYVq2bJkqVqz4wHN4eHjI19fX7gMAAAAAAADO5dR7SklS79691a5dO1WsWFFPPvmkxowZo+vXr6tDhw6SpJdffll58uRRRESEJGnEiBEaOHCgvvvuO4WEhCg6OlqS5OPjIx8fH6c9DwAAAAAAAKSc00OpVq1a6fz58xo4cKCio6NVrlw5LVu2zHbz86ioKLm4/L2ga+LEiYqPj9fzzz9vN8+gQYM0ePBgM0sHAAAAAADAQ3J6KCVJPXr0UI8ePZLdt3btWrvHkZGRaV8QAAAAAAAA0tRj/e57AAAAAAAAeDwRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANM9EqHUhAkTFBISIk9PT1WqVElbt2594Pgff/xRxYoVk6enp0qXLq0lS5aYVCkAAAAAAABSg9NDqdmzZ6t3794aNGiQdu7cqbJlyyo8PFznzp1LdvzGjRvVunVrvfLKK9q1a5eaNWumZs2aad++fSZXDgAAAAAAgIfl9FBq9OjR6ty5szp06KASJUpo0qRJ8vb21tSpU5MdP3bsWDVo0EB9+/ZV8eLFNWzYMFWoUEGfffaZyZUDAAAAAADgYbk58+Tx8fHasWOHBgwYYNvm4uKiunXratOmTckes2nTJvXu3dtuW3h4uBYsWJDs+Li4OMXFxdkeX716VZIUExPzH6tPHda4G2k6f4zFSLO5E24mpNncj8rn51GTlv2Slr0i0S/OQL8kj35JXpr2Sxq+5mnZKxL9cj+P6/cX+sV8/K6bPHolefRL8uiX5D2uP4ukjNEviXUYxoNfS6eGUhcuXFBCQoJy5cpltz1Xrlw6dOhQssdER0cnOz46OjrZ8RERERoyZEiS7cHBwQ9Z9ePFL01nP5hmM/u9lraVI6m0f8Xpl/SEfoEj/MY4u4KHR7+Y73H93UWiX5zhce0XesU56BekFL/rpp5r167Jz+/+NTk1lDLDgAED7FZWWa1WXbp0SdmzZ5fFYnFiZY+WmJgYBQcH69SpU/L19XV2OXjE0S9wBP0CR9AvcAT9gpSiV+AI+gWOoF+SZxiGrl27pty5cz9wnFNDqRw5csjV1VVnz56123727FkFBgYme0xgYKBD4z08POTh4WG3zd/f/+GLTud8fX35QkKK0S9wBP0CR9AvcAT9gpSiV+AI+gWOoF+SetAKqUROvdG5u7u7wsLCtHr1ats2q9Wq1atXq0qVKskeU6VKFbvxkrRy5cr7jgcAAAAAAMCjx+mX7/Xu3Vvt2rVTxYoV9eSTT2rMmDG6fv26OnToIEl6+eWXlSdPHkVEREiSevbsqZo1a+qTTz5Ro0aNNGvWLG3fvl2TJ0925tMAAAAAAACAA5weSrVq1Urnz5/XwIEDFR0drXLlymnZsmW2m5lHRUXJxeXvBV1PPfWUvvvuO7333nt65513VLhwYS1YsEClSpVy1lNIFzw8PDRo0KAklzoCyaFf4Aj6BY6gX+AI+gUpRa/AEfQLHEG//DcW49/enw8AAAAAAABIZU69pxQAAAAAAAAyJkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIgSeL2cgCARwE/jwAAyDgIpdK569evO7sEPCbOnDnj7BLwGDly5IguXbrk7DLwmFi5cqVmz57t7DLwmLBYLM4uAQAAmIRQKh2bNWuWevTooQMHDji7FDziJk2apGrVqunChQvOLgWPgalTp6px48baunWrbty44exy8IibOnWqwsPDNXfuXGeXgsfA0qVL1atXL73++uv67rvvnF0OHnHbtm3T8uXLNX/+fP3111/OLgePuH379mnbtm3atGkTKzLxQLdv33Z2CRkKoVQ6dfHiRb377rvasGGDJk6cqEOHDtn28U0Y9/riiy/Uo0cPjRw5Ujly5HB2OXjEzZo1S6+//roGDBig2rVry9vb29kl4RE2efJkvfbaa+ratatWrFihtWvXOrskPMK++uortWnTRleuXNHmzZs1ceJE7dq1y9ll4RH11VdfqWHDhho1apQ6dOigNm3a6KOPPnJ2WXhEffnll6pTp45eeuklVa1aVS1atOB/liBZ3377rbp166YrV644u5QMw83ZBSBt+Pj4KF++fMqSJYs2btyo27dvq0ePHipVqpRtWbxhGCyRz+CmTp2qHj16aN68eXr22Wd1+fJl3b59WxcuXFCJEiWcXR4eIYZh6MaNG5o+fboGDRqkDh066M8//9Svv/6qCxcuqHDhwmrQoIGzy8QjZPLkyerWrZvmzJmjBg0aaNeuXVq4cKFq1aolq9UqFxf+vxj+tmnTJg0cOFBffvmlWrRooVOnTqlKlSqKjY11dml4BK1fv14DBw7U5MmT9eyzz+rs2bPq0qWL3nnnHZ0/f16ffPKJs0vEI2TTpk16++23NWHCBFWtWlXnzp1Tv379NGbMGP3111964403nF0iHhE///yzOnfurLi4ON28eVOff/65fH19nV1WusdvhOmQYRjy8PBQsWLF1KdPH/Xt21ebN2/WV199pf3796tfv36SuGdDRnfgwAH169dP9erV07PPPqtjx46pRYsWql69ukqVKqXnn39eS5YscXaZeERYLBYlJCTozz//VJMmTRQVFaVq1app6tSp+uijj9SnTx+1a9fO2WXiEfHdd9+pa9eumjNnjpo1ayZPT0/Vr19fM2bM0IULF+Ti4sKqXdg5dOiQ8uTJoyZNmkiSgoODFRoaqq+//lovvfSShgwZ4uQK8SjZtWuXSpcurebNm0uS8uTJo5deeklBQUFatGiR3n//fSdXiEfJkSNHlDdvXj333HMKDg5WWFiYvvzySxUuXFizZs3SjBkznF0iHgHR0dH64Ycf1KNHD61YsUJLlixR586dFRMT4+zS0j1CqXQoMWzKlSuXFi1apBdeeEFvvvmm1q1bp1q1aunHH390coV4FGTLlk2vvfaaoqOj9corr6hhw4YqW7asPv74Y61evVp//fWXRo8erX379jm7VDwifHx85OLiotWrV+u9995T06ZNtXDhQu3atUv9+vXT5s2b9eGHHzq7TDwCChcurGXLlqlZs2ZKSEiQJL3++usKCgrSqFGjWKmLJNzd3RUTE6M5c+bozp07atq0qY4dO6bcuXMrc+bM+vbbb9WzZ09nl4lHxMWLF3X16lXduXNHbm53L/w4f/68ypYtq/DwcK1YsULHjh1zcpV4VGTOnFk3btyw3XcsISFBoaGhGjRokIKCgvT999/r9OnTTq4Szubl5aUaNWqoadOmqlu3rpYuXaqVK1cSTJmAUCodSvy/z8HBwdqzZ48kqX379jp37pzi4+NVq1YtHT161JklwskMw1BgYKB69Oihpk2basWKFXr66ac1YsQIPfvss6pdu7a+/fZbbd++Xb/88ouzy8UjwGq1ymq1qnLlylq/fr1OnTqlZ555Rt7e3sqZM6datmypp59+Wtu3b7eFEMiYrFarnnjiCdWvX1+S5OrqKkny9/dXlSpVtHbtWtsNRFkthUSVKlVS0aJF1b9/fzVo0ECbNm3S2rVrNWTIEE2aNEkvvfSSfv31V50/f97ZpeIRUK9ePW3ZskVDhgzRypUrNXXqVPXs2VN9+vRRRESEDh06ZPsdGChZsqTOnz+vmTNnSpJcXFxktVqVP39+RUREaM2aNVq1apWTq4Sz+fn5qU2bNqpWrZqkuz+XlixZYgumrl27Jkm6evWqtm7d6sxS0x1CqXTgzp07do8T/+9zjRo15Ofnp1u3bql06dIqWrSoBg4cqP379+v999/XyZMnnVEunOjeXjEMQ7ly5dKrr76qwYMHq0uXLnJ3d5fFYpHValXBggVVuHBh/gDIwO7tFxcXF7m5ualjx4765ZdftG7dOrtw29PTU0WKFFFsbKysVqszyoWTJfZLciugDMOQm5ub3n77bf3+++/68ssv7zsWGUNivxiGIcMwVKhQIU2aNEnr1q1T06ZNVbZsWRUuXNg2Pm/evHJxcVGmTJmcVTKc6N5+sVqtql69umbNmqUvv/xS3bt31/vvv6/vv/9eTz/9tDJnzqygoCBdvnzZyVXDWWJiYnTu3DlJd3umePHi+vjjjzVw4EBNnTpVFotFFotFhmGoSJEiqly5siIjI51bNJzi3l6R7q6qu1flypVtwVSXLl109OhRNWrUyPZ7DFIHodRjbsmSJZo0aVKy7w7g5uamtWvXKjAwUNmyZdPcuXP11ltvqXXr1vL09FRwcLD5BcNp7u2Ve292HxgYqNatW6tChQq2sS4uLjp//rwsFovdHwXIOP75vSXxD4HKlStrwYIF8vDw0BdffKE5c+ZIuvt/jVauXKlChQrxR2MGlNz3l3slht358+fX//73Py1ZsoQbWGdg9/t5FBQUpNDQUAUEBMjV1VWXLl2SJMXFxWnevHkqVqyY/Pz8nFk6nOCf/ZIYJrRs2VLbtm3TqlWrtHnzZrVq1UqS9Oeff8rT01O5c+d2cuVwhlmzZqlZs2Z64oknVLt2bS1fvlxWq1UdO3bUwIED1alTJ40ZM0bXr1+XxWLRzZs3deXKFWXNmtXZpcNk/+yVFStWJFnBbRiGKleurGXLlmnlypUqWbKkzp07pwkTJjip6nTKwGNr7ty5hsViMfLmzWtMnjzZuHr1qmEYhmG1Wm1j+vXrZ7zwwgtGdHS03bGJYxISEswrGE6Tkl5JdPv2bePy5cvGM888Yzz11FPGnTt3zC4XTna/fklISLB9z/j111+NsLAwIzQ01ChYsKDxxBNPGGXKlDHi4+MNw0i+t5A+3a9f7mf+/PmGxWIxtm3bZlKFeJSkpF927NhheHl5GU2bNjU6duxo1K9fn+8vGdSDfh79sw/i4+ONyMhI45lnnjEqVarE7y8Z0Ndff234+voaI0eONGbPnm1Ur17dCAsLM27dumUYhmHcvHnT+PTTTw03NzcjPDzceO6554xatWoZJUqUMG7fvu3k6mGm5HqlYsWKtl75pytXrhglS5Y0qlWrZusVeib1WAyDGzo8jo4fP6527dqpTp06OnXqlNatW6e+ffuqdevW8vX1td1E9vz588qcObO8vb0lye5tuA1uNJsh/Fuv3CshIUGjR4/WggULFB8fr40bNypTpkxKSEiw3RcG6du/9UvipXkuLi46efKkjh07pm3btik4OFgtW7aUm5ub3Y1nkb458v0lUXx8vAYPHqyhQ4fSJxlMSn53MQxDLi4uWr9+vUaPHi2LxaICBQpoxIgRfH/JYBz9/rJhwwZNmDBBhw8f1ubNm/n9JYPZvXu3XnrpJfXs2VOdOnWSJN24cUN58+bVxIkTbSvpJGnTpk1asGCBzp49q9y5c9t+HtEvGcODemXSpElq2bKl3fi4uDh16NBB69ev14kTJ5QpUyZ+FqUyXsnHlKenpxo0aKCGDRuqQoUKevXVVzVq1ChJsvthHRAQIOnvACoxkJK4l0dGkdJeke7ekLhevXq6ceOG3n33Xf4AyIBS0i+Jfzjmz59f+fPn19NPP207PiEhgX7JQBz5/iLd/Vnk7u6u4cOHSxLfXzKYlPaL1WpVjRo1FBYWZnd/D76/ZCyOfn8pWrSounTpourVq8vV1ZXvLxnM0aNHVbBgQTVo0EDS3Z8vHh4eKlCgQJI316hSpYoqVapk93cR/ZJxPKhX4uPjk4y/ffu2WrVqpa+//pq/jdIIK6UeY5cuXVK2bNlsj7t06aI1a9borbfeUps2beTr66urV6/K1dVVPj4+TqwUzpaSXrly5YpcXFzsfsnj/xhlTHxvgSPoFzgipT+PXF1dlSVLFts4VndnTCn9/uLi4mLXL/deGYCM4fr16/rll1/UpEkTSX//DtuwYUO1bNlSHTp0sI2Nj4+Xu7u7s0qFk/2XXuFvo7TBd+vHWOIP6cT0f/Lkyapdu7Y++eQTzZo1S3/88YdeeOEFffDBB84sE4+AlPRK69at9eGHH0r6+/8k8U03Y+J7CxxBv8ARjv48SkQglTGl9PvLP/uFQCpjsVqtypw5sy1kMAzD9jtsbGysoqOjbdu7d++uBQsWOKtUONl/7RX+NkobrJRKJ+5Nbbt27arVq1fr+vXr8vPz0++//867YcGGXoEj6Bc4gn6BI+gXOIJ+gSMSV1fWrVtXLVq00GuvvaaGDRvqwIEDOnbsGJdfwYZecT5CqcdASpesJ/6wvnbtmoKCglS2bFmtW7eOa18zEHoFjqBf4Aj6BY6gX+AI+gWOSEm/JPbK888/r/DwcC1dulQHDhzQ3r17uQl+BkKvPB4IpR4jt27dkqen5wOvk79y5Yrq1Kmja9eu6cCBA/yQzqDoFTiCfoEj6Bc4gn6BI+gXOCIl/RIeHq6VK1eqePHi2r17N++clkHRK482Lrh+TIwbN04NGzaU9ODr5DNnzqzmzZtr//79/JDOoOgVOIJ+gSPoFziCfoEj6Bc4IiX9YrValTVrVlWsWFF79uwhZMig6JVHH6HUY6JkyZI6c+aMfvvttweOy5Qpk9577z2+kDIwegWOoF/gCPoFjqBf4Aj6BY5ISb+4uLjoq6++0qZNmwgwMzB65dFHKPUISu6KysKFC8vLy0tr166975h/4gsp/aNX4Aj6BY6gX+AI+gWOoF/giIftl8R3WnN1dZXVaqVfMgB65fFEKPUISrwZ25UrV2zb8uXLp27dumn06NE6ePAgb40MSfQKHEO/wBH0CxxBv8AR9Asc8bD9cu+lWg+6JBTpB73yeOIVf4RYrVbbv8eOHatOnTpp/Pjxku6+K8Dzzz+vMmXK2FLehIQEZ5SJRwC9AkfQL3AE/QJH0C9wBP0CR9AvSCl65fFGKPUISUxlv/vuOx0+fFhBQUH64IMPVKtWLY0YMUKenp6qWLGiJk2aJEm8NWUGRq/AEfQLHEG/wBH0CxxBv8AR9AtSil55zBlwuoSEBNu/x44da+TIkcM4duyYYRiGER0dbbz11ltGtWrVjPz58xtvv/22YbFYjMmTJzurXDgRvQJH0C9wBP0CR9AvcAT9AkfQL0gpeiV9YKXUIyAx2d29e7fOnDmjsWPHqkCBArpz545y5cqlkSNHavXq1XrjjTd05MgRubm5adGiRU6uGs5Ar8AR9AscQb/AEfQLHEG/wBH0C1KKXkknnJ2KwTCsVquxadMmw2KxGJkyZTJmzJhh23dv+msYhnHt2jVj5cqVhoeHh7Fw4UKzS4WT0StwBP0CR9AvcAT9AkfQL3AE/YKUolfSB1ZKPQIsFosqV66szz//XHfu3NGGDRt04cIFSX+nv8b/v3Vl5syZVbt2bYWHh2vv3r1OqxnOQa/AEfQLHEG/wBH0CxxBv8AR9AtSil5JH9ycXUBGZLVak32rya5du+rGjRvq06ePChYsqK5du8rX11fS329vabFY5OrqqqtXr+rEiROm1g3z0StwBP0CR9AvcAT9AkfQL3AE/YKUolfSJ0Ipk937hTR16lTt27dPhmEoLCxML774onr37q3bt2+rf//+slgsevXVV21fUIl27NihkydPasyYMU54BjALvQJH0C9wBP0CR9AvcAT9AkfQL0gpeiUdM/+KQRiGYfTt29fIli2b0b59eyMsLMwoWbKk0axZM9v+jz/+2HBzczPef/994/r163bHXrx40Th37pzZJcNJ6BU4gn6BI+gXOIJ+gSPoFziCfkFK0SvpD6GUE6xfv94IDg42fv31V8MwDCM+Pt747rvvjLJlyxpt2rSxjRsyZIhRtWpVw2q1OqtUOBm9AkfQL3AE/QJH0C9wBP0CR9AvSCl6JX3iRudOEB0dLavVqhIlSkiSMmXKpKZNm+rVV1/VwYMHdfDgQUnSwIED9euvv8pisdhu0IaMhV6BI+gXOIJ+gSPoFziCfoEj6BekFL2SPhFKpbHkvgjy5s0rb29v7d6927bN29tbDRs21P79+3X48GHb9sQvpMQbtCH9olfgCPoFjqBf4Aj6BY6gX+AI+gUpRa9kHIRSaejeL4Jx48Zp3759kqTg4GB5eXlp0qRJdl84Hh4eKlGihLJkyWI3D19I6R+9AkfQL3AE/QJH0C9wBP0CR9AvSCl6JWOxGKxnSxP3vjvAoUOH1LZtW128eFErVqxQkSJFtG3bNjVu3FhPPvmkateurZIlS2r06NG6cOGCtm7dKldXVyc/A5iFXoEj6Bc4gn6BI+gXOIJ+gSPoF6QUvZLxEEqlscGDB2vLli26evWqtmzZorx582rx4sUqVaqUdu7cqQ8//FB79uyRj4+PcufOrYULFypTpkxKSEjgCyqDoVfgCPoFjqBf4Aj6BY6gX+AI+gUpRa9kIGl7H/WMbcKECUbmzJmNdevWGX/++acxf/58o06dOkaePHmMffv2GYZhGDExMcalS5eMU6dO2d4d4Pbt284sG05Ar8AR9AscQb/AEfQLHEG/wBH0C1KKXslYWCmVRhISEtS1a1dZrVZ99dVXtu1btmzRG2+8oXPnzmnlypUqVKiQ3XH3LldExkCvwBH0CxxBv8AR9AscQb/AEfQLUopeyXj4rKURV1dXeXh4aNeuXbpz545te6VKldSiRQudPHlSDRo0sN2gLTEb5Asp46FX4Aj6BY6gX+AI+gWOoF/gCPoFKUWvZDx85lKB1WpNdnvdunV1584dTZ8+XdevX7dtL1q0qNq2bavy5curV69eiomJ4Z0BMgh6BY6gX+AI+gWOoF/gCPoFjqBfkFL0CiTJzdkFPO7uXSY4d+5c/fnnn7pz544aNWqkZs2aadGiRfriiy8UExOjli1byt3dXV999ZVKliypQoUKaeDAgTp9+rR8fX2d/EyQ1ugVOIJ+gSPoFziCfoEj6Bc4gn5BStErsHHWzazSm759+xqBgYFG69atjbCwMKNUqVLGN998YyQkJBidOnUywsLCDA8PD6NYsWJGsWLFDMMwjL179xoFChQwDhw44OTqYSZ6BY6gX+AI+gWOoF/gCPoFjqBfkFL0ClgplQpmz56tWbNm6eeff1bFihX1zTff6JVXXpGHh4dcXFw0efJknTx5Ups2bZK/v7/q168vSZoyZYqyZcumXLlyOfkZwCz0ChxBv8AR9AscQb/AEfQLHEG/IKXoFUhipdTDSHzLycT/fvjhh0bLli0NwzCM2bNnG76+vsbEiRMNw7j7VpWHDh2yO37t2rVGt27djKxZsxq7d+82sXKYjV6BI+gXOIJ+gSPoFziCfoEj6BekFL2C5LBS6iEk3kzt9OnTypMnj27evKmQkBBt3rxZr7zyij7++GN17dpVhmFo7ty5unDhgvLmzavMmTNLkm7evKlTp05p/fr1KlWqlDOfCtIYvQJH0C9wBP0CR9AvcAT9AkfQL0gpegXJcl4e9viZP3++sXr1asMwDKNPnz5Gz549DcMwjBUrVhgWi8WwWCzGDz/8YBt//fp1o379+rZx97p+/boZJcNJ6BU4gn6BI+gXOIJ+gSPoFziCfkFK0St4EEKpFLp69arRtm1bw9PT02jVqpXh5eVl7Nq1y7Z/+PDhhoeHhzFt2jTj+PHjxq5du4zw8HCjfPnyxu3bt23jEpcqIv2iV+AI+gWOoF/gCPoFjqBf4Aj6BSlFr+DfEEo5IDo62ihYsKDh6upqTJ482TAMw/aFEhUVZQwcONDw8vIycufObZQtW9aoU6eOER8fbxiGYdy5c8dpdcN89AocQb/AEfQLHEG/wBH0CxxBvyCl6BU8iMUwDMPZlxA+6gzDkMViUXR0tF599VUlJCRo06ZNmj17turWrWvbL0mHDx/WhQsX5OPjo9KlS8vFxUV37tyRmxu378oI6BU4gn6BI+gXOIJ+gSPoFziCfkFK0StIEbNTsMdJQkJCsttOnDhhtGvXzsiaNauxcuVKu/2nT5/+1zmQ/tArcAT9AkfQL3AE/QJH0C9wBP2ClKJX4AgXZ4dijyqr1SoXl7svz6ZNm/Trr7/qt99+k4uLi0JCQtS/f381bdpUL7zwgpYvXy5JatGihT7//HO7eRLnQPpFr8AR9AscQb/AEfQLHEG/wBH0C1KKXoHDnJ2KPYruvYnaO++8YxQuXNgICQkxChUqZLzxxhu2fYcOHTI6d+5sWCwWo1y5ckbBggVt174iY6BX4Aj6BY6gX+AI+gWOoF/gCPoFKUWv4GEQSj3Ah//X3v3HVFX/cRx/na5C41oxt7KhUCOEFTBzNUzvxmzGNDODNbJVUijmDXNaWFv9xR+Rq+haNLqoG1d0ztqK2iSlFmUDquFgTG3o6Iejqa1M0YAiuny+f5h3XNO6n6/XS3afj40/OPec47l3T/55e+7nVFWZ6667zrS1tZnTp0+b559/3jiOY8rKykL7nDx50uzcudPU1taGFmsb+5QAxAdagQ16gQ16gQ16gQ16gQ16QaRoBTYYSl1AT0+PWbRokdm1a5cxxpimpiZzzTXXGK/Xa9xut3n88cfPexxPB4g/tAIb9AIb9AIb9AIb9AIb9IJI0QpsMZT6U3d3t3n//fdNW1ubMcaY3377zfj9fnPy5EnT2tpqpk2bZvx+vzHGmJUrVxrHcUxxcfF4XjLGCa3ABr3ABr3ABr3ABr3ABr0gUrSCi8XzFSVt375d1dXVSktLU3Z2tjwejxITE7VixQq5XC41NTVp7ty5KikpkSRNmzZNixcv1tDQUNhCbvjvoxXYoBfYoBfYoBfYoBfYoBdEilYQDXE/lNq6dau8Xq/q6+u1YMECJScnh15zuVwaHR3Vvn37JElJSUn69ddf1dXVpfvuu0+lpaWSxB9UnKAV2KAX2KAX2KAX2KAX2KAXRIpWEDXjfavWeDpw4IDJzs42mzdvDts+9qkBxhjT2NhoEhISTH5+vrn11ltNbm5uaBG2c/fFfxOtwAa9wAa9wAa9wAa9wAa9IFK0gmiK67HkkSNHNDQ0pPz8fBljQtsdx5Gk0LaFCxfq7bffVnp6uubPn6+uri5NmDBBwWAwtC/+22gFNugFNugFNugFNugFNugFkaIVRFNcf32vs7NTv/zyizIzMyWd+eMZ+8fhOI56enp04sQJFRYWqrCwMPTaH3/8oQkT4vrjiyu0Ahv0Ahv0Ahv0Ahv0Ahv0gkjRCqIpru+UysjI0ODgoD766CNJOu+0duvWrWpoaNDo6GjYdv6Q4gutwAa9wAa9wAa9wAa9wAa9IFK0gmiK66HUbbfdpoSEBG3atEl9fX2h7WdvNzx9+rR6e3uVm5vLAmxxjlZgg15gg15gg15gg15gg14QKVpBVF36Zav+3Xbs2GESExPNQw89ZLq6ukLbjxw5Yu6++27j8XhCi7EhvtEKbNALbNALbNALbNALbNALIkUriBbHmDErk8WhYDCoQCCg8vJyTZkyRTk5ORodHdWpU6c0Ojqq9vZ2TZw4UcFgUC6Xa7wvF+OIVmCDXmCDXmCDXmCDXmCDXhApWkG0xP1Q6qzu7m7V19fr0KFDSk1N1cyZM+X1euVyuViMDWFoBTboBTboBTboBTboBTboBZGiFVwshlL/gMkuIkUrsEEvsEEvsEEvsEEvsEEviBStIFIMpcYw5zzKErgQWoENeoENeoENeoENeoENekGkaAUXg6EUAAAAAAAAYo7nMwIAAAAAACDmGEoBAAAAAAAg5hhKAQAAAAAAIOYYSgEAAAAAACDmGEoBAAAAAAAg5hhKAQAAAAAAIOYYSgEAAAAAACDmGEoBAAAAAAAg5hhKAQAAWPrhhx+0evVqpaenKzExUampqbr33nvV0tIS0fFbtmxRcnLypb1IAACAf7kJ430BAAAAl5PDhw/L4/EoOTlZr7zyinJzczUyMqIPP/xQq1at0sGDB8f7Eq2NjIxo4sSJ430ZAAAgznCnFAAAgIXy8nI5jqOOjg7df//9yszMVHZ2tp5++ml9+eWXkiSfz6fc3Fy53W6lpqaqvLxcAwMDkqQ9e/aotLRUp06dkuM4chxHlZWVkqTh4WGtW7dOU6dOldvt1qxZs7Rnz56wf3/z5s1KTU1VUlKSioqK5PP5/nLXld/v10033aSEhARlZWVp27ZtYa87jiO/36/FixfL7XbrhRdeUEZGhqqrq8P26+7uluM4+vrrr6P3AQIAAPyJoRQAAECETpw4oebmZq1atUput/svr58dDl1xxRWqqanRV199pYaGBn3yySd69tlnJUlz5szRa6+9pquvvlrHjh3TsWPHtG7dOknSk08+qS+++EJvvfWW9u3bp+LiYi1YsEC9vb2SpPb2dnm9Xq1Zs0bd3d0qKChQVVVV2DW89957WrNmjSoqKnTgwAGtXLlSpaWl+vTTT8P2q6ysVFFRkfbv36/ly5dr2bJlCgQCYfsEAgHl5+crIyMjKp8fAADAWI4xxoz3RQAAAFwOOjo6NGvWLDU2NqqoqCji49555x15vV4dP35c0pk1pdauXav+/v7QPn19fUpPT1dfX59SUlJC2++66y7l5eXpxRdf1IMPPqiBgQE1NTWFXn/kkUfU1NQUOpfH41F2drY2bdoU2ueBBx7Q4OCgPvjgA0ln7pRau3atNmzYENrn6NGjSktL0+eff668vDyNjIwoJSVF1dXVevTRR60+JwAAgEhwpxQAAECEIv2/vI8//ljz5s3T1KlTddVVV2np0qX6+eefNTQ0dMFj9u/fr2AwqMzMTE2aNCn089lnn+mbb76RJB06dEh5eXlhx537e09PjzweT9g2j8ejnp6esG2333572O8pKSm65557VF9fL0nauXOnhoeHVVxcHNF7BgAAsMVC5wAAABGaPn26HMf528XMDx8+rEWLFumJJ55QVVWVJk+erLa2Ni1fvly///67kpKSznvcwMCAXC6XOjs75XK5wl6bNGlSVN+HpPN+/bCsrExLly7Vhg0bFAgEtGTJkgteLwAAwMXiTikAAIAITZ48WfPnz1dtba0GBwf/8np/f786Ozs1OjqqV199VXfccYcyMzN19OjRsP0SEhIUDAbDts2cOVPBYFA//vijMjIywn6uv/56SVJWVpb27t0bdty5v998881qb28P29be3q5bbrnlH9/fwoUL5Xa75ff71dzcrGXLlv3jMQAAAP8vhlIAAAAWamtrFQwGlZeXp3fffVe9vb3q6elRTU2NZs+erYyMDI2MjOiNN97Qt99+q23btqmuri7sHDfeeKMGBgbU0tKi48ePa2hoSJmZmXr44YdVUlKixsZGfffdd+ro6ND69etDa0GtXr1au3btks/nU29vrzZu3Kjdu3fLcZzQuZ955hlt2bJFfr9fvb298vl8amxsDC2m/ndcLpcee+wxPffcc5o+fbpmz54d3Q8PAABgDIZSAAAAFtLT09XV1aU777xTFRUVysnJUUFBgVpaWuT3+zVjxgz5fD699NJLysnJ0fbt27V+/fqwc8yZM0der1dLlizRtddeq5dfflnSmafdlZSUqKKiQllZWSosLNTevXuVlpYm6czaUHV1dfL5fJoxY4aam5v11FNP6corrwydu7CwUK+//rqqq6uVnZ2tjRs3KhAIaO7cuRG9v7NfMywtLY3OBwYAAHABPH0PAADgMrZixQodPHhQra2tUTlfa2ur5s2bp++//15TpkyJyjkBAADOh4XOAQAALiPV1dUqKCiQ2+3W7t271dDQoDfffPOizzs8PKyffvpJlZWVKi4uZiAFAAAuOb6+BwAAcBnp6OhQQUGBcnNzVVdXp5qaGpWVlV30eXfs2KEbbrhB/f39oa8TAgAAXEp8fQ8AAAAAAAAxx51SAAAAAAAAiDmGUgAAAAAAAIg5hlIAAAAAAACIOYZSAAAAAAAAiDmGUgAAAAAAAIg5hlIAAAAAAACIOYZSAAAAAAAAiDmGUgAAAAAAAIg5hlIAAAAAAACIuf8BQGK2QdiW+GUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x600 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nResults saved to 'scibert_evaluation_results.csv'\nGraphs saved as 'f1_score_comparison.png' and 'accuracy_comparison.png'\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "-HQ_LMp3MjnL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Jhz90RtPMjnL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "RcrDkyR9MjnM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "qYLfADKDMjnM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Jl_HQF9LMjnM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Roto_NBRMjnM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "gYnh2VgsMjnM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "CW_Z9r-2MjnN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "mNq2_99WMjnN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_dataset_with_scibert(df, dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Evaluate a dataset using SciBERT for Categories 14-21\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with 'Justification' column and Category 14-21 columns\n",
        "        dataset_name: Name for display purposes\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"SciBERT Evaluation on {dataset_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # --------------------- 1. Prepare Data ---------------------\n",
        "    category_cols = [f\"Category {i}\" for i in range(14, 22)]\n",
        "\n",
        "    # Use Justification column for SciBERT evaluation\n",
        "    X_texts = df[\"Justification\"].fillna(\"\").astype(str).tolist()\n",
        "    Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "    print(f\"Dataset size: {len(df)}\")\n",
        "    print(f\"Categories evaluated: {category_cols}\")\n",
        "\n",
        "    # Check for empty dataset\n",
        "    if len(X_texts) == 0:\n",
        "        print(f\"Warning: {dataset_name} is empty!\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # --------------------- 2. Split (20/80) Train/Val ---------------------\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Validation samples: {len(X_val)}\")\n",
        "\n",
        "    # --------------------- 3. Custom Dataset ---------------------\n",
        "    class MultiLabelDataset(Dataset):\n",
        "        def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "            self.texts = texts\n",
        "            self.labels = labels\n",
        "            self.tokenizer = tokenizer\n",
        "            self.max_length = max_length\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.texts)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            text = self.texts[idx]\n",
        "            label = self.labels[idx]\n",
        "            encoding = self.tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_length,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "            item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "            return item\n",
        "\n",
        "    # --------------------- 4. Load SciBERT ---------------------\n",
        "    model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=len(category_cols),\n",
        "        problem_type=\"multi_label_classification\"\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # --------------------- 5. DataLoaders ---------------------\n",
        "    batch_size = 8\n",
        "\n",
        "    train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "    val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # --------------------- 6. Optimizer & Loss ---------------------\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # --------------------- 7. Training Loop ---------------------\n",
        "    epochs = 5\n",
        "    print(f\"\\nTraining for {epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "        for batch in loop:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = loss_fn(outputs.logits, labels)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # --------------------- 8. Evaluation ---------------------\n",
        "    print(\"Evaluating model...\")\n",
        "    model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).int()\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_probs.append(probs.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    Y_pred = torch.cat(all_preds).numpy()\n",
        "    Y_prob = torch.cat(all_probs).numpy()\n",
        "    Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "    # --------------------- 9. Metrics ---------------------\n",
        "    results = []\n",
        "    for i, cat in enumerate(category_cols):\n",
        "        acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "        prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "    results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "    results_df[\"Dataset\"] = dataset_name  # Add dataset identifier\n",
        "\n",
        "    print(f\"\\nSciBERT Evaluation Results for {dataset_name}:\")\n",
        "    print(results_df[[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]])\n",
        "\n",
        "    # Clear GPU memory\n",
        "    del model, optimizer, train_dataset, val_dataset\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    return results_df\n",
        "\n",
        "def compare_all_datasets(initial_df, generated_df, merged_df):\n",
        "    \"\"\"\n",
        "    Compare SciBERT performance across all three datasets\n",
        "    \"\"\"\n",
        "    print(\"Starting comprehensive SciBERT evaluation...\")\n",
        "    print(\"This will evaluate: Initial → Generated → Merged datasets\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # Evaluate Initial Dataset\n",
        "    if len(initial_df) > 0:\n",
        "        initial_results = evaluate_dataset_with_scibert(initial_df, \"Initial Dataset\")\n",
        "        all_results.append(initial_results)\n",
        "\n",
        "    # Evaluate Generated Dataset\n",
        "    if len(generated_df) > 0:\n",
        "        generated_results = evaluate_dataset_with_scibert(generated_df, \"Generated Dataset\")\n",
        "        all_results.append(generated_results)\n",
        "\n",
        "    # Evaluate Merged Dataset\n",
        "    if len(merged_df) > 0:\n",
        "        merged_results = evaluate_dataset_with_scibert(merged_df, \"Merged Dataset\")\n",
        "        all_results.append(merged_results)\n",
        "\n",
        "    # Combine all results for comparison\n",
        "    if all_results:\n",
        "        comparison_df = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"COMPREHENSIVE COMPARISON - All Datasets\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Pivot for easier comparison\n",
        "        comparison_pivot = comparison_df.pivot_table(\n",
        "            index='Category',\n",
        "            columns='Dataset',\n",
        "            values=['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
        "            aggfunc='first'\n",
        "        )\n",
        "\n",
        "        print(\"\\nF1 Score Comparison:\")\n",
        "        if 'F1 Score' in comparison_pivot.columns.levels[0]:\n",
        "            print(comparison_pivot['F1 Score'].round(4))\n",
        "\n",
        "        print(\"\\nAccuracy Comparison:\")\n",
        "        if 'Accuracy' in comparison_pivot.columns.levels[0]:\n",
        "            print(comparison_pivot['Accuracy'].round(4))\n",
        "\n",
        "        # Save comprehensive results\n",
        "        comparison_df.to_csv('scibert_evaluation_results.csv', index=False)\n",
        "        print(f\"\\nResults saved to 'scibert_evaluation_results.csv'\")\n",
        "\n",
        "        return comparison_df\n",
        "\n",
        "    return pd.DataFrame()\n",
        "\n",
        "\n",
        "# df = initial_df  # ← CHANGE THIS LINE to switch datasets\n",
        "results = evaluate_dataset_with_scibert(df, \"Initial Dataset\")\n",
        "\n",
        "# initial_df = pd.read_csv('your_initial_dataset.csv')\n",
        "# generated_df = pd.read_csv('generated_augmented_data.csv')\n",
        "# merged_df = pd.read_csv('merged_dataset.csv')\n",
        "# comparison_results = compare_all_datasets(initial_df, generated_df, merged_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T21:25:45.175194Z",
          "iopub.execute_input": "2025-08-07T21:25:45.175847Z",
          "iopub.status.idle": "2025-08-07T21:32:34.020040Z",
          "shell.execute_reply.started": "2025-08-07T21:25:45.175820Z",
          "shell.execute_reply": "2025-08-07T21:32:34.019414Z"
        },
        "colab": {
          "referenced_widgets": [
            "ce13f60c946e4354bd6e39b2941d03d2",
            "432a3d9fd1c34691b903ded19e477ec8",
            "0197be498dfa41bb88ff496258458457",
            "9b648510844e4be697a386751f434fdd"
          ]
        },
        "id": "G4cunlW8MjnN",
        "outputId": "f26474c2-929d-40b3-a5cd-099d01a56847"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n============================================================\nSciBERT Evaluation on Initial Dataset\n============================================================\nDataset size: 1023\nCategories evaluated: ['Category 14', 'Category 15', 'Category 16', 'Category 17', 'Category 18', 'Category 19', 'Category 20', 'Category 21']\nTraining samples: 818\nValidation samples: 205\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce13f60c946e4354bd6e39b2941d03d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "432a3d9fd1c34691b903ded19e477ec8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0197be498dfa41bb88ff496258458457"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b648510844e4be697a386751f434fdd"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Using device: cuda\n\nTraining for 5 epochs...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\nEpoch 1/5:   0%|          | 0/103 [00:00<?, ?it/s]\u001b[A\nEpoch 1/5:   0%|          | 0/103 [00:01<?, ?it/s, loss=0.729]\u001b[A\nEpoch 1/5:   1%|          | 1/103 [00:01<02:39,  1.57s/it, loss=0.729]\u001b[A\nEpoch 1/5:   1%|          | 1/103 [00:02<02:39,  1.57s/it, loss=0.651]\u001b[A\nEpoch 1/5:   2%|▏         | 2/103 [00:02<01:47,  1.06s/it, loss=0.651]\u001b[A\nEpoch 1/5:   2%|▏         | 2/103 [00:02<01:47,  1.06s/it, loss=0.634]\u001b[A\nEpoch 1/5:   3%|▎         | 3/103 [00:02<01:30,  1.11it/s, loss=0.634]\u001b[A\nEpoch 1/5:   3%|▎         | 3/103 [00:03<01:30,  1.11it/s, loss=0.593]\u001b[A\nEpoch 1/5:   4%|▍         | 4/103 [00:03<01:21,  1.21it/s, loss=0.593]\u001b[A\nEpoch 1/5:   4%|▍         | 4/103 [00:04<01:21,  1.21it/s, loss=0.573]\u001b[A\nEpoch 1/5:   5%|▍         | 5/103 [00:04<01:16,  1.27it/s, loss=0.573]\u001b[A\nEpoch 1/5:   5%|▍         | 5/103 [00:05<01:16,  1.27it/s, loss=0.544]\u001b[A\nEpoch 1/5:   6%|▌         | 6/103 [00:05<01:13,  1.32it/s, loss=0.544]\u001b[A\nEpoch 1/5:   6%|▌         | 6/103 [00:05<01:13,  1.32it/s, loss=0.505]\u001b[A\nEpoch 1/5:   7%|▋         | 7/103 [00:05<01:11,  1.34it/s, loss=0.505]\u001b[A\nEpoch 1/5:   7%|▋         | 7/103 [00:06<01:11,  1.34it/s, loss=0.493]\u001b[A\nEpoch 1/5:   8%|▊         | 8/103 [00:06<01:10,  1.35it/s, loss=0.493]\u001b[A\nEpoch 1/5:   8%|▊         | 8/103 [00:07<01:10,  1.35it/s, loss=0.47] \u001b[A\nEpoch 1/5:   9%|▊         | 9/103 [00:07<01:08,  1.37it/s, loss=0.47]\u001b[A\nEpoch 1/5:   9%|▊         | 9/103 [00:07<01:08,  1.37it/s, loss=0.444]\u001b[A\nEpoch 1/5:  10%|▉         | 10/103 [00:07<01:07,  1.38it/s, loss=0.444]\u001b[A\nEpoch 1/5:  10%|▉         | 10/103 [00:08<01:07,  1.38it/s, loss=0.5]  \u001b[A\nEpoch 1/5:  11%|█         | 11/103 [00:08<01:06,  1.39it/s, loss=0.5]\u001b[A\nEpoch 1/5:  11%|█         | 11/103 [00:09<01:06,  1.39it/s, loss=0.434]\u001b[A\nEpoch 1/5:  12%|█▏        | 12/103 [00:09<01:05,  1.39it/s, loss=0.434]\u001b[A\nEpoch 1/5:  12%|█▏        | 12/103 [00:10<01:05,  1.39it/s, loss=0.388]\u001b[A\nEpoch 1/5:  13%|█▎        | 13/103 [00:10<01:04,  1.40it/s, loss=0.388]\u001b[A\nEpoch 1/5:  13%|█▎        | 13/103 [00:10<01:04,  1.40it/s, loss=0.476]\u001b[A\nEpoch 1/5:  14%|█▎        | 14/103 [00:10<01:03,  1.39it/s, loss=0.476]\u001b[A\nEpoch 1/5:  14%|█▎        | 14/103 [00:11<01:03,  1.39it/s, loss=0.379]\u001b[A\nEpoch 1/5:  15%|█▍        | 15/103 [00:11<01:03,  1.40it/s, loss=0.379]\u001b[A\nEpoch 1/5:  15%|█▍        | 15/103 [00:12<01:03,  1.40it/s, loss=0.423]\u001b[A\nEpoch 1/5:  16%|█▌        | 16/103 [00:12<01:02,  1.40it/s, loss=0.423]\u001b[A\nEpoch 1/5:  16%|█▌        | 16/103 [00:12<01:02,  1.40it/s, loss=0.45] \u001b[A\nEpoch 1/5:  17%|█▋        | 17/103 [00:12<01:01,  1.39it/s, loss=0.45]\u001b[A\nEpoch 1/5:  17%|█▋        | 17/103 [00:13<01:01,  1.39it/s, loss=0.371]\u001b[A\nEpoch 1/5:  17%|█▋        | 18/103 [00:13<01:01,  1.39it/s, loss=0.371]\u001b[A\nEpoch 1/5:  17%|█▋        | 18/103 [00:14<01:01,  1.39it/s, loss=0.493]\u001b[A\nEpoch 1/5:  18%|█▊        | 19/103 [00:14<01:00,  1.39it/s, loss=0.493]\u001b[A\nEpoch 1/5:  18%|█▊        | 19/103 [00:15<01:00,  1.39it/s, loss=0.457]\u001b[A\nEpoch 1/5:  19%|█▉        | 20/103 [00:15<00:59,  1.39it/s, loss=0.457]\u001b[A\nEpoch 1/5:  19%|█▉        | 20/103 [00:15<00:59,  1.39it/s, loss=0.362]\u001b[A\nEpoch 1/5:  20%|██        | 21/103 [00:15<00:59,  1.38it/s, loss=0.362]\u001b[A\nEpoch 1/5:  20%|██        | 21/103 [00:16<00:59,  1.38it/s, loss=0.403]\u001b[A\nEpoch 1/5:  21%|██▏       | 22/103 [00:16<00:58,  1.38it/s, loss=0.403]\u001b[A\nEpoch 1/5:  21%|██▏       | 22/103 [00:17<00:58,  1.38it/s, loss=0.476]\u001b[A\nEpoch 1/5:  22%|██▏       | 23/103 [00:17<00:58,  1.37it/s, loss=0.476]\u001b[A\nEpoch 1/5:  22%|██▏       | 23/103 [00:18<00:58,  1.37it/s, loss=0.399]\u001b[A\nEpoch 1/5:  23%|██▎       | 24/103 [00:18<00:57,  1.37it/s, loss=0.399]\u001b[A\nEpoch 1/5:  23%|██▎       | 24/103 [00:18<00:57,  1.37it/s, loss=0.502]\u001b[A\nEpoch 1/5:  24%|██▍       | 25/103 [00:18<00:56,  1.37it/s, loss=0.502]\u001b[A\nEpoch 1/5:  24%|██▍       | 25/103 [00:19<00:56,  1.37it/s, loss=0.398]\u001b[A\nEpoch 1/5:  25%|██▌       | 26/103 [00:19<00:56,  1.37it/s, loss=0.398]\u001b[A\nEpoch 1/5:  25%|██▌       | 26/103 [00:20<00:56,  1.37it/s, loss=0.432]\u001b[A\nEpoch 1/5:  26%|██▌       | 27/103 [00:20<00:55,  1.37it/s, loss=0.432]\u001b[A\nEpoch 1/5:  26%|██▌       | 27/103 [00:20<00:55,  1.37it/s, loss=0.429]\u001b[A\nEpoch 1/5:  27%|██▋       | 28/103 [00:20<00:54,  1.37it/s, loss=0.429]\u001b[A\nEpoch 1/5:  27%|██▋       | 28/103 [00:21<00:54,  1.37it/s, loss=0.426]\u001b[A\nEpoch 1/5:  28%|██▊       | 29/103 [00:21<00:53,  1.38it/s, loss=0.426]\u001b[A\nEpoch 1/5:  28%|██▊       | 29/103 [00:22<00:53,  1.38it/s, loss=0.406]\u001b[A\nEpoch 1/5:  29%|██▉       | 30/103 [00:22<00:53,  1.37it/s, loss=0.406]\u001b[A\nEpoch 1/5:  29%|██▉       | 30/103 [00:23<00:53,  1.37it/s, loss=0.324]\u001b[A\nEpoch 1/5:  30%|███       | 31/103 [00:23<00:52,  1.37it/s, loss=0.324]\u001b[A\nEpoch 1/5:  30%|███       | 31/103 [00:23<00:52,  1.37it/s, loss=0.452]\u001b[A\nEpoch 1/5:  31%|███       | 32/103 [00:23<00:51,  1.37it/s, loss=0.452]\u001b[A\nEpoch 1/5:  31%|███       | 32/103 [00:24<00:51,  1.37it/s, loss=0.406]\u001b[A\nEpoch 1/5:  32%|███▏      | 33/103 [00:24<00:51,  1.36it/s, loss=0.406]\u001b[A\nEpoch 1/5:  32%|███▏      | 33/103 [00:25<00:51,  1.36it/s, loss=0.397]\u001b[A\nEpoch 1/5:  33%|███▎      | 34/103 [00:25<00:50,  1.36it/s, loss=0.397]\u001b[A\nEpoch 1/5:  33%|███▎      | 34/103 [00:26<00:50,  1.36it/s, loss=0.459]\u001b[A\nEpoch 1/5:  34%|███▍      | 35/103 [00:26<00:50,  1.36it/s, loss=0.459]\u001b[A\nEpoch 1/5:  34%|███▍      | 35/103 [00:26<00:50,  1.36it/s, loss=0.469]\u001b[A\nEpoch 1/5:  35%|███▍      | 36/103 [00:26<00:49,  1.35it/s, loss=0.469]\u001b[A\nEpoch 1/5:  35%|███▍      | 36/103 [00:27<00:49,  1.35it/s, loss=0.332]\u001b[A\nEpoch 1/5:  36%|███▌      | 37/103 [00:27<00:49,  1.35it/s, loss=0.332]\u001b[A\nEpoch 1/5:  36%|███▌      | 37/103 [00:28<00:49,  1.35it/s, loss=0.437]\u001b[A\nEpoch 1/5:  37%|███▋      | 38/103 [00:28<00:48,  1.35it/s, loss=0.437]\u001b[A\nEpoch 1/5:  37%|███▋      | 38/103 [00:29<00:48,  1.35it/s, loss=0.339]\u001b[A\nEpoch 1/5:  38%|███▊      | 39/103 [00:29<00:47,  1.35it/s, loss=0.339]\u001b[A\nEpoch 1/5:  38%|███▊      | 39/103 [00:29<00:47,  1.35it/s, loss=0.363]\u001b[A\nEpoch 1/5:  39%|███▉      | 40/103 [00:29<00:46,  1.34it/s, loss=0.363]\u001b[A\nEpoch 1/5:  39%|███▉      | 40/103 [00:30<00:46,  1.34it/s, loss=0.372]\u001b[A\nEpoch 1/5:  40%|███▉      | 41/103 [00:30<00:46,  1.34it/s, loss=0.372]\u001b[A\nEpoch 1/5:  40%|███▉      | 41/103 [00:31<00:46,  1.34it/s, loss=0.369]\u001b[A\nEpoch 1/5:  41%|████      | 42/103 [00:31<00:45,  1.34it/s, loss=0.369]\u001b[A\nEpoch 1/5:  41%|████      | 42/103 [00:32<00:45,  1.34it/s, loss=0.369]\u001b[A\nEpoch 1/5:  42%|████▏     | 43/103 [00:32<00:44,  1.34it/s, loss=0.369]\u001b[A\nEpoch 1/5:  42%|████▏     | 43/103 [00:32<00:44,  1.34it/s, loss=0.369]\u001b[A\nEpoch 1/5:  43%|████▎     | 44/103 [00:32<00:43,  1.35it/s, loss=0.369]\u001b[A\nEpoch 1/5:  43%|████▎     | 44/103 [00:33<00:43,  1.35it/s, loss=0.352]\u001b[A\nEpoch 1/5:  44%|████▎     | 45/103 [00:33<00:43,  1.34it/s, loss=0.352]\u001b[A\nEpoch 1/5:  44%|████▎     | 45/103 [00:34<00:43,  1.34it/s, loss=0.359]\u001b[A\nEpoch 1/5:  45%|████▍     | 46/103 [00:34<00:42,  1.34it/s, loss=0.359]\u001b[A\nEpoch 1/5:  45%|████▍     | 46/103 [00:35<00:42,  1.34it/s, loss=0.445]\u001b[A\nEpoch 1/5:  46%|████▌     | 47/103 [00:35<00:41,  1.34it/s, loss=0.445]\u001b[A\nEpoch 1/5:  46%|████▌     | 47/103 [00:35<00:41,  1.34it/s, loss=0.472]\u001b[A\nEpoch 1/5:  47%|████▋     | 48/103 [00:35<00:41,  1.34it/s, loss=0.472]\u001b[A\nEpoch 1/5:  47%|████▋     | 48/103 [00:36<00:41,  1.34it/s, loss=0.389]\u001b[A\nEpoch 1/5:  48%|████▊     | 49/103 [00:36<00:40,  1.34it/s, loss=0.389]\u001b[A\nEpoch 1/5:  48%|████▊     | 49/103 [00:37<00:40,  1.34it/s, loss=0.298]\u001b[A\nEpoch 1/5:  49%|████▊     | 50/103 [00:37<00:39,  1.34it/s, loss=0.298]\u001b[A\nEpoch 1/5:  49%|████▊     | 50/103 [00:38<00:39,  1.34it/s, loss=0.34] \u001b[A\nEpoch 1/5:  50%|████▉     | 51/103 [00:38<00:39,  1.33it/s, loss=0.34]\u001b[A\nEpoch 1/5:  50%|████▉     | 51/103 [00:38<00:39,  1.33it/s, loss=0.353]\u001b[A\nEpoch 1/5:  50%|█████     | 52/103 [00:38<00:38,  1.33it/s, loss=0.353]\u001b[A\nEpoch 1/5:  50%|█████     | 52/103 [00:39<00:38,  1.33it/s, loss=0.41] \u001b[A\nEpoch 1/5:  51%|█████▏    | 53/103 [00:39<00:37,  1.32it/s, loss=0.41]\u001b[A\nEpoch 1/5:  51%|█████▏    | 53/103 [00:40<00:37,  1.32it/s, loss=0.364]\u001b[A\nEpoch 1/5:  52%|█████▏    | 54/103 [00:40<00:37,  1.32it/s, loss=0.364]\u001b[A\nEpoch 1/5:  52%|█████▏    | 54/103 [00:41<00:37,  1.32it/s, loss=0.353]\u001b[A\nEpoch 1/5:  53%|█████▎    | 55/103 [00:41<00:36,  1.32it/s, loss=0.353]\u001b[A\nEpoch 1/5:  53%|█████▎    | 55/103 [00:41<00:36,  1.32it/s, loss=0.266]\u001b[A\nEpoch 1/5:  54%|█████▍    | 56/103 [00:41<00:35,  1.31it/s, loss=0.266]\u001b[A\nEpoch 1/5:  54%|█████▍    | 56/103 [00:42<00:35,  1.31it/s, loss=0.407]\u001b[A\nEpoch 1/5:  55%|█████▌    | 57/103 [00:42<00:34,  1.32it/s, loss=0.407]\u001b[A\nEpoch 1/5:  55%|█████▌    | 57/103 [00:43<00:34,  1.32it/s, loss=0.373]\u001b[A\nEpoch 1/5:  56%|█████▋    | 58/103 [00:43<00:34,  1.31it/s, loss=0.373]\u001b[A\nEpoch 1/5:  56%|█████▋    | 58/103 [00:44<00:34,  1.31it/s, loss=0.268]\u001b[A\nEpoch 1/5:  57%|█████▋    | 59/103 [00:44<00:33,  1.32it/s, loss=0.268]\u001b[A\nEpoch 1/5:  57%|█████▋    | 59/103 [00:44<00:33,  1.32it/s, loss=0.369]\u001b[A\nEpoch 1/5:  58%|█████▊    | 60/103 [00:44<00:32,  1.31it/s, loss=0.369]\u001b[A\nEpoch 1/5:  58%|█████▊    | 60/103 [00:45<00:32,  1.31it/s, loss=0.445]\u001b[A\nEpoch 1/5:  59%|█████▉    | 61/103 [00:45<00:32,  1.31it/s, loss=0.445]\u001b[A\nEpoch 1/5:  59%|█████▉    | 61/103 [00:46<00:32,  1.31it/s, loss=0.243]\u001b[A\nEpoch 1/5:  60%|██████    | 62/103 [00:46<00:31,  1.31it/s, loss=0.243]\u001b[A\nEpoch 1/5:  60%|██████    | 62/103 [00:47<00:31,  1.31it/s, loss=0.297]\u001b[A\nEpoch 1/5:  61%|██████    | 63/103 [00:47<00:30,  1.30it/s, loss=0.297]\u001b[A\nEpoch 1/5:  61%|██████    | 63/103 [00:48<00:30,  1.30it/s, loss=0.287]\u001b[A\nEpoch 1/5:  62%|██████▏   | 64/103 [00:48<00:29,  1.30it/s, loss=0.287]\u001b[A\nEpoch 1/5:  62%|██████▏   | 64/103 [00:48<00:29,  1.30it/s, loss=0.332]\u001b[A\nEpoch 1/5:  63%|██████▎   | 65/103 [00:48<00:29,  1.30it/s, loss=0.332]\u001b[A\nEpoch 1/5:  63%|██████▎   | 65/103 [00:49<00:29,  1.30it/s, loss=0.405]\u001b[A\nEpoch 1/5:  64%|██████▍   | 66/103 [00:49<00:28,  1.30it/s, loss=0.405]\u001b[A\nEpoch 1/5:  64%|██████▍   | 66/103 [00:50<00:28,  1.30it/s, loss=0.413]\u001b[A\nEpoch 1/5:  65%|██████▌   | 67/103 [00:50<00:27,  1.30it/s, loss=0.413]\u001b[A\nEpoch 1/5:  65%|██████▌   | 67/103 [00:51<00:27,  1.30it/s, loss=0.347]\u001b[A\nEpoch 1/5:  66%|██████▌   | 68/103 [00:51<00:26,  1.30it/s, loss=0.347]\u001b[A\nEpoch 1/5:  66%|██████▌   | 68/103 [00:51<00:26,  1.30it/s, loss=0.354]\u001b[A\nEpoch 1/5:  67%|██████▋   | 69/103 [00:51<00:26,  1.30it/s, loss=0.354]\u001b[A\nEpoch 1/5:  67%|██████▋   | 69/103 [00:52<00:26,  1.30it/s, loss=0.346]\u001b[A\nEpoch 1/5:  68%|██████▊   | 70/103 [00:52<00:25,  1.30it/s, loss=0.346]\u001b[A\nEpoch 1/5:  68%|██████▊   | 70/103 [00:53<00:25,  1.30it/s, loss=0.355]\u001b[A\nEpoch 1/5:  69%|██████▉   | 71/103 [00:53<00:24,  1.29it/s, loss=0.355]\u001b[A\nEpoch 1/5:  69%|██████▉   | 71/103 [00:54<00:24,  1.29it/s, loss=0.43] \u001b[A\nEpoch 1/5:  70%|██████▉   | 72/103 [00:54<00:24,  1.29it/s, loss=0.43]\u001b[A\nEpoch 1/5:  70%|██████▉   | 72/103 [00:55<00:24,  1.29it/s, loss=0.31]\u001b[A\nEpoch 1/5:  71%|███████   | 73/103 [00:55<00:23,  1.29it/s, loss=0.31]\u001b[A\nEpoch 1/5:  71%|███████   | 73/103 [00:55<00:23,  1.29it/s, loss=0.331]\u001b[A\nEpoch 1/5:  72%|███████▏  | 74/103 [00:55<00:22,  1.28it/s, loss=0.331]\u001b[A\nEpoch 1/5:  72%|███████▏  | 74/103 [00:56<00:22,  1.28it/s, loss=0.328]\u001b[A\nEpoch 1/5:  73%|███████▎  | 75/103 [00:56<00:21,  1.28it/s, loss=0.328]\u001b[A\nEpoch 1/5:  73%|███████▎  | 75/103 [00:57<00:21,  1.28it/s, loss=0.292]\u001b[A\nEpoch 1/5:  74%|███████▍  | 76/103 [00:57<00:21,  1.28it/s, loss=0.292]\u001b[A\nEpoch 1/5:  74%|███████▍  | 76/103 [00:58<00:21,  1.28it/s, loss=0.387]\u001b[A\nEpoch 1/5:  75%|███████▍  | 77/103 [00:58<00:20,  1.27it/s, loss=0.387]\u001b[A\nEpoch 1/5:  75%|███████▍  | 77/103 [00:58<00:20,  1.27it/s, loss=0.268]\u001b[A\nEpoch 1/5:  76%|███████▌  | 78/103 [00:58<00:19,  1.27it/s, loss=0.268]\u001b[A\nEpoch 1/5:  76%|███████▌  | 78/103 [00:59<00:19,  1.27it/s, loss=0.296]\u001b[A\nEpoch 1/5:  77%|███████▋  | 79/103 [00:59<00:18,  1.27it/s, loss=0.296]\u001b[A\nEpoch 1/5:  77%|███████▋  | 79/103 [01:00<00:18,  1.27it/s, loss=0.42] \u001b[A\nEpoch 1/5:  78%|███████▊  | 80/103 [01:00<00:18,  1.27it/s, loss=0.42]\u001b[A\nEpoch 1/5:  78%|███████▊  | 80/103 [01:01<00:18,  1.27it/s, loss=0.23]\u001b[A\nEpoch 1/5:  79%|███████▊  | 81/103 [01:01<00:17,  1.27it/s, loss=0.23]\u001b[A\nEpoch 1/5:  79%|███████▊  | 81/103 [01:02<00:17,  1.27it/s, loss=0.275]\u001b[A\nEpoch 1/5:  80%|███████▉  | 82/103 [01:02<00:16,  1.26it/s, loss=0.275]\u001b[A\nEpoch 1/5:  80%|███████▉  | 82/103 [01:02<00:16,  1.26it/s, loss=0.457]\u001b[A\nEpoch 1/5:  81%|████████  | 83/103 [01:02<00:15,  1.26it/s, loss=0.457]\u001b[A\nEpoch 1/5:  81%|████████  | 83/103 [01:03<00:15,  1.26it/s, loss=0.248]\u001b[A\nEpoch 1/5:  82%|████████▏ | 84/103 [01:03<00:15,  1.26it/s, loss=0.248]\u001b[A\nEpoch 1/5:  82%|████████▏ | 84/103 [01:04<00:15,  1.26it/s, loss=0.321]\u001b[A\nEpoch 1/5:  83%|████████▎ | 85/103 [01:04<00:14,  1.25it/s, loss=0.321]\u001b[A\nEpoch 1/5:  83%|████████▎ | 85/103 [01:05<00:14,  1.25it/s, loss=0.304]\u001b[A\nEpoch 1/5:  83%|████████▎ | 86/103 [01:05<00:13,  1.25it/s, loss=0.304]\u001b[A\nEpoch 1/5:  83%|████████▎ | 86/103 [01:06<00:13,  1.25it/s, loss=0.527]\u001b[A\nEpoch 1/5:  84%|████████▍ | 87/103 [01:06<00:12,  1.25it/s, loss=0.527]\u001b[A\nEpoch 1/5:  84%|████████▍ | 87/103 [01:06<00:12,  1.25it/s, loss=0.461]\u001b[A\nEpoch 1/5:  85%|████████▌ | 88/103 [01:06<00:12,  1.25it/s, loss=0.461]\u001b[A\nEpoch 1/5:  85%|████████▌ | 88/103 [01:07<00:12,  1.25it/s, loss=0.334]\u001b[A\nEpoch 1/5:  86%|████████▋ | 89/103 [01:07<00:11,  1.24it/s, loss=0.334]\u001b[A\nEpoch 1/5:  86%|████████▋ | 89/103 [01:08<00:11,  1.24it/s, loss=0.327]\u001b[A\nEpoch 1/5:  87%|████████▋ | 90/103 [01:08<00:10,  1.24it/s, loss=0.327]\u001b[A\nEpoch 1/5:  87%|████████▋ | 90/103 [01:09<00:10,  1.24it/s, loss=0.288]\u001b[A\nEpoch 1/5:  88%|████████▊ | 91/103 [01:09<00:09,  1.24it/s, loss=0.288]\u001b[A\nEpoch 1/5:  88%|████████▊ | 91/103 [01:10<00:09,  1.24it/s, loss=0.286]\u001b[A\nEpoch 1/5:  89%|████████▉ | 92/103 [01:10<00:08,  1.24it/s, loss=0.286]\u001b[A\nEpoch 1/5:  89%|████████▉ | 92/103 [01:10<00:08,  1.24it/s, loss=0.256]\u001b[A\nEpoch 1/5:  90%|█████████ | 93/103 [01:10<00:08,  1.24it/s, loss=0.256]\u001b[A\nEpoch 1/5:  90%|█████████ | 93/103 [01:11<00:08,  1.24it/s, loss=0.254]\u001b[A\nEpoch 1/5:  91%|█████████▏| 94/103 [01:11<00:07,  1.24it/s, loss=0.254]\u001b[A\nEpoch 1/5:  91%|█████████▏| 94/103 [01:12<00:07,  1.24it/s, loss=0.407]\u001b[A\nEpoch 1/5:  92%|█████████▏| 95/103 [01:12<00:06,  1.24it/s, loss=0.407]\u001b[A\nEpoch 1/5:  92%|█████████▏| 95/103 [01:13<00:06,  1.24it/s, loss=0.31] \u001b[A\nEpoch 1/5:  93%|█████████▎| 96/103 [01:13<00:05,  1.23it/s, loss=0.31]\u001b[A\nEpoch 1/5:  93%|█████████▎| 96/103 [01:14<00:05,  1.23it/s, loss=0.276]\u001b[A\nEpoch 1/5:  94%|█████████▍| 97/103 [01:14<00:04,  1.23it/s, loss=0.276]\u001b[A\nEpoch 1/5:  94%|█████████▍| 97/103 [01:15<00:04,  1.23it/s, loss=0.282]\u001b[A\nEpoch 1/5:  95%|█████████▌| 98/103 [01:15<00:04,  1.23it/s, loss=0.282]\u001b[A\nEpoch 1/5:  95%|█████████▌| 98/103 [01:15<00:04,  1.23it/s, loss=0.208]\u001b[A\nEpoch 1/5:  96%|█████████▌| 99/103 [01:15<00:03,  1.23it/s, loss=0.208]\u001b[A\nEpoch 1/5:  96%|█████████▌| 99/103 [01:16<00:03,  1.23it/s, loss=0.269]\u001b[A\nEpoch 1/5:  97%|█████████▋| 100/103 [01:16<00:02,  1.23it/s, loss=0.269]\u001b[A\nEpoch 1/5:  97%|█████████▋| 100/103 [01:17<00:02,  1.23it/s, loss=0.216]\u001b[A\nEpoch 1/5:  98%|█████████▊| 101/103 [01:17<00:01,  1.23it/s, loss=0.216]\u001b[A\nEpoch 1/5:  98%|█████████▊| 101/103 [01:18<00:01,  1.23it/s, loss=0.336]\u001b[A\nEpoch 1/5:  99%|█████████▉| 102/103 [01:18<00:00,  1.23it/s, loss=0.336]\u001b[A\nEpoch 1/5:  99%|█████████▉| 102/103 [01:18<00:00,  1.23it/s, loss=0.159]\u001b[A\nEpoch 1/5: 100%|██████████| 103/103 [01:18<00:00,  1.57it/s, loss=0.159]\u001b[A\n                                                                        \u001b[A",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.3828\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.1323\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.0983\nEvaluating model...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 26/26 [00:06<00:00,  3.98it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nSciBERT Evaluation Results for Initial Dataset:\n      Category  Accuracy  Precision    Recall  F1 Score\n0  Category 14  0.882927   0.746988  0.953846  0.837838\n1  Category 15  0.960976   0.785714  0.916667  0.846154\n2  Category 16  0.902439   0.708333  0.850000  0.772727\n3  Category 17  0.902439   0.200000  0.142857  0.166667\n4  Category 18  0.975610   0.875000  0.636364  0.736842\n5  Category 19  0.956098   0.666667  0.615385  0.640000\n6  Category 20  0.917073   0.918919  0.708333  0.800000\n7  Category 21  0.882927   0.652174  0.483871  0.555556\nSciBERT evaluation functions ready!\n\nUsage Options:\n1. Single dataset: results = evaluate_dataset_with_scibert(df, 'Dataset Name')\n2. Compare all: comparison = compare_all_datasets(initial_df, generated_df, merged_df)\n\nTo switch datasets for single evaluation, just change the 'df' variable!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_dataset_with_scibert(df, dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Evaluate a dataset using SciBERT for Categories 14-21\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with 'Justification' column and Category 14-21 columns OR file path string\n",
        "        dataset_name: Name for display purposes\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"SciBERT Evaluation on {dataset_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # --------------------- 1. Load Data if needed ---------------------\n",
        "    # Check if df is a file path string\n",
        "    if isinstance(df, str):\n",
        "        print(f\"Loading dataset from: {df}\")\n",
        "        df = pd.read_csv(df)\n",
        "        print(f\"Dataset loaded successfully!\")\n",
        "\n",
        "    # --------------------- 2. Prepare Data ---------------------\n",
        "    category_cols = [f\"Category {i}\" for i in range(14, 22)]\n",
        "\n",
        "    # Use Justification column for SciBERT evaluation\n",
        "    X_texts = df[\"Justification\"].fillna(\"\").astype(str).tolist()\n",
        "    Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "    print(f\"Dataset size: {len(df)}\")\n",
        "    print(f\"Categories evaluated: {category_cols}\")\n",
        "\n",
        "    # Check for empty dataset\n",
        "    if len(X_texts) == 0:\n",
        "        print(f\"Warning: {dataset_name} is empty!\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # --------------------- 2. Split (20/80) Train/Val ---------------------\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Validation samples: {len(X_val)}\")\n",
        "\n",
        "    # --------------------- 3. Custom Dataset ---------------------\n",
        "    class MultiLabelDataset(Dataset):\n",
        "        def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "            self.texts = texts\n",
        "            self.labels = labels\n",
        "            self.tokenizer = tokenizer\n",
        "            self.max_length = max_length\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.texts)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            text = self.texts[idx]\n",
        "            label = self.labels[idx]\n",
        "            encoding = self.tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_length,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "            item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "            return item\n",
        "\n",
        "    # --------------------- 4. Load SciBERT ---------------------\n",
        "    model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=len(category_cols),\n",
        "        problem_type=\"multi_label_classification\"\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # --------------------- 5. DataLoaders ---------------------\n",
        "    batch_size = 8\n",
        "\n",
        "    train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "    val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # --------------------- 6. Optimizer & Loss ---------------------\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # --------------------- 7. Training Loop ---------------------\n",
        "    epochs = 5\n",
        "    print(f\"\\nTraining for {epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "        for batch in loop:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = loss_fn(outputs.logits, labels)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # --------------------- 8. Evaluation ---------------------\n",
        "    print(\"Evaluating model...\")\n",
        "    model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).int()\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_probs.append(probs.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    Y_pred = torch.cat(all_preds).numpy()\n",
        "    Y_prob = torch.cat(all_probs).numpy()\n",
        "    Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "    # --------------------- 9. Metrics ---------------------\n",
        "    results = []\n",
        "    for i, cat in enumerate(category_cols):\n",
        "        acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "        prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "    results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "    results_df[\"Dataset\"] = dataset_name  # Add dataset identifier\n",
        "\n",
        "    print(f\"\\nSciBERT Evaluation Results for {dataset_name}:\")\n",
        "    print(results_df[[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]])\n",
        "\n",
        "    # Clear GPU memory\n",
        "    del model, optimizer, train_dataset, val_dataset\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    return results_df\n",
        "\n",
        "def compare_all_datasets(initial_df, generated_df, merged_df):\n",
        "    \"\"\"\n",
        "    Compare SciBERT performance across all three datasets\n",
        "    \"\"\"\n",
        "    print(\"Starting comprehensive SciBERT evaluation...\")\n",
        "    print(\"This will evaluate: Initial → Generated → Merged datasets\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # Evaluate Initial Dataset\n",
        "    if len(initial_df) > 0:\n",
        "        initial_results = evaluate_dataset_with_scibert(initial_df, \"Initial Dataset\")\n",
        "        all_results.append(initial_results)\n",
        "\n",
        "    # Evaluate Generated Dataset\n",
        "    if len(generated_df) > 0:\n",
        "        generated_results = evaluate_dataset_with_scibert(generated_df, \"Generated Dataset\")\n",
        "        all_results.append(generated_results)\n",
        "\n",
        "    # Evaluate Merged Dataset\n",
        "    if len(merged_df) > 0:\n",
        "        merged_results = evaluate_dataset_with_scibert(merged_df, \"Merged Dataset\")\n",
        "        all_results.append(merged_results)\n",
        "\n",
        "    # Combine all results for comparison\n",
        "    if all_results:\n",
        "        comparison_df = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"COMPREHENSIVE COMPARISON - All Datasets\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Pivot for easier comparison\n",
        "        comparison_pivot = comparison_df.pivot_table(\n",
        "            index='Category',\n",
        "            columns='Dataset',\n",
        "            values=['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
        "            aggfunc='first'\n",
        "        )\n",
        "\n",
        "        print(\"\\nF1 Score Comparison:\")\n",
        "        if 'F1 Score' in comparison_pivot.columns.levels[0]:\n",
        "            print(comparison_pivot['F1 Score'].round(4))\n",
        "\n",
        "        print(\"\\nAccuracy Comparison:\")\n",
        "        if 'Accuracy' in comparison_pivot.columns.levels[0]:\n",
        "            print(comparison_pivot['Accuracy'].round(4))\n",
        "\n",
        "        # Save comprehensive results\n",
        "        comparison_df.to_csv('scibert_evaluation_results.csv', index=False)\n",
        "        print(f\"\\nResults saved to 'scibert_evaluation_results.csv'\")\n",
        "\n",
        "        return comparison_df\n",
        "\n",
        "    return pd.DataFrame()\n",
        "\n",
        "results = evaluate_dataset_with_scibert(\"/kaggle/working/merged_dataset.csv\", \"Merged Dataset\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T21:45:09.067126Z",
          "iopub.execute_input": "2025-08-07T21:45:09.067722Z",
          "iopub.status.idle": "2025-08-07T21:55:30.769224Z",
          "shell.execute_reply.started": "2025-08-07T21:45:09.067696Z",
          "shell.execute_reply": "2025-08-07T21:55:30.768539Z"
        },
        "id": "ZRkTvcttMjnN",
        "outputId": "e3746682-97ee-4ba2-d600-6d75271fd490"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n============================================================\nSciBERT Evaluation on Merged Dataset\n============================================================\nLoading dataset from: /kaggle/working/merged_dataset.csv\nDataset loaded successfully!\nDataset size: 1565\nCategories evaluated: ['Category 14', 'Category 15', 'Category 16', 'Category 17', 'Category 18', 'Category 19', 'Category 20', 'Category 21']\nTraining samples: 1252\nValidation samples: 313\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Using device: cuda\n\nTraining for 5 epochs...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.4344\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Train Loss: 0.3475\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Train Loss: 0.2888\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.2331\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                         \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.1744\nEvaluating model...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 40/40 [00:10<00:00,  4.00it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nSciBERT Evaluation Results for Merged Dataset:\n      Category  Accuracy  Precision    Recall  F1 Score\n0  Category 14  0.811502   0.604396  0.705128  0.650888\n1  Category 15  0.859425   0.542373  0.653061  0.592593\n2  Category 16  0.859425   0.483333  0.690476  0.568627\n3  Category 17  0.817891   0.480769  0.454545  0.467290\n4  Category 18  0.849840   0.475000  0.422222  0.447059\n5  Category 19  0.849840   0.479167  0.511111  0.494624\n6  Category 20  0.929712   0.770833  0.770833  0.770833\n7  Category 21  0.853035   0.653846  0.548387  0.596491\nSciBERT evaluation functions ready!\n\nUsage Options:\n1. DataFrame: results = evaluate_dataset_with_scibert(df, 'Dataset Name')\n2. File path: results = evaluate_dataset_with_scibert('/path/to/file.csv', 'Dataset Name')\n3. Compare all: comparison = compare_all_datasets(df1, df2, df3)\n\nNow supports both DataFrames and file paths!\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_dataset_with_scibert(df, dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Evaluate a dataset using SciBERT for Categories 14-21\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with 'Justification' column and Category 14-21 columns OR file path string\n",
        "        dataset_name: Name for display purposes\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"SciBERT Evaluation on {dataset_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # --------------------- 1. Load Data if needed ---------------------\n",
        "    # Check if df is a file path string\n",
        "    if isinstance(df, str):\n",
        "        print(f\"Loading dataset from: {df}\")\n",
        "        df = pd.read_csv(df)\n",
        "        print(f\"Dataset loaded successfully!\")\n",
        "\n",
        "    # --------------------- 2. Prepare Data ---------------------\n",
        "    category_cols = [f\"Category {i}\" for i in range(14, 22)]\n",
        "\n",
        "    # Use Justification column for SciBERT evaluation\n",
        "    X_texts = df[\"Justification\"].fillna(\"\").astype(str).tolist()\n",
        "    Y = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int).values\n",
        "\n",
        "    print(f\"Dataset size: {len(df)}\")\n",
        "    print(f\"Categories evaluated: {category_cols}\")\n",
        "\n",
        "    # Check for empty dataset\n",
        "    if len(X_texts) == 0:\n",
        "        print(f\"Warning: {dataset_name} is empty!\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # --------------------- 2. Split (20/80) Train/Val ---------------------\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X_texts, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Validation samples: {len(X_val)}\")\n",
        "\n",
        "    # --------------------- 3. Custom Dataset ---------------------\n",
        "    class MultiLabelDataset(Dataset):\n",
        "        def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "            self.texts = texts\n",
        "            self.labels = labels\n",
        "            self.tokenizer = tokenizer\n",
        "            self.max_length = max_length\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.texts)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            text = self.texts[idx]\n",
        "            label = self.labels[idx]\n",
        "            encoding = self.tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.max_length,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "            item[\"labels\"] = torch.tensor(label, dtype=torch.float)\n",
        "            return item\n",
        "\n",
        "    # --------------------- 4. Load SciBERT ---------------------\n",
        "    model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=len(category_cols),\n",
        "        problem_type=\"multi_label_classification\"\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # --------------------- 5. DataLoaders ---------------------\n",
        "    batch_size = 8\n",
        "\n",
        "    train_dataset = MultiLabelDataset(X_train, Y_train, tokenizer)\n",
        "    val_dataset = MultiLabelDataset(X_val, Y_val, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # --------------------- 6. Optimizer & Loss ---------------------\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # --------------------- 7. Training Loop ---------------------\n",
        "    epochs = 5\n",
        "    print(f\"\\nTraining for {epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "        for batch in loop:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = loss_fn(outputs.logits, labels)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Train Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # --------------------- 8. Evaluation ---------------------\n",
        "    print(\"Evaluating model...\")\n",
        "    model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).int()\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_probs.append(probs.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    Y_pred = torch.cat(all_preds).numpy()\n",
        "    Y_prob = torch.cat(all_probs).numpy()\n",
        "    Y_true = torch.cat(all_labels).numpy()\n",
        "\n",
        "    # --------------------- 9. Metrics ---------------------\n",
        "    results = []\n",
        "    for i, cat in enumerate(category_cols):\n",
        "        acc = accuracy_score(Y_true[:, i], Y_pred[:, i])\n",
        "        prec = precision_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        rec = recall_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        f1 = f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0)\n",
        "        results.append([cat, acc, prec, rec, f1])\n",
        "\n",
        "    results_df = pd.DataFrame(results, columns=[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "    results_df[\"Dataset\"] = dataset_name  # Add dataset identifier\n",
        "\n",
        "    print(f\"\\nSciBERT Evaluation Results for {dataset_name}:\")\n",
        "    print(results_df[[\"Category\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]])\n",
        "\n",
        "    # Clear GPU memory\n",
        "    del model, optimizer, train_dataset, val_dataset\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    return results_df\n",
        "\n",
        "def compare_all_datasets(initial_df, generated_df, merged_df):\n",
        "    \"\"\"\n",
        "    Compare SciBERT performance across all three datasets\n",
        "    \"\"\"\n",
        "    print(\"Starting comprehensive SciBERT evaluation...\")\n",
        "    print(\"This will evaluate: Initial → Generated → Merged datasets\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # Evaluate Initial Dataset\n",
        "    if len(initial_df) > 0:\n",
        "        initial_results = evaluate_dataset_with_scibert(initial_df, \"Initial Dataset\")\n",
        "        all_results.append(initial_results)\n",
        "\n",
        "    # Evaluate Generated Dataset\n",
        "    if len(generated_df) > 0:\n",
        "        generated_results = evaluate_dataset_with_scibert(generated_df, \"Generated Dataset\")\n",
        "        all_results.append(generated_results)\n",
        "\n",
        "    # Evaluate Merged Dataset\n",
        "    if len(merged_df) > 0:\n",
        "        merged_results = evaluate_dataset_with_scibert(merged_df, \"Merged Dataset\")\n",
        "        all_results.append(merged_results)\n",
        "\n",
        "    # Combine all results for comparison\n",
        "    if all_results:\n",
        "        comparison_df = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"COMPREHENSIVE COMPARISON - All Datasets\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Pivot for easier comparison\n",
        "        comparison_pivot = comparison_df.pivot_table(\n",
        "            index='Category',\n",
        "            columns='Dataset',\n",
        "            values=['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
        "            aggfunc='first'\n",
        "        )\n",
        "\n",
        "        print(\"\\nF1 Score Comparison:\")\n",
        "        if 'F1 Score' in comparison_pivot.columns.levels[0]:\n",
        "            print(comparison_pivot['F1 Score'].round(4))\n",
        "\n",
        "        print(\"\\nAccuracy Comparison:\")\n",
        "        if 'Accuracy' in comparison_pivot.columns.levels[0]:\n",
        "            print(comparison_pivot['Accuracy'].round(4))\n",
        "\n",
        "        # Save comprehensive results\n",
        "        comparison_df.to_csv('scibert_evaluation_results.csv', index=False)\n",
        "        print(f\"\\nResults saved to 'scibert_evaluation_results.csv'\")\n",
        "\n",
        "        return comparison_df\n",
        "\n",
        "    return pd.DataFrame()\n",
        "\n",
        "results = evaluate_dataset_with_scibert(\"/kaggle/working/generated_augmented_data.csv\", \"Generated Dataset\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-08T00:58:01.347790Z",
          "iopub.execute_input": "2025-08-08T00:58:01.348346Z",
          "iopub.status.idle": "2025-08-08T01:01:29.172868Z",
          "shell.execute_reply.started": "2025-08-08T00:58:01.348323Z",
          "shell.execute_reply": "2025-08-08T01:01:29.172257Z"
        },
        "colab": {
          "referenced_widgets": [
            "870818975d014a369db39192eeeaebf5",
            "8bf5b175e983445b86daba81a7aee076",
            "54dbcc0282ff4deb99da98171f340f9d",
            "485186885cd3480e9691341cdde73451"
          ]
        },
        "id": "zlO4qslGMjnO",
        "outputId": "6c22af9b-94ac-419c-d4ea-44a16be2ee9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n============================================================\nSciBERT Evaluation on Generated Dataset\n============================================================\nLoading dataset from: /kaggle/working/generated_augmented_data.csv\nDataset loaded successfully!\nDataset size: 542\nCategories evaluated: ['Category 14', 'Category 15', 'Category 16', 'Category 17', 'Category 18', 'Category 19', 'Category 20', 'Category 21']\nTraining samples: 433\nValidation samples: 109\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "870818975d014a369db39192eeeaebf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bf5b175e983445b86daba81a7aee076"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54dbcc0282ff4deb99da98171f340f9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "485186885cd3480e9691341cdde73451"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Using device: cuda\n\nTraining for 5 epochs...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\nEpoch 1/5:   0%|          | 0/55 [00:00<?, ?it/s]\u001b[A\nEpoch 1/5:   0%|          | 0/55 [00:01<?, ?it/s, loss=0.677]\u001b[A\nEpoch 1/5:   2%|▏         | 1/55 [00:01<01:22,  1.53s/it, loss=0.677]\u001b[A\nEpoch 1/5:   2%|▏         | 1/55 [00:02<01:22,  1.53s/it, loss=0.634]\u001b[A\nEpoch 1/5:   4%|▎         | 2/55 [00:02<00:54,  1.03s/it, loss=0.634]\u001b[A\nEpoch 1/5:   4%|▎         | 2/55 [00:02<00:54,  1.03s/it, loss=0.653]\u001b[A\nEpoch 1/5:   5%|▌         | 3/55 [00:02<00:45,  1.16it/s, loss=0.653]\u001b[A\nEpoch 1/5:   5%|▌         | 3/55 [00:03<00:45,  1.16it/s, loss=0.506]\u001b[A\nEpoch 1/5:   7%|▋         | 4/55 [00:03<00:40,  1.27it/s, loss=0.506]\u001b[A\nEpoch 1/5:   7%|▋         | 4/55 [00:04<00:40,  1.27it/s, loss=0.549]\u001b[A\nEpoch 1/5:   9%|▉         | 5/55 [00:04<00:37,  1.34it/s, loss=0.549]\u001b[A\nEpoch 1/5:   9%|▉         | 5/55 [00:04<00:37,  1.34it/s, loss=0.601]\u001b[A\nEpoch 1/5:  11%|█         | 6/55 [00:04<00:35,  1.39it/s, loss=0.601]\u001b[A\nEpoch 1/5:  11%|█         | 6/55 [00:05<00:35,  1.39it/s, loss=0.595]\u001b[A\nEpoch 1/5:  13%|█▎        | 7/55 [00:05<00:33,  1.42it/s, loss=0.595]\u001b[A\nEpoch 1/5:  13%|█▎        | 7/55 [00:06<00:33,  1.42it/s, loss=0.517]\u001b[A\nEpoch 1/5:  15%|█▍        | 8/55 [00:06<00:32,  1.45it/s, loss=0.517]\u001b[A\nEpoch 1/5:  15%|█▍        | 8/55 [00:06<00:32,  1.45it/s, loss=0.51] \u001b[A\nEpoch 1/5:  16%|█▋        | 9/55 [00:06<00:31,  1.46it/s, loss=0.51]\u001b[A\nEpoch 1/5:  16%|█▋        | 9/55 [00:07<00:31,  1.46it/s, loss=0.563]\u001b[A\nEpoch 1/5:  18%|█▊        | 10/55 [00:07<00:30,  1.46it/s, loss=0.563]\u001b[A\nEpoch 1/5:  18%|█▊        | 10/55 [00:08<00:30,  1.46it/s, loss=0.567]\u001b[A\nEpoch 1/5:  20%|██        | 11/55 [00:08<00:29,  1.47it/s, loss=0.567]\u001b[A\nEpoch 1/5:  20%|██        | 11/55 [00:08<00:29,  1.47it/s, loss=0.443]\u001b[A\nEpoch 1/5:  22%|██▏       | 12/55 [00:08<00:29,  1.48it/s, loss=0.443]\u001b[A\nEpoch 1/5:  22%|██▏       | 12/55 [00:09<00:29,  1.48it/s, loss=0.558]\u001b[A\nEpoch 1/5:  24%|██▎       | 13/55 [00:09<00:28,  1.49it/s, loss=0.558]\u001b[A\nEpoch 1/5:  24%|██▎       | 13/55 [00:10<00:28,  1.49it/s, loss=0.511]\u001b[A\nEpoch 1/5:  25%|██▌       | 14/55 [00:10<00:27,  1.49it/s, loss=0.511]\u001b[A\nEpoch 1/5:  25%|██▌       | 14/55 [00:10<00:27,  1.49it/s, loss=0.446]\u001b[A\nEpoch 1/5:  27%|██▋       | 15/55 [00:10<00:26,  1.49it/s, loss=0.446]\u001b[A\nEpoch 1/5:  27%|██▋       | 15/55 [00:11<00:26,  1.49it/s, loss=0.629]\u001b[A\nEpoch 1/5:  29%|██▉       | 16/55 [00:11<00:26,  1.48it/s, loss=0.629]\u001b[A\nEpoch 1/5:  29%|██▉       | 16/55 [00:12<00:26,  1.48it/s, loss=0.582]\u001b[A\nEpoch 1/5:  31%|███       | 17/55 [00:12<00:25,  1.48it/s, loss=0.582]\u001b[A\nEpoch 1/5:  31%|███       | 17/55 [00:12<00:25,  1.48it/s, loss=0.47] \u001b[A\nEpoch 1/5:  33%|███▎      | 18/55 [00:12<00:24,  1.48it/s, loss=0.47]\u001b[A\nEpoch 1/5:  33%|███▎      | 18/55 [00:13<00:24,  1.48it/s, loss=0.497]\u001b[A\nEpoch 1/5:  35%|███▍      | 19/55 [00:13<00:24,  1.48it/s, loss=0.497]\u001b[A\nEpoch 1/5:  35%|███▍      | 19/55 [00:14<00:24,  1.48it/s, loss=0.35] \u001b[A\nEpoch 1/5:  36%|███▋      | 20/55 [00:14<00:23,  1.48it/s, loss=0.35]\u001b[A\nEpoch 1/5:  36%|███▋      | 20/55 [00:14<00:23,  1.48it/s, loss=0.335]\u001b[A\nEpoch 1/5:  38%|███▊      | 21/55 [00:14<00:22,  1.48it/s, loss=0.335]\u001b[A\nEpoch 1/5:  38%|███▊      | 21/55 [00:15<00:22,  1.48it/s, loss=0.518]\u001b[A\nEpoch 1/5:  40%|████      | 22/55 [00:15<00:22,  1.48it/s, loss=0.518]\u001b[A\nEpoch 1/5:  40%|████      | 22/55 [00:16<00:22,  1.48it/s, loss=0.479]\u001b[A\nEpoch 1/5:  42%|████▏     | 23/55 [00:16<00:21,  1.47it/s, loss=0.479]\u001b[A\nEpoch 1/5:  42%|████▏     | 23/55 [00:17<00:21,  1.47it/s, loss=0.545]\u001b[A\nEpoch 1/5:  44%|████▎     | 24/55 [00:17<00:21,  1.48it/s, loss=0.545]\u001b[A\nEpoch 1/5:  44%|████▎     | 24/55 [00:17<00:21,  1.48it/s, loss=0.416]\u001b[A\nEpoch 1/5:  45%|████▌     | 25/55 [00:17<00:20,  1.47it/s, loss=0.416]\u001b[A\nEpoch 1/5:  45%|████▌     | 25/55 [00:18<00:20,  1.47it/s, loss=0.491]\u001b[A\nEpoch 1/5:  47%|████▋     | 26/55 [00:18<00:19,  1.48it/s, loss=0.491]\u001b[A\nEpoch 1/5:  47%|████▋     | 26/55 [00:19<00:19,  1.48it/s, loss=0.242]\u001b[A\nEpoch 1/5:  49%|████▉     | 27/55 [00:19<00:19,  1.47it/s, loss=0.242]\u001b[A\nEpoch 1/5:  49%|████▉     | 27/55 [00:19<00:19,  1.47it/s, loss=0.409]\u001b[A\nEpoch 1/5:  51%|█████     | 28/55 [00:19<00:18,  1.47it/s, loss=0.409]\u001b[A\nEpoch 1/5:  51%|█████     | 28/55 [00:20<00:18,  1.47it/s, loss=0.778]\u001b[A\nEpoch 1/5:  53%|█████▎    | 29/55 [00:20<00:17,  1.47it/s, loss=0.778]\u001b[A\nEpoch 1/5:  53%|█████▎    | 29/55 [00:21<00:17,  1.47it/s, loss=0.629]\u001b[A\nEpoch 1/5:  55%|█████▍    | 30/55 [00:21<00:17,  1.47it/s, loss=0.629]\u001b[A\nEpoch 1/5:  55%|█████▍    | 30/55 [00:21<00:17,  1.47it/s, loss=0.411]\u001b[A\nEpoch 1/5:  56%|█████▋    | 31/55 [00:21<00:16,  1.47it/s, loss=0.411]\u001b[A\nEpoch 1/5:  56%|█████▋    | 31/55 [00:22<00:16,  1.47it/s, loss=0.661]\u001b[A\nEpoch 1/5:  58%|█████▊    | 32/55 [00:22<00:15,  1.47it/s, loss=0.661]\u001b[A\nEpoch 1/5:  58%|█████▊    | 32/55 [00:23<00:15,  1.47it/s, loss=0.404]\u001b[A\nEpoch 1/5:  60%|██████    | 33/55 [00:23<00:14,  1.48it/s, loss=0.404]\u001b[A\nEpoch 1/5:  60%|██████    | 33/55 [00:23<00:14,  1.48it/s, loss=0.591]\u001b[A\nEpoch 1/5:  62%|██████▏   | 34/55 [00:23<00:14,  1.47it/s, loss=0.591]\u001b[A\nEpoch 1/5:  62%|██████▏   | 34/55 [00:24<00:14,  1.47it/s, loss=0.524]\u001b[A\nEpoch 1/5:  64%|██████▎   | 35/55 [00:24<00:13,  1.47it/s, loss=0.524]\u001b[A\nEpoch 1/5:  64%|██████▎   | 35/55 [00:25<00:13,  1.47it/s, loss=0.626]\u001b[A\nEpoch 1/5:  65%|██████▌   | 36/55 [00:25<00:12,  1.47it/s, loss=0.626]\u001b[A\nEpoch 1/5:  65%|██████▌   | 36/55 [00:25<00:12,  1.47it/s, loss=0.523]\u001b[A\nEpoch 1/5:  67%|██████▋   | 37/55 [00:25<00:12,  1.46it/s, loss=0.523]\u001b[A\nEpoch 1/5:  67%|██████▋   | 37/55 [00:26<00:12,  1.46it/s, loss=0.449]\u001b[A\nEpoch 1/5:  69%|██████▉   | 38/55 [00:26<00:11,  1.46it/s, loss=0.449]\u001b[A\nEpoch 1/5:  69%|██████▉   | 38/55 [00:27<00:11,  1.46it/s, loss=0.556]\u001b[A\nEpoch 1/5:  71%|███████   | 39/55 [00:27<00:10,  1.46it/s, loss=0.556]\u001b[A\nEpoch 1/5:  71%|███████   | 39/55 [00:27<00:10,  1.46it/s, loss=0.461]\u001b[A\nEpoch 1/5:  73%|███████▎  | 40/55 [00:27<00:10,  1.46it/s, loss=0.461]\u001b[A\nEpoch 1/5:  73%|███████▎  | 40/55 [00:28<00:10,  1.46it/s, loss=0.574]\u001b[A\nEpoch 1/5:  75%|███████▍  | 41/55 [00:28<00:09,  1.46it/s, loss=0.574]\u001b[A\nEpoch 1/5:  75%|███████▍  | 41/55 [00:29<00:09,  1.46it/s, loss=0.379]\u001b[A\nEpoch 1/5:  76%|███████▋  | 42/55 [00:29<00:08,  1.46it/s, loss=0.379]\u001b[A\nEpoch 1/5:  76%|███████▋  | 42/55 [00:30<00:08,  1.46it/s, loss=0.406]\u001b[A\nEpoch 1/5:  78%|███████▊  | 43/55 [00:30<00:08,  1.45it/s, loss=0.406]\u001b[A\nEpoch 1/5:  78%|███████▊  | 43/55 [00:30<00:08,  1.45it/s, loss=0.438]\u001b[A\nEpoch 1/5:  80%|████████  | 44/55 [00:30<00:07,  1.45it/s, loss=0.438]\u001b[A\nEpoch 1/5:  80%|████████  | 44/55 [00:31<00:07,  1.45it/s, loss=0.386]\u001b[A\nEpoch 1/5:  82%|████████▏ | 45/55 [00:31<00:06,  1.45it/s, loss=0.386]\u001b[A\nEpoch 1/5:  82%|████████▏ | 45/55 [00:32<00:06,  1.45it/s, loss=0.245]\u001b[A\nEpoch 1/5:  84%|████████▎ | 46/55 [00:32<00:06,  1.45it/s, loss=0.245]\u001b[A\nEpoch 1/5:  84%|████████▎ | 46/55 [00:32<00:06,  1.45it/s, loss=0.645]\u001b[A\nEpoch 1/5:  85%|████████▌ | 47/55 [00:32<00:05,  1.45it/s, loss=0.645]\u001b[A\nEpoch 1/5:  85%|████████▌ | 47/55 [00:33<00:05,  1.45it/s, loss=0.439]\u001b[A\nEpoch 1/5:  87%|████████▋ | 48/55 [00:33<00:04,  1.44it/s, loss=0.439]\u001b[A\nEpoch 1/5:  87%|████████▋ | 48/55 [00:34<00:04,  1.44it/s, loss=0.68] \u001b[A\nEpoch 1/5:  89%|████████▉ | 49/55 [00:34<00:04,  1.44it/s, loss=0.68]\u001b[A\nEpoch 1/5:  89%|████████▉ | 49/55 [00:34<00:04,  1.44it/s, loss=0.605]\u001b[A\nEpoch 1/5:  91%|█████████ | 50/55 [00:34<00:03,  1.44it/s, loss=0.605]\u001b[A\nEpoch 1/5:  91%|█████████ | 50/55 [00:35<00:03,  1.44it/s, loss=0.579]\u001b[A\nEpoch 1/5:  93%|█████████▎| 51/55 [00:35<00:02,  1.44it/s, loss=0.579]\u001b[A\nEpoch 1/5:  93%|█████████▎| 51/55 [00:36<00:02,  1.44it/s, loss=0.492]\u001b[A\nEpoch 1/5:  95%|█████████▍| 52/55 [00:36<00:02,  1.44it/s, loss=0.492]\u001b[A\nEpoch 1/5:  95%|█████████▍| 52/55 [00:36<00:02,  1.44it/s, loss=0.642]\u001b[A\nEpoch 1/5:  96%|█████████▋| 53/55 [00:36<00:01,  1.44it/s, loss=0.642]\u001b[A\nEpoch 1/5:  96%|█████████▋| 53/55 [00:37<00:01,  1.44it/s, loss=0.468]\u001b[A\nEpoch 1/5:  98%|█████████▊| 54/55 [00:37<00:00,  1.44it/s, loss=0.468]\u001b[A\nEpoch 1/5:  98%|█████████▊| 54/55 [00:37<00:00,  1.44it/s, loss=0.261]\u001b[A\nEpoch 1/5: 100%|██████████| 55/55 [00:37<00:00,  1.88it/s, loss=0.261]\u001b[A\n                                                                      \u001b[A",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Train Loss: 0.5117\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                      \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Train Loss: 0.4697\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                      \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Train Loss: 0.3784\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Train Loss: 0.2489\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                       \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Train Loss: 0.2158\nEvaluating model...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating: 100%|██████████| 14/14 [00:03<00:00,  4.27it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nSciBERT Evaluation Results for Generated Dataset:\n      Category  Accuracy  Precision    Recall  F1 Score\n0  Category 14  0.917431   0.500000  0.222222  0.307692\n1  Category 15  0.770642   0.541667  0.481481  0.509804\n2  Category 16  0.944954   0.000000  0.000000  0.000000\n3  Category 17  0.770642   0.541667  0.481481  0.509804\n4  Category 18  0.770642   0.541667  0.481481  0.509804\n5  Category 19  0.770642   0.541667  0.481481  0.509804\n6  Category 20  0.972477   0.000000  0.000000  0.000000\n7  Category 21  0.770642   0.541667  0.481481  0.509804\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}